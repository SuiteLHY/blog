<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[分布式技术面试题]]></title>
    <url>%2Fblog%2F2019%2F10%2F25%2Fdesign%2Farchitecture%2F%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[分布式技术面试题 1. 分布式缓存 1.1. Redis 有什么数据类型？分别用于什么场景？ 1.2. Redis 的主从复制是如何实现的？ 1.3. Redis 的 key 是如何寻址的？ 1.4. Redis 的集群模式是如何实现的？ 1.5. Redis 如何实现分布式锁？ZooKeeper 如何实现分布式锁？比较二者优劣？ 1.6. Redis 的持久化方式？有什么优缺点？持久化实现原理？ 1.7. Redis 过期策略有哪些？ 1.8. Redis 和 Memcached 有什么区别？ 1.9. 为什么单线程的 Redis 性能反而优于多线程的 Memcached？ 2. 分布式消息队列（MQ） 2.1. 为什么使用 MQ？ 2.2. 如何保证 MQ 的高可用？ 2.3. MQ 有哪些常见问题？如何解决这些问题？ 2.4. Kafka, ActiveMQ, RabbitMQ, RocketMQ 各有什么优缺点？ 3. 分布式服务（RPC） 3.1. Dubbo 的实现过程？ 3.2. Dubbo 负载均衡策略有哪些？ 3.3. Dubbo 集群容错策略 ？ 3.4. 动态代理策略？ 3.5. Dubbo 支持哪些序列化协议？Hessian？Hessian 的数据结构？ 3.6. Protoco Buffer 是什么？ 3.7. 注册中心挂了可以继续通信吗？ 3.8. ZooKeeper 原理是什么？ZooKeeper 有什么用？ 3.9. Netty 有什么用？NIO/BIO/AIO 有什么用？有什么区别？ 3.10. 为什么要进行系统拆分？拆分不用 Dubbo 可以吗？ 3.11. Dubbo 和 Thrift 有什么区别？ 1. 分布式缓存 1.1. Redis 有什么数据类型？分别用于什么场景？ 数据类型 可以存储的值 操作 STRING 字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作 LIST 列表 从两端压入或者弹出元素 读取单个或者多个元素 进行修剪，只保留一个范围内的元素 SET 无序集合 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 HASH 包含键值对的无序散列表 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 ZSET 有序集合 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 What Redis data structures look like 1.2. Redis 的主从复制是如何实现的？ 从服务器连接主服务器，发送 SYNC 命令； 主服务器接收到 SYNC 命名后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令； 主服务器 BGSAVE 执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； 1.3. Redis 的 key 是如何寻址的？ 背景 （1）redis 中的每一个数据库，都由一个 redisDb 的结构存储。其中： redisDb.id 存储着 redis 数据库以整数表示的号码。 redisDb.dict 存储着该库所有的键值对数据。 redisDb.expires 保存着每一个键的过期时间。 （2）当 redis 服务器初始化时，会预先分配 16 个数据库（该数量可以通过配置文件配置），所有数据库保存到结构 redisServer 的一个成员 redisServer.db 数组中。当我们选择数据库 select number 时，程序直接通过 redisServer.db[number] 来切换数据库。有时候当程序需要知道自己是在哪个数据库时，直接读取 redisDb.id 即可。 （3）redis 的字典使用哈希表作为其底层实现。dict 类型使用的两个指向哈希表的指针，其中 0 号哈希表（ht[0]）主要用于存储数据库的所有键值，而 1 号哈希表主要用于程序对 0 号哈希表进行 rehash 时使用，rehash 一般是在添加新值时会触发，这里不做过多的赘述。所以 redis 中查找一个 key，其实就是对进行该 dict 结构中的 ht[0] 进行查找操作。 （4）既然是哈希，那么我们知道就会有哈希碰撞，那么当多个键哈希之后为同一个值怎么办呢？redis 采取链表的方式来存储多个哈希碰撞的键。也就是说，当根据 key 的哈希值找到该列表后，如果列表的长度大于 1，那么我们需要遍历该链表来找到我们所查找的 key。当然，一般情况下链表长度都为是 1，所以时间复杂度可看作 o(1)。 寻址 key 的步骤 当拿到一个 key 后，redis 先判断当前库的 0 号哈希表是否为空，即：if (dict-&gt;ht[0].size == 0)。如果为 true 直接返回 NULL。 判断该 0 号哈希表是否需要 rehash，因为如果在进行 rehash，那么两个表中者有可能存储该 key。如果正在进行 rehash，将调用一次_dictRehashStep 方法，_dictRehashStep 用于对数据库字典、以及哈希键的字典进行被动 rehash，这里不作赘述。 计算哈希表，根据当前字典与 key 进行哈希值的计算。 根据哈希值与当前字典计算哈希表的索引值。 根据索引值在哈希表中取出链表，遍历该链表找到 key 的位置。一般情况，该链表长度为 1。 当 ht[0] 查找完了之后，再进行了次 rehash 判断，如果未在 rehashing，则直接结束，否则对 ht[1]重复 345 步骤。 1.4. Redis 的集群模式是如何实现的？ Redis Cluster 是 Redis 的分布式解决方案，在 Redis 3.0 版本正式推出的。 Redis Cluster 去中心化，每个节点保存数据和整个集群状态，每个节点都和其他所有节点连接。 Redis Cluster 节点分配 Redis Cluster 特点： 所有的 redis 节点彼此互联(PING-PONG 机制)，内部使用二进制协议优化传输速度和带宽。 节点的 fail 是通过集群中超过半数的节点检测失效时才生效。 客户端与 redis 节点直连,不需要中间 proxy 层。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。 redis-cluster 把所有的物理节点映射到[0-16383] 哈希槽 (hash slot)上（不一定是平均分配）,cluster 负责维护 node、slot、value。 Redis 集群预分好 16384 个桶，当需要在 Redis 集群中放置一个 key-value 时，根据 CRC16(key) mod 16384 的值，决定将一个 key 放到哪个桶中。 Redis Cluster 主从模式 Redis Cluster 为了保证数据的高可用性，加入了主从模式。 一个主节点对应一个或多个从节点，主节点提供数据存取，从节点则是从主节点拉取数据备份。当这个主节点挂掉后，就会有这个从节点选取一个来充当主节点，从而保证集群不会挂掉。所以，在集群建立的时候，一定要为每个主节点都添加了从节点。 Redis Sentinel Redis Sentinel 用于管理多个 Redis 服务器，它有三个功能： 监控（Monitoring） - Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。 提醒（Notification） - 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。 自动故障迁移（Automatic failover） - 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效主服务器的其中一个从服务器升级为新的主服务器， 并让失效主服务器的其他从服务器改为复制新的主服务器； 当客户端试图连接失效的主服务器时， 集群也会向客户端返回新主服务器的地址， 使得集群可以使用新主服务器代替失效服务器。 Redis 集群中应该有奇数个节点，所以至少有三个节点。 哨兵监控集群中的主服务器出现故障时，需要根据 quorum 选举出一个哨兵来执行故障转移。选举需要 majority，即大多数哨兵是运行的（2 个哨兵的 majority=2，3 个哨兵的 majority=2，5 个哨兵的 majority=3，4 个哨兵的 majority=2）。 假设集群仅仅部署 2 个节点 +----+ +----+| M1 |---------| R1 || S1 | | S2 |+----+ +----+ 如果 M1 和 S1 所在服务器宕机，则哨兵只有 1 个，无法满足 majority 来进行选举，就不能执行故障转移。 1.5. Redis 如何实现分布式锁？ZooKeeper 如何实现分布式锁？比较二者优劣？ 分布式锁的三种实现： 基于数据库实现分布式锁； 基于缓存（Redis 等）实现分布式锁； 基于 Zookeeper 实现分布式锁； 数据库实现 Redis 实现 获取锁的时候，使用 setnx 加锁，并使用 expire 命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的 value 值为一个随机生成的 UUID，通过此在释放锁的时候进行判断。 获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。 释放锁的时候，通过 UUID 判断是不是该锁，若是该锁，则执行 delete 进行锁释放。 ZooKeeper 实现 创建一个目录 mylock； 线程 A 想获取锁就在 mylock 目录下创建临时顺序节点； 获取 mylock 目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁； 线程 B 获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点； 线程 A 处理完，删除自己的节点，线程 B 监听到变更事件，判断自己是不是最小的节点，如果是则获得锁。 实现对比 ZooKeeper 具备高可用、可重入、阻塞锁特性，可解决失效死锁问题。 但 ZooKeeper 因为需要频繁的创建和删除节点，性能上不如 Redis 方式。 1.6. Redis 的持久化方式？有什么优缺点？持久化实现原理？ RDB 快照（snapshot） 将存在于某一时刻的所有数据都写入到硬盘中。 快照的原理 在默认情况下，Redis 将数据库快照保存在名字为 dump.rdb 的二进制文件中。你可以对 Redis 进行设置， 让它在“N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据集。你也可以通过调用 SAVE 或者 BGSAVE，手动让 Redis 进行数据集保存操作。这种持久化方式被称为快照。 当 Redis 需要保存 dump.rdb 文件时， 服务器执行以下操作: Redis 创建一个子进程。 子进程将数据集写入到一个临时快照文件中。 当子进程完成对新快照文件的写入时，Redis 用新快照文件替换原来的快照文件，并删除旧的快照文件。 这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益。 快照的优点 它保存了某个时间点的数据集，非常适用于数据集的备份。 很方便传送到另一个远端数据中心或者亚马逊的 S3（可能加密），非常适用于灾难恢复。 快照在保存 RDB 文件时父进程唯一需要做的就是 fork 出一个子进程，接下来的工作全部由子进程来做，父进程不需要再做其他 IO 操作，所以快照持久化方式可以最大化 redis 的性能。 与 AOF 相比，在恢复大的数据集的时候，DB 方式会更快一些。 快照的缺点 如果你希望在 redis 意外停止工作（例如电源中断）的情况下丢失的数据最少的话，那么快照不适合你。 快照需要经常 fork 子进程来保存数据集到硬盘上。当数据集比较大的时候，fork 的过程是非常耗时的，可能会导致 Redis 在一些毫秒级内不能响应客户端的请求。 AOF AOF 持久化方式记录每次对服务器执行的写操作。当服务器重启的时候会重新执行这些命令来恢复原始的数据。 AOF 的原理 Redis 创建一个子进程。 子进程开始将新 AOF 文件的内容写入到临时文件。 对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾，这样样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。 当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。 搞定！现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。 AOF 的优点 使用默认的每秒 fsync 策略，Redis 的性能依然很好(fsync 是由后台线程进行处理的,主线程会尽力处理客户端请求)，一旦出现故障，使用 AOF ，你最多丢失 1 秒的数据。 AOF 文件是一个只进行追加的日志文件，所以不需要写入 seek，即使由于某些原因(磁盘空间已满，写的过程中宕机等等)未执行完整的写入命令，你也也可使用 redis-check-aof 工具修复这些问题。 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写：重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。整个重写操作是绝对安全的。 AOF 文件有序地保存了对数据库执行的所有写入操作，这些写入操作以 Redis 协议的格式保存。因此 AOF 文件的内容非常容易被人读懂，对文件进行分析（parse）也很轻松。 AOF 的缺点 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。 根据所使用的 fsync 策略，AOF 的速度可能会慢于快照。在一般情况下，每秒 fsync 的性能依然非常高，而关闭 fsync 可以让 AOF 的速度和快照一样快，即使在高负荷之下也是如此。不过在处理巨大的写入载入时，快照可以提供更有保证的最大延迟时间（latency）。 1.7. Redis 过期策略有哪些？ noeviction - 当内存使用达到阈值的时候，所有引起申请内存的命令会报错。 allkeys-lru - 在主键空间中，优先移除最近未使用的 key。 allkeys-random - 在主键空间中，随机移除某个 key。 volatile-lru - 在设置了过期时间的键空间中，优先移除最近未使用的 key。 volatile-random - 在设置了过期时间的键空间中，随机移除某个 key。 volatile-ttl - 在设置了过期时间的键空间中，具有更早过期时间的 key 优先移除。 1.8. Redis 和 Memcached 有什么区别？ 两者都是非关系型内存键值数据库。有以下主要不同： 数据类型 Memcached 仅支持字符串类型； 而 Redis 支持五种不同种类的数据类型，使得它可以更灵活地解决问题。 数据持久化 Memcached 不支持持久化； Redis 支持两种持久化策略：RDB 快照和 AOF 日志。 分布式 Memcached 不支持分布式，只能通过在客户端使用像一致性哈希这样的分布式算法来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。 Redis Cluster 实现了分布式的支持。 内存管理机制 Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题，但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘。而 Memcached 的数据则会一直在内存中。 1.9. 为什么单线程的 Redis 性能反而优于多线程的 Memcached？ Redis 快速的原因： 绝大部分请求是纯粹的内存操作（非常快速） 采用单线程,避免了不必要的上下文切换和竞争条件 非阻塞 IO 内部实现采用 epoll，采用了 epoll+自己实现的简单的事件框架。epoll 中的读、写、关闭、连接都转化成了事件，然后利用 epoll 的多路复用特性，绝不在 io 上浪费一点时间。 2. 分布式消息队列（MQ） 2.1. 为什么使用 MQ？ 异步处理 - 相比于传统的串行、并行方式，提高了系统吞吐量。 应用解耦 - 系统间通过消息通信，不用关心其他系统的处理。 流量削锋 - 可以通过消息队列长度控制请求量；可以缓解短时间内的高并发请求。 日志处理 - 解决大量日志传输。 消息通讯 - 消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。 2.2. 如何保证 MQ 的高可用？ 数据复制 将所有 Broker 和待分配的 Partition 排序 将第 i 个 Partition 分配到第（i mod n）个 Broker 上 将第 i 个 Partition 的第 j 个 Replica 分配到第（(i + j) mode n）个 Broker 上 选举主服务器 2.3. MQ 有哪些常见问题？如何解决这些问题？ MQ 的常见问题有： 消息的顺序问题 消息的重复问题 消息的顺序问题 消息有序指的是可以按照消息的发送顺序来消费。 假如生产者产生了 2 条消息：M1、M2，假定 M1 发送到 S1，M2 发送到 S2，如果要保证 M1 先于 M2 被消费，怎么做？ 解决方案： （1）保证生产者 - MQServer - 消费者是一对一对一的关系 缺陷： 并行度就会成为消息系统的瓶颈（吞吐量不够） 更多的异常处理，比如：只要消费端出现问题，就会导致整个处理流程阻塞，我们不得不花费更多的精力来解决阻塞的问题。 （2）通过合理的设计或者将问题分解来规避。 不关注乱序的应用实际大量存在 队列无序并不意味着消息无序 所以从业务层面来保证消息的顺序而不仅仅是依赖于消息系统，是一种更合理的方式。 消息的重复问题 造成消息重复的根本原因是：网络不可达。 所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？ 消费端处理消息的业务逻辑保持幂等性。只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。 保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现。利用一张日志表来记录已经处理成功的消息的 ID，如果新到的消息 ID 已经在日志表中，那么就不再处理这条消息。 2.4. Kafka, ActiveMQ, RabbitMQ, RocketMQ 各有什么优缺点？ 3. 分布式服务（RPC） 3.1. Dubbo 的实现过程？ 节点角色： 节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 服务运行容器 调用关系： 务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 3.2. Dubbo 负载均衡策略有哪些？ Random 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin 轮循，按公约后的权重设置轮循比率。 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActive 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash 一致性 Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 算法参见：http://en.wikipedia.org/wiki/Consistent_hashing 缺省只对第一个参数 Hash，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.arguments&quot; value=&quot;0,1&quot; /&gt; 缺省用 160 份虚拟节点，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.nodes&quot; value=&quot;320&quot; /&gt; 3.3. Dubbo 集群容错策略 ？ Failover - 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=“2” 来设置重试次数(不含第一次)。 Failfast - 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe - 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback - 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking - 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=“2” 来设置最大并行数。 Broadcast - 播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。 3.4. 动态代理策略？ Dubbo 作为 RPC 框架，首先要完成的就是跨系统，跨网络的服务调用。消费方与提供方遵循统一的接口定义，消费方调用接口时，Dubbo 将其转换成统一格式的数据结构，通过网络传输，提供方根据规则找到接口实现，通过反射完成调用。也就是说，消费方获取的是对远程服务的一个代理(Proxy)，而提供方因为要支持不同的接口实现，需要一个包装层(Wrapper)。调用的过程大概是这样： 消费方的 Proxy 和提供方的 Wrapper 得以让 Dubbo 构建出复杂、统一的体系。而这种动态代理与包装也是通过基于 SPI 的插件方式实现的，它的接口就是ProxyFactory。 @SPI("javassist")public interface ProxyFactory &#123; @Adaptive(&#123;Constants.PROXY_KEY&#125;) &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException; @Adaptive(&#123;Constants.PROXY_KEY&#125;) &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) throws RpcException;&#125; ProxyFactory 有两种实现方式，一种是基于 JDK 的代理实现，一种是基于 javassist 的实现。ProxyFactory 接口上定义了@SPI(“javassist”)，默认为 javassist 的实现。 3.5. Dubbo 支持哪些序列化协议？Hessian？Hessian 的数据结构？ dubbo 序列化，阿里尚不成熟的 java 序列化实现。 hessian2 序列化：hessian 是一种跨语言的高效二进制的序列化方式，但这里实际不是原生的 hessian2 序列化，而是阿里修改过的 hessian lite，它是 dubbo RPC 默认启用的序列化方式。 json 序列化：目前有两种实现，一种是采用的阿里的 fastjson 库，另一种是采用 dubbo 中自已实现的简单 json 库，一般情况下，json 这种文本序列化性能不如二进制序列化。 java 序列化：主要是采用 JDK 自带的 java 序列化实现，性能很不理想。 Kryo 和 FST：Kryo 和 FST 的性能依然普遍优于 hessian 和 dubbo 序列化。 Hessian 序列化与 Java 默认的序列化区别？ Hessian 是一个轻量级的 remoting on http 工具，采用的是 Binary RPC 协议，所以它很适合于发送二进制数据，同时又具有防火墙穿透能力。 Hessian 支持跨语言串行 比 java 序列化具有更好的性能和易用性 支持的语言比较多 3.6. Protoco Buffer 是什么？ Protocol Buffer 是 Google 出品的一种轻量 &amp; 高效的结构化数据存储格式，性能比 Json、XML 真的强！太！多！ Protocol Buffer 的序列化 &amp; 反序列化简单 &amp; 速度快的原因是： 编码 / 解码 方式简单（只需要简单的数学运算 = 位移等等） 采用 Protocol Buffer 自身的框架代码 和 编译器 共同完成 Protocol Buffer 的数据压缩效果好（即序列化后的数据量体积小）的原因是： 采用了独特的编码方式，如 Varint、Zigzag 编码方式等等 采用 T - L - V 的数据存储方式：减少了分隔符的使用 &amp; 数据存储得紧凑 3.7. 注册中心挂了可以继续通信吗？ 可以。Dubbo 消费者在应用启动时会从注册中心拉取已注册的生产者的地址接口，并缓存在本地。每次调用时，按照本地存储的地址进行调用。 3.8. ZooKeeper 原理是什么？ZooKeeper 有什么用？ ZooKeeper 是一个分布式应用协调系统，已经用到了许多分布式项目中，用来完成统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等工作。 每个 Server 在内存中存储了一份数据； Zookeeper 启动时，将从实例中选举一个 leader（Paxos 协议）； Leader 负责处理数据更新等操作（Zab 协议）； 一个更新操作成功，当且仅当大多数 Server 在内存中成功修改数据。 3.9. Netty 有什么用？NIO/BIO/AIO 有什么用？有什么区别？ Netty 是一个“网络通讯框架”。 Netty 进行事件处理的流程。Channel是连接的通道，是 ChannelEvent 的产生者，而ChannelPipeline可以理解为 ChannelHandler 的集合。 参考：https://github.com/code4craft/netty-learning/blob/master/posts/ch1-overview.md IO 的方式通常分为几种： 同步阻塞的 BIO 同步非阻塞的 NIO 异步非阻塞的 AIO 在使用同步 I/O 的网络应用中，如果要同时处理多个客户端请求，或是在客户端要同时和多个服务器进行通讯，就必须使用多线程来处理。 NIO 基于 Reactor，当 socket 有流可读或可写入 socket 时，操作系统会相应的通知引用程序进行处理，应用再将流读取到缓冲区或写入操作系统。也就是说，这个时候，已经不是一个连接就要对应一个处理线程了，而是有效的请求，对应一个线程，当连接没有数据时，是没有工作线程来处理的。 与 NIO 不同，当进行读写操作时，只须直接调用 API 的 read 或 write 方法即可。这两种方法均为异步的，对于读操作而言，当有流可读取时，操作系统会将可读的流传入 read 方法的缓冲区，并通知应用程序；对于写操作而言，当操作系统将 write 方法传递的流写入完毕时，操作系统主动通知应用程序。 即可以理解为，read/write 方法都是异步的，完成后会主动调用回调函数。 参考：https://blog.csdn.net/skiof007/article/details/52873421 3.10. 为什么要进行系统拆分？拆分不用 Dubbo 可以吗？ 系统拆分从资源角度分为：应用拆分和数据库拆分。 从采用的先后顺序可分为：水平扩展、垂直拆分、业务拆分、水平拆分。 是否使用服务依据实际业务场景来决定。 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。 当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键。 3.11. Dubbo 和 Thrift 有什么区别？ Thrift 是跨语言的 RPC 框架。 Dubbo 支持服务治理，而 Thrift 不支持。]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
        <tag>distributed</tag>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2Fblog%2F2019%2F10%2F25%2Fbigdata%2FREADME%2F</url>
    <content type="text"><![CDATA[大数据 📝 知识点 MapReduce HDFS YARN HBase HBase 命令 HBase 配置 📚 学习资源 书 Hadoop 权威指南 🚪 传送门 | 回首頁 |]]></content>
      <tags>
        <tag>hide</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式存储]]></title>
    <url>%2Fblog%2F2019%2F08%2F21%2Fdesign%2Fdistributed%2Fdistributed-storage%2F</url>
    <content type="text"><![CDATA[分布式存储 分区规则 分布式数据库 首先要解决把 整个数据集 按照 分区规则 映射到 多个节点 的问题，即把 数据集 划分到 多个节点 上，每个节点负责 整体数据 的一个 子集。 数据分布通常有 哈希分区 和 顺序分区 两种方式，对比如下： 分区方式 特点 相关产品 哈希分区 离散程度好，数据分布与业务无关，无法顺序访问 Redis Cluster，Cassandra，Dynamo 顺序分区 离散程度易倾斜，数据分布与业务相关，可以顺序访问 BigTable，HBase，Hypertable 由于 Redis Cluster 采用 哈希分区规则，这里重点讨论 哈希分区。常见的 哈希分区 规则有几种，下面分别介绍： 节点取余分区 使用特定的数据，如 Redis 的 键 或 用户 ID，再根据 节点数量 N 使用公式：hash（key）% N 计算出 哈希值，用来决定数据 映射 到哪一个节点上。 优点 这种方式的突出优点是 简单性，常用于 数据库 的 分库分表规则。一般采用 预分区 的方式，提前根据 数据量 规划好 分区数，比如划分为 512 或 1024 张表，保证可支撑未来一段时间的 数据容量，再根据 负载情况 将 表 迁移到其他 数据库 中。扩容时通常采用 翻倍扩容，避免 数据映射 全部被 打乱，导致 全量迁移 的情况。 缺点 当 节点数量 变化时，如 扩容 或 收缩 节点，数据节点 映射关系 需要重新计算，会导致数据的 重新迁移。 一致性哈希分区 一致性哈希 可以很好的解决 稳定性问题，可以将所有的 存储节点 排列在 首尾相接 的 Hash 环上，每个 key 在计算 Hash 后会 顺时针 找到 临接 的 存储节点 存放。而当有节点 加入 或 退出 时，仅影响该节点在 Hash 环上 顺时针相邻 的 后续节点。 优点 加入 和 删除 节点只影响 哈希环 中 顺时针方向 的 相邻的节点，对其他节点无影响。 缺点 加减节点 会造成 哈希环 中部分数据 无法命中。当使用 少量节点 时，节点变化 将大范围影响 哈希环 中 数据映射，不适合 少量数据节点 的分布式方案。普通 的 一致性哈希分区 在增减节点时需要 增加一倍 或 减去一半 节点才能保证 数据 和 负载的均衡。 注意：因为 一致性哈希分区 的这些缺点，一些分布式系统采用 虚拟槽 对 一致性哈希 进行改进，比如 Dynamo 系统。 虚拟槽分区 虚拟槽分区 巧妙地使用了 哈希空间，使用 分散度良好 的 哈希函数 把所有数据 映射 到一个 固定范围 的 整数集合 中，整数定义为 槽（slot）。这个范围一般 远远大于 节点数，比如 Redis Cluster 槽范围是 0 ~ 16383。槽 是集群内 数据管理 和 迁移 的 基本单位。采用 大范围槽 的主要目的是为了方便 数据拆分 和 集群扩展。每个节点会负责 一定数量的槽，如图所示： 当前集群有 `3` 个节点，每个节点平均大约负责 `5460` 个 **槽**。由于采用 **高质量** 的 **哈希算法**，每个槽所映射的数据通常比较 **均匀**，将数据平均划分到 `3` 个节点进行 **数据分区**。`Redis Cluster` 就是采用 **虚拟槽分区**。 集群中的每个节点负责一部分哈希槽，比如集群中有３个节点，则： 节点Ａ存储的哈希槽范围是：0 – 5460 节点Ｂ存储的哈希槽范围是：5461 – 10922 节点Ｃ存储的哈希槽范围是：10923 – 16383 这种结构很容易 添加 或者 删除 节点。如果 增加 一个节点 4，就需要从节点 1 ~ 3 获得部分 槽 分配到节点 4 上。如果想 移除 节点 1，需要将节点 1 中的 槽 移到节点 2 ~ 3 上，然后将 没有任何槽 的节点 1 从集群中 移除 即可。 由于从一个节点将 哈希槽 移动到另一个节点并不会 停止服务，所以无论 添加删除 或者 改变 某个节点的 哈希槽的数量 都不会造成 集群不可用 的状态. 参考资料 深入剖析 Redis 系列(三) - Redis 集群模式搭建与原理详解]]></content>
      <categories>
        <category>design</category>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库教程]]></title>
    <url>%2Fblog%2F2019%2F08%2F19%2Fdatabase%2F</url>
    <content type="text"><![CDATA[数据库教程 🔢 数据库经验总结 🔁 项目同步维护：Github | Gitee 📖 电子书阅读：Github Pages | Gitee Pages]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 教程]]></title>
    <url>%2Fblog%2F2019%2F08%2F19%2Flinux%2F</url>
    <content type="text"><![CDATA[Linux 教程 🔁 项目同步维护在 github | gitee 📖 电子书 | 电子书（国内）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端教程]]></title>
    <url>%2Fblog%2F2019%2F08%2F19%2Ffrontend%2F</url>
    <content type="text"><![CDATA[Frontend Tutorial ☕ frontend-tutorial 是对 Java 核心技术的经验总结。 🔁 项目同步维护：Github | Gitee 📖 电子书阅读：Github Pages | Gitee Pages]]></content>
      <categories>
        <category>frontend</category>
      </categories>
      <tags>
        <tag>frontend</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 教程]]></title>
    <url>%2Fblog%2F2019%2F08%2F19%2Fjava%2F</url>
    <content type="text"><![CDATA[Java 教程 ☕ Java Tutorial 是本人在 Java 技术领域的十年积累。 🔁 项目同步维护：Github | Gitee 📖 电子书阅读：Github Pages | Gitee Pages]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式 ID]]></title>
    <url>%2Fblog%2F2019%2F07%2F24%2Fdesign%2Fdistributed%2Fdistributed-id%2F</url>
    <content type="text"><![CDATA[分布式 ID UUID UUID 是通用唯一识别码（Universally Unique Identifier)的缩写，开放软件基金会(OSF)规范定义了包括网卡 MAC 地址、时间戳、名字空间（Namespace）、随机或伪随机数、时序等元素。利用这些元素来生成 UUID。 UUID 是由 128 位二进制组成，一般转换成十六进制，然后用 String 表示。在 java 中有个 UUID 类,在他的注释中我们看见这里有 4 种不同的 UUID 的生成策略: random - 基于随机数生成 UUID，由于 Java 中的随机数是伪随机数，其重复的概率是可以被计算出来的。这个一般我们用下面的代码获取基于随机数的 UUID: String id = UUID.randomUUID().toString(); time-based - 基于时间的 UUID,这个一般是通过当前时间，随机数，和本地 Mac 地址来计算出来，自带的 JDK 包并没有这个算法的我们在一些 UUIDUtil 中，比如我们的 log4j.core.util，会重新定义 UUID 的高位和低位。 public static UUID getTimeBasedUuid() &#123; long time = System.currentTimeMillis() * 10000L + 122192928000000000L + (long)(COUNT.incrementAndGet() % 10000); long timeLow = (time &amp; 4294967295L) &lt;&lt; 32; long timeMid = (time &amp; 281470681743360L) &gt;&gt; 16; long timeHi = (time &amp; 1152640029630136320L) &gt;&gt; 48; long most = timeLow | timeMid | 4096L | timeHi; return new UUID(most, LEAST);&#125; DCE security - DCE 安全的 UUID。 name-based - 基于名字的 UUID，通过计算名字和名字空间的 MD5 来计算 UUID。 UUID 的优点: 通过本地生成，没有经过网络 I/O，性能较快 UUID 的缺点: 长度过长 - UUID 太长，16 字节 128 位，通常以 36 长度的字符串表示，很多场景不适用。例如：Mysql 官方明确建议主键越短越好，36 个字符长度的 UUID 不符合要求。 信息不安全 - 基于 MAC 地址生成 UUID 的算法可能会造成 MAC 地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。 无序性 - 不能生成递增有序的数字。这对于一些特定场景不利。例如：如果作为数据库主键，在 InnoDB 引擎下，UUID 的无序性可能会引起数据位置频繁变动，严重影响性能。 适用场景：UUID 的适用场景可以为不需要担心过多的空间占用，以及不需要生成有递增趋势的数字。在 Log4j 里 UuidPatternConverter 中加入了 UUID 来标识每一条日志。 数据库主键自增 大家对于唯一标识最容易想到的就是主键自增，这个也是我们最常用的方法。例如我们有个订单服务，那么把订单 id 设置为主键自增即可。 优点: 简单方便，有序递增，方便排序和分页 缺点: 分库分表会带来问题，需要进行改造。 并发性能不高，受限于数据库的性能。 简单递增容易被其他人猜测利用，比如你有一个用户服务用的递增，那么其他人可以根据分析注册的用户 ID 来得到当天你的服务有多少人注册，从而就能猜测出你这个服务当前的一个大概状况。 数据库宕机服务不可用。 适用场景: 根据上面可以总结出来，当数据量不多，并发性能不高的时候这个很适合，比如一些 to B 的业务，商家注册这些，商家注册和用户注册不是一个数量级的，所以可以数据库主键递增。如果对顺序递增强依赖，那么也可以使用数据库主键自增。 Redis 熟悉 Redis 的同学，应该知道在 Redis 中有两个命令 Incr，IncrBy,因为 Redis 是单线程的所以能保证原子性。 优点： 性能比数据库好，能满足有序递增。 缺点： 由于 redis 是内存的 KV 数据库，即使有 AOF 和 RDB，但是依然会存在数据丢失，有可能会造成 ID 重复。 依赖于 redis，redis 要是不稳定，会影响 ID 生成。 适用：由于其性能比数据库好，但是有可能会出现 ID 重复和不稳定，这一块如果可以接受那么就可以使用。也适用于到了某个时间，比如每天都刷新 ID，那么这个 ID 就需要重置，通过(Incr Today)，每天都会从 0 开始加。 Zookeeper 利用 ZK 的 Znode 数据版本如下面的代码，每次都不获取期望版本号也就是每次都会成功，那么每次都会返回最新的版本号: Zookeeper 这个方案用得较少，严重依赖 Zookeeper 集群，并且性能不是很高，所以不予推荐。 数据库分段+服务缓存 ID 这个方法在美团的 Leaf 中有介绍，详情可以参考美团技术团队的发布的技术文章:Leaf——美团点评分布式 ID 生成系统,这个方案是将数据库主键自增进行优化。 biz_tag 代表每个不同的业务，max_id 代表每个业务设置的大小，step 代表每个 proxyServer 缓存的步长。 之前我们的每个服务都访问的是数据库，现在不需要，每个服务直接和我们的 ProxyServer 做交互，减少了对数据库的依赖。我们的每个 ProxyServer 回去数据库中拿出步长的长度，比如 server1 拿到了 1-1000,server2 拿到来 1001-2000。如果用完会再次去数据库中拿。 优点: 比主键递增性能高，能保证趋势递增。 如果 DB 宕机，proxServer 由于有缓存依然可以坚持一段时间。 缺点: 和主键递增一样，容易被人猜测。 DB 宕机，虽然能支撑一段时间但是仍然会造成系统不可用。 适用场景:需要趋势递增，并且 ID 大小可控制的，可以使用这套方案。 当然这个方案也可以通过一些手段避免被人猜测，把 ID 变成是无序的，比如把我们生成的数据是一个递增的 long 型，把这个 Long 分成几个部分，比如可以分成几组三位数，几组四位数，然后在建立一个映射表，将我们的数据变成无序。 雪花算法-Snowflake 算法原理： Snowflake 是 Twitter 提出来的一个算法，其目的是生成一个 64bit 的整数: 1bit:一般是符号位，不做处理 41bit:用来记录时间戳，这里可以记录 69 年，如果设置好起始时间比如今年是 2018 年，那么可以用到 2089 年，到时候怎么办？要是这个系统能用 69 年，我相信这个系统早都重构了好多次了。 10bit:10bit 用来记录机器 ID，总共可以记录 1024 台机器，一般用前 5 位代表数据中心，后面 5 位是某个数据中心的机器 ID 12bit:循环位，用来对同一个毫秒之内产生不同的 ID，12 位可以最多记录 4095 个，也就是在同一个机器同一毫秒最多记录 4095 个，多余的需要进行等待下毫秒。 上面只是一个将 64bit 划分的标准，当然也不一定这么做，可以根据不同业务的具体场景来划分，比如下面给出一个业务场景： 服务目前 QPS10 万，预计几年之内会发展到百万。 当前机器三地部署，上海，北京，深圳都有。 当前机器 10 台左右，预计未来会增加至百台。 这个时候我们根据上面的场景可以再次合理的划分 62bit,QPS 几年之内会发展到百万，那么每毫秒就是千级的请求，目前 10 台机器那么每台机器承担百级的请求，为了保证扩展，后面的循环位可以限制到 1024，也就是 2^10，那么循环位 10 位就足够了。 机器三地部署我们可以用 3bit 总共 8 来表示机房位置，当前的机器 10 台，为了保证扩展到百台那么可以用 7bit 128 来表示，时间位依然是 41bit,那么还剩下 64-10-3-7-41-1 = 2bit,还剩下 2bit 可以用来进行扩展。 适用场景:当我们需要无序不能被猜测的 ID，并且需要一定高性能，且需要 long 型，那么就可以使用我们雪花算法。比如常见的订单 ID，用雪花算法别人就无法猜测你每天的订单量是多少。 优点： 毫秒数在高位，自增序列在低位，整个 ID 都是趋势递增的。 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成 ID 的性能也是非常高的。 可以根据自身业务特性分配 bit 位，非常灵活。 缺点： 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。 一个简单的 Snowflake public static class DistributedId &#123; private long workerId; // 这个就是代表了机器id private long datacenterId; // 这个就是代表了机房id private long sequence; // 这个就是代表了一毫秒内生成的多个id的最新序号 public DistributedId(long workerId, long datacenterId, long sequence) &#123; // sanity check for workerId // 这儿就不检查了，要求就是你传递进来的机房id和机器id不能超过32，不能小于0 if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException( String.format("worker Id can't be greater than %d or less than 0", maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException( String.format("datacenter Id can't be greater than %d or less than 0", maxDatacenterId)); &#125; this.workerId = workerId; this.datacenterId = datacenterId; this.sequence = sequence; &#125; private long twepoch = 1288834974657L; private long workerIdBits = 5L; private long datacenterIdBits = 5L; // 这个是二进制运算，就是5 bit最多只能有31个数字，也就是说机器id最多只能是32以内 private long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); // 这个是一个意思，就是5 bit最多只能有31个数字，机房id最多只能是32以内 private long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); private long sequenceBits = 12L; private long workerIdShift = sequenceBits; private long datacenterIdShift = sequenceBits + workerIdBits; private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; private long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); private long lastTimestamp = -1L; public long getWorkerId() &#123; return workerId; &#125; public long getDatacenterId() &#123; return datacenterId; &#125; public long getTimestamp() &#123; return System.currentTimeMillis(); &#125; // 这个是核心方法，通过调用nextId()方法，让当前这台机器上的snowflake算法程序生成一个全局唯一的id public synchronized long nextId() &#123; // 这儿就是获取当前时间戳，单位是毫秒 long timestamp = timeGen(); if (timestamp &lt; lastTimestamp) &#123; System.err.printf("clock is moving backwards. Rejecting requests until %d.", lastTimestamp); throw new RuntimeException( String.format("Clock moved backwards. Refusing to generate id for %d milliseconds", lastTimestamp - timestamp)); &#125; // 下面是说假设在同一个毫秒内，又发送了一个请求生成一个id // 这个时候就得把seqence序号给递增1，最多就是4096 if (lastTimestamp == timestamp) &#123; // 这个意思是说一个毫秒内最多只能有4096个数字，无论你传递多少进来， //这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围 sequence = (sequence + 1) &amp; sequenceMask; if (sequence == 0) &#123; timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123; sequence = 0; &#125; // 这儿记录一下最近一次生成id的时间戳，单位是毫秒 lastTimestamp = timestamp; // 这儿就是最核心的二进制位运算操作，生成一个64bit的id // 先将当前时间戳左移，放到41 bit那儿；将机房id左移放到5 bit那儿；将机器id左移放到5 bit那儿；将序号放最后12 bit // 最后拼接起来成一个64 bit的二进制数字，转换成10进制就是个long型 return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift) | (workerId &lt;&lt; workerIdShift) | sequence; &#125; private long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; private long timeGen() &#123; return System.currentTimeMillis(); &#125;&#125; 上面定义了雪花算法的实现，在 nextId 中是我们生成雪花算法的关键。 防止时钟回拨 因为机器的原因会发生时间回拨，我们的雪花算法是强依赖我们的时间的，如果时间发生回拨，有可能会生成重复的 ID，在我们上面的 nextId 中我们用当前时间和上一次的时间进行判断，如果当前时间小于上一次的时间那么肯定是发生了回拨，普通的算法会直接抛出异常,这里我们可以对其进行优化,一般分为两个情况: 如果时间回拨时间较短，比如配置 5ms 以内，那么可以直接等待一定的时间，让机器的时间追上来。 如果时间的回拨时间较长，我们不能接受这么长的阻塞等待，那么又有两个策略: 直接拒绝，抛出异常，打日志，通知 RD 时钟回滚。 利用扩展位，上面我们讨论过不同业务场景位数可能用不到那么多，那么我们可以把扩展位数利用起来了，比如当这个时间回拨比较长的时候，我们可以不需要等待，直接在扩展位加 1。2 位的扩展位允许我们有 3 次大的时钟回拨，一般来说就够了，如果其超过三次我们还是选择抛出异常，打日志。 通过上面的几种策略可以比较的防护我们的时钟回拨，防止出现回拨之后大量的异常出现。下面是修改之后的代码，这里修改了时钟回拨的逻辑: 参考资料 百度分布式 ID 如果再有人问你分布式 ID，这篇文章丢给他 理解分布式 id 生成算法 SnowFlake Leaf——美团点评分布式 ID 生成系统 UUID 规范]]></content>
      <categories>
        <category>design</category>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式缓存]]></title>
    <url>%2Fblog%2F2019%2F06%2F27%2Fdesign%2Fdistributed%2Fdistributed-cache%2F</url>
    <content type="text"><![CDATA[分布式缓存 简介 使用缓存的好处： 提升数据读取速度 提升系统扩展能力，通过扩展缓存，提升系统承载能力 降低存储成本，Cache+DB 的方式可以承担原有需要多台 DB 才能承担的请求量，节省机器成本 根据业务场景，通常缓存有以下几种使用方式 懒汉式(读时触发)：写入 DB 后, 然后把相关的数据也写入 Cache 饥饿式(写时触发)：先查询 DB 里的数据, 然后把相关的数据写入 Cache 定期刷新：适合周期性的跑数据的任务，或者列表型的数据，而且不要求绝对实时性 缓存分类： 应用内缓存：如：EHCache 分布式缓存：如：Memached、Redis 问题 缓存雪崩 缓存雪崩是指：在高并发场景下，由于原有缓存失效，新缓存未到期间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库 CPU 和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。 解决方案： 用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。 还有一个简单的方案，就是将缓存失效时间分散开，不要所有缓存时间长度都设置成 5 分钟或者 10 分钟；比如我们可以在原有的失效时间基础上增加一个随机值，比如 1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 缓存失效时产生的雪崩效应，将所有请求全部放在数据库上，这样很容易就达到数据库的瓶颈，导致服务无法正常提供。尽量避免这种场景的发生。 缓存穿透 缓存穿透是指：用户查询的数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。 当在流量较大时，出现这样的情况，一直请求 DB，很容易导致服务挂掉。 解决方案： 在封装的缓存 SET 和 GET 部分增加个步骤，如果查询一个 KEY 不存在，就以这个 KEY 为前缀设定一个标识 KEY；以后再查询该 KEY 的时候，先查询标识 KEY，如果标识 KEY 存在，就返回一个协定好的非 false 或者 NULL 值，然后 APP 做相应的处理，这样缓存层就不会被穿透。当然这个验证 KEY 的失效时间不能太长。 如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，一般只有几分钟。 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。 缓存预热 缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！ 解决方案： 直接写个缓存刷新页面，上线时手工操作下； 数据量不大，可以在项目启动的时候自动进行加载； 定时刷新缓存； 缓存更新 除了缓存服务器自带的缓存失效策略之外（Redis 默认的有 6 中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种： 定时去清理过期的缓存； 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。 两者各有优劣，第一种的缺点是维护大量缓存的 key 是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。 缓存降级 当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。 降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。 参考资料 分布式缓存架构基础 阿里 P8 技术专家细究分布式缓存问题]]></content>
      <categories>
        <category>design</category>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>distributed</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务]]></title>
    <url>%2Fblog%2F2019%2F06%2F21%2Fdesign%2Fdistributed%2Fdistributed-transaction%2F</url>
    <content type="text"><![CDATA[分布式事务 分布式事务指的是事务操作跨越多个节点，并且要求满足事务的 ACID 特性。 分布式事务的实现主要有以下 5 种方案： XA 方案 TCC 方案 本地消息表 可靠消息最终一致性方案 最大努力通知方案 两阶段提交 两阶段提交（Two-phase Commit，2PC）通过引入协调者（Coordinator）来调度参与者的行为，并最终决定这些参与者是否要真正执行事务。 参考实现：https://github.com/changmingxie/tcc-transaction 运行过程 准备阶段 协调者询问参与者事务是否执行成功，参与者发回事务执行结果。 提交阶段 如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。 需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。 问题 同步阻塞 - 所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。 单点问题 - 协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响，特别是在阶段二发生故障，所有参与者会一直等待状态，无法完成其它操作。 数据不一致 - 在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。 太过保守 - 任意一个节点失败就会导致整个事务失败，没有完善的容错机制。 优缺点 优点：尽量保证了数据的强一致，适合对数据强一致要求很高的关键领域。（其实也不能 100%保证强一致 缺点：实现复杂，牺牲了可用性，对性能影响较大，不适合高并发高性能场景。 补偿事务 补偿事务（TCC），全称是：Try、Confirm、Cancel。 其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。它分为三个阶段： TCC 的。 Try 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留。 Confirm 阶段：这个阶段说的是在各个服务中执行实际的操作。 Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚） 举个例子，假设 Bob 要向 Smith 转账，思路大概是： 首先在 Try 阶段，要先调用远程接口把 Smith 和 Bob 的钱给冻结起来。 在 Confirm 阶段，执行远程调用的转账的操作，转账成功进行解冻。 如果第 2 步执行成功，那么转账成功，如果第二步执行失败，则调用远程冻结接口对应的解冻方法 (Cancel)。 优缺点： 优点：跟 2PC 比起来，实现以及流程相对简单了一些，但数据的一致性比 2PC 也要差一些。 缺点：缺点还是比较明显的，在 2,3 步中都有可能失败。TCC 属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用 TCC 不太好定义及处理。 这种方案几乎很少人使用，因为事务回滚实际上是严重依赖于自己写代码来回滚和补偿了，会造成补偿代码巨大。 但是，也有特殊的使用场景：一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，会用 TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性，保证在资金上不会出现问题。 而且最好是你的各个业务执行的时间都比较短。 但是说实话，一般尽量别这么搞，自己手写回滚逻辑，或者是补偿逻辑，实在太恶心了，那个业务代码是很难维护的。 本地消息表（异步确保） 本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性。 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到 Kafka 等消息队列（MQ）中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。 这种方案遵循 BASE 理论，采用的是最终一致性。 本地消息表利用了本地事务来实现分布式事务，并且使用了消息队列来保证最终一致性。 优缺点 优点：一种非常经典的实现，避免了分布式事务，实现了最终一致性。 缺点：消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。 MQ 事务消息 有一些第三方的 MQ 是支持事务消息的，比如 RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交。但是市面上一些主流的 MQ 都是不支持事务消息的，比如 RabbitMQ 和 Kafka 都不支持。 以阿里的 RocketMQ 中间件为例，其思路大致为： Prepared 消息，会拿到消息的地址。 执行本地事务。 通过第一阶段拿到的地址去访问消息，并修改状态。 也就是说在业务方法内要想消息队列提交两次请求，一次发送消息和一次确认消息。如果确认消息发送失败了 RocketMQ 会定期扫描消息集群中的事务消息，这时候发现了 Prepared 消息，它会向消息发送者确认，所以生产方需要实现一个 check 接口，RocketMQ 会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。 优缺点 优点：实现了最终一致性，不需要依赖本地数据库事务。 缺点：实现难度大，主流 MQ 不支持。 两阶段提交方案/XA 方案 所谓的 XA 方案，即：两阶段提交，有一个事务管理器的概念，负责协调多个数据库（资源管理器）的事务，事务管理器先问问各个数据库你准备好了吗？如果每个数据库都回复 ok，那么就正式提交事务，在各个数据库上执行操作；如果任何其中一个数据库回答不 ok，那么就回滚事务。 这种分布式事务方案，比较适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景。如果要玩儿，那么基于 Spring + JTA 就可以搞定，自己随便搜个 demo 看看就知道了。 这个方案，我们很少用，一般来说某个系统内部如果出现跨多个库的这么一个操作，是不合规的。我可以给大家介绍一下， 现在微服务，一个大的系统分成几十个甚至几百个服务。一般来说，我们的规定和规范，是要求每个服务只能操作自己对应的一个数据库。 如果你要操作别的服务对应的库，不允许直连别的服务的库，违反微服务架构的规范，你随便交叉胡乱访问，几百个服务的话，全体乱套，这样的一套服务是没法管理的，没法治理的，可能会出现数据被别人改错，自己的库被别人写挂等情况。 如果你要操作别人的服务的库，你必须是通过调用别的服务的接口来实现，绝对不允许交叉访问别人的数据库。 本地消息表 本地消息表其实是国外的 ebay 搞出来的这么一套思想。 这个大概意思是这样的： A 系统在自己本地一个事务里操作同时，插入一条数据到消息表； 接着 A 系统将这个消息发送到 MQ 中去； B 系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样保证不会重复处理消息； B 系统执行成功之后，就会更新自己本地消息表的状态以及 A 系统消息表的状态； 如果 B 系统处理失败了，那么就不会更新消息表状态，那么此时 A 系统会定时扫描自己的消息表，如果有未处理的消息，会再次发送到 MQ 中去，让 B 再次处理； 这个方案保证了最终一致性，哪怕 B 事务失败了，但是 A 会不断重发消息，直到 B 那边成功为止。 这个方案说实话最大的问题就在于严重依赖于数据库的消息表来管理事务啥的，如果是高并发场景咋办呢？咋扩展呢？所以一般确实很少用。 可靠消息最终一致性方案 这个的意思，就是干脆不要用本地的消息表了，直接基于 MQ 来实现事务。比如阿里的 RocketMQ 就支持消息事务。 大概的意思就是： A 系统先发送一个 prepared 消息到 mq，如果这个 prepared 消息发送失败那么就直接取消操作别执行了； 如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉 mq 发送确认消息，如果失败就告诉 mq 回滚消息； 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务； mq 会自动定时轮询所有 prepared 消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。 这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你举用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。 最大努力通知方案 这个方案的大致意思就是： 系统 A 本地事务执行完之后，发送个消息到 MQ； 这里会有个专门消费 MQ 的最大努力通知服务，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口； 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。 你们公司是如何处理分布式事务的？ 如果你真的被问到，可以这么说，我们某某特别严格的场景，用的是 TCC 来保证强一致性；然后其他的一些场景基于阿里的 RocketMQ 来实现分布式事务。 你找一个严格资金要求绝对不能错的场景，你可以说你是用的 TCC 方案；如果是一般的分布式事务场景，订单插入之后要调用库存服务更新库存，库存数据没有资金那么的敏感，可以用可靠消息最终一致性方案。 友情提示一下，RocketMQ 3.2.6 之前的版本，是可以按照上面的思路来的，但是之后接口做了一些改变，我这里不再赘述了。 当然如果你愿意，你可以参考可靠消息最终一致性方案来自己实现一套分布式事务，比如基于 RocketMQ 来玩儿。 参考资料 聊聊分布式事务，再说说解决方案]]></content>
      <categories>
        <category>design</category>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>distributed</tag>
        <tag>transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁]]></title>
    <url>%2Fblog%2F2019%2F06%2F04%2Fdesign%2Fdistributed%2Fdistributed-lock%2F</url>
    <content type="text"><![CDATA[分布式锁 Java 原生 API 虽然有并发锁，但并没有提供分布式锁的能力，所以针对分布式场景中的锁需要解决的方案。 分布式锁的解决方案大致有以下几种： 基于数据库实现 基于缓存（redis，memcached 等）实现 基于 Zookeeper 实现 ✅ 注：推荐基于 ZooKeeper 实现分布式锁，具体原因看完本文即可明了。 分布式锁思路 分布式锁的总体思路大同小异，仅在实现细节上有所不同。 分布式锁的主要思路如下： 互斥 - 创建锁必须是唯一的，表现形式为向数据存储服务器或容器插入一个唯一的 key，一旦有一个线程插入这个 key，其他线程就不能再插入了。 避免永远不释放锁 - 数据库分布式锁和缓存分布式锁（Redis）的思路都是引入超时机制，即成功申请锁后，超过一定时间，锁失效（删除 key），原因在于它们无法感知申请锁的客户端节点状态。而 ZooKeeper 由于其 znode 以目录、文件形式组织，天然就存在物理空间隔离，只要 znode 存在，即表示客户端节点还在工作，所以不存在这种问题。 容错（只要大部分 redis 节点创建了这把锁就可以） 数据库分布式锁 具体实现 （1）创建表 CREATE TABLE `methodLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键', `method_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的方法名', `desc` varchar(1024) NOT NULL DEFAULT '备注信息', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成', PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁定中的方法'; （2）获取锁 想要锁住某个方法时，执行以下 SQL： insert into methodLock(method_name,desc) values (‘method_name’,‘desc’) 因为我们对 method_name 做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。 成功插入则获取锁。 （3）释放锁 当方法执行完毕之后，想要释放锁的话，需要执行以下 Sql: delete from methodLock where method_name ='method_name' 问题 这把锁强依赖数据库的可用性。如果数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。 这把锁只能是非阻塞的，因为数据的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。 解决办法 单点问题可以用多数据库实例，同时塞 N 个表，N/2+1 个成功就任务锁定成功 写一个定时任务，隔一段时间清除一次过期的数据。 写一个 while 循环，不断的重试插入，直到成功。 在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。 小结 优点: 直接借助数据库，容易理解。 缺点: 会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。操作数据库需要一定的开销，性能问题需要考虑。 Redis 分布式锁 相比于用数据库来实现分布式锁，基于缓存实现的分布式锁的性能会更好一些。目前有很多成熟的分布式产品，包括 Redis、memcache、Tair 等。这里以 Redis 举例。 实现思路 这个分布式锁有 3 个重要的考量点： 互斥（只能有一个客户端获取锁） 不能死锁 容错（只要大部分 redis 节点创建了这把锁就可以） 对应的 Redis 指令如下： setnx - setnx key val：当且仅当 key 不存在时，set 一个 key 为 val 的字符串，返回 1；若 key 存在，则什么都不做，返回 0。 expire - expire key timeout：为 key 设置一个超时时间，单位为 second，超过这个时间锁会自动释放，避免死锁。 delete - delete key：删除 key 具体实现 （1）申请锁 SET resource_name my_random_value NX PX 30000 执行这个命令就 ok。 NX：表示只有 key 不存在的时候才会设置成功。（如果此时 redis 中存在这个 key，那么设置失败，返回 nil） PX 30000：意思是 30s 后锁自动释放。别人创建的时候如果发现已经有了就不能加锁了。 （2）释放锁 释放锁就是删除 key ，但是一般可以用 lua 脚本删除，判断 value 一样才删除： -- 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。if redis.call("get",KEYS[1]) == ARGV[1] then return redis.call("del",KEYS[1])else return 0end 小结 为啥要用 random_value 随机值呢？因为如果某个客户端获取到了锁，但是阻塞了很长时间才执行完，比如说超过了 30s，此时可能已经自动释放锁了，此时可能别的客户端已经获取到了这个锁，要是你这个时候直接删除 key 的话会有问题，所以得用随机值加上面的 lua 脚本来释放锁。 但是这样是肯定不行的。因为如果是普通的 redis 单实例，那就是单点故障。或者是 redis 普通主从，那 redis 主从异步复制，如果主节点挂了（key 就没有了），key 还没同步到从节点，此时从节点切换为主节点，别人就可以 set key，从而拿到锁。 RedLock 算法 这个场景是假设有一个 redis cluster，有 5 个 redis master 实例。然后执行如下步骤获取一把锁： 获取当前时间戳，单位是毫秒； 跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒； 尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点 n / 2 + 1； 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了； 要是锁建立失败了，那么就依次之前建立过的锁删除； 只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。 Redis 官方给出了以上两种基于 Redis 实现分布式锁的方法，详细说明可以查看：https://redis.io/topics/distlock 。 ZooKeeper 分布式锁 实现思路 这也是 ZooKeeper 客户端 curator 的分布式锁实现。 创建一个目录 mylock； 线程 A 想获取锁就在 mylock 目录下创建临时顺序节点； 获取 mylock 目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁； 线程 B 获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点； 线程 A 处理完，删除自己的节点，线程 B 监听到变更事件，判断自己是不是最小的节点，如果是则获得锁。 具体实现 /** * ZooKeeperSession * * @author bingo * @since 2018/11/29 * */public class ZooKeeperSession &#123; private static CountDownLatch connectedSemaphore = new CountDownLatch(1); private ZooKeeper zookeeper; private CountDownLatch latch; public ZooKeeperSession() &#123; try &#123; this.zookeeper = new ZooKeeper("192.168.31.187:2181,192.168.31.19:2181,192.168.31.227:2181", 50000, new ZooKeeperWatcher()); try &#123; connectedSemaphore.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("ZooKeeper session established......"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 获取分布式锁 * * @param productId */ public Boolean acquireDistributedLock(Long productId) &#123; String path = "/product-lock-" + productId; try &#123; zookeeper.create(path, "".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL); return true; &#125; catch (Exception e) &#123; while (true) &#123; try &#123; // 相当于是给node注册一个监听器，去看看这个监听器是否存在 Stat stat = zk.exists(path, true); if (stat != null) &#123; this.latch = new CountDownLatch(1); this.latch.await(waitTime, TimeUnit.MILLISECONDS); this.latch = null; &#125; zookeeper.create(path, "".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL); return true; &#125; catch (Exception ee) &#123; continue; &#125; &#125; &#125; return true; &#125; /** * 释放掉一个分布式锁 * * @param productId */ public void releaseDistributedLock(Long productId) &#123; String path = "/product-lock-" + productId; try &#123; zookeeper.delete(path, -1); System.out.println("release the lock for product[id=" + productId + "]......"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 建立zk session的watcher * * @author bingo * @since 2018/11/29 * */ private class ZooKeeperWatcher implements Watcher &#123; public void process(WatchedEvent event) &#123; System.out.println("Receive watched event: " + event.getState()); if (KeeperState.SyncConnected == event.getState()) &#123; connectedSemaphore.countDown(); &#125; if (this.latch != null) &#123; this.latch.countDown(); &#125; &#125; &#125; /** * 封装单例的静态内部类 * * @author bingo * @since 2018/11/29 * */ private static class Singleton &#123; private static ZooKeeperSession instance; static &#123; instance = new ZooKeeperSession(); &#125; public static ZooKeeperSession getInstance() &#123; return instance; &#125; &#125; /** * 获取单例 * * @return */ public static ZooKeeperSession getInstance() &#123; return Singleton.getInstance(); &#125; /** * 初始化单例的便捷方法 */ public static void init() &#123; getInstance(); &#125;&#125; 也可以采用另一种方式，创建临时顺序节点： 如果有一把锁，被多个人给竞争，此时多个人会排队，第一个拿到锁的人会执行，然后释放锁；后面的每个人都会去监听排在自己前面的那个人创建的 node 上，一旦某个人释放了锁，排在自己后面的人就会被 zookeeper 给通知，一旦被通知了之后，就 ok 了，自己就获取到了锁，就可以执行代码了。 public class ZooKeeperDistributedLock implements Watcher &#123; private ZooKeeper zk; private String locksRoot = "/locks"; private String productId; private String waitNode; private String lockNode; private CountDownLatch latch; private CountDownLatch connectedLatch = new CountDownLatch(1); private int sessionTimeout = 30000; public ZooKeeperDistributedLock(String productId) &#123; this.productId = productId; try &#123; String address = "192.168.31.187:2181,192.168.31.19:2181,192.168.31.227:2181"; zk = new ZooKeeper(address, sessionTimeout, this); connectedLatch.await(); &#125; catch (IOException e) &#123; throw new LockException(e); &#125; catch (KeeperException e) &#123; throw new LockException(e); &#125; catch (InterruptedException e) &#123; throw new LockException(e); &#125; &#125; public void process(WatchedEvent event) &#123; if (event.getState() == KeeperState.SyncConnected) &#123; connectedLatch.countDown(); return; &#125; if (this.latch != null) &#123; this.latch.countDown(); &#125; &#125; public void acquireDistributedLock() &#123; try &#123; if (this.tryLock()) &#123; return; &#125; else &#123; waitForLock(waitNode, sessionTimeout); &#125; &#125; catch (KeeperException e) &#123; throw new LockException(e); &#125; catch (InterruptedException e) &#123; throw new LockException(e); &#125; &#125; public boolean tryLock() &#123; try &#123; // 传入进去的locksRoot + “/” + productId // 假设productId代表了一个商品id，比如说1 // locksRoot = locks // /locks/10000000000，/locks/10000000001，/locks/10000000002 lockNode = zk.create(locksRoot + "/" + productId, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); // 看看刚创建的节点是不是最小的节点 // locks：10000000000，10000000001，10000000002 List&lt;String&gt; locks = zk.getChildren(locksRoot, false); Collections.sort(locks); if(lockNode.equals(locksRoot+"/"+ locks.get(0)))&#123; //如果是最小的节点,则表示取得锁 return true; &#125; //如果不是最小的节点，找到比自己小1的节点 int previousLockIndex = -1; for(int i = 0; i &lt; locks.size(); i++) &#123; if(lockNode.equals(locksRoot + “/” + locks.get(i))) &#123; previousLockIndex = i - 1; break; &#125; &#125; this.waitNode = locks.get(previousLockIndex); &#125; catch (KeeperException e) &#123; throw new LockException(e); &#125; catch (InterruptedException e) &#123; throw new LockException(e); &#125; return false; &#125; private boolean waitForLock(String waitNode, long waitTime) throws InterruptedException, KeeperException &#123; Stat stat = zk.exists(locksRoot + "/" + waitNode, true); if (stat != null) &#123; this.latch = new CountDownLatch(1); this.latch.await(waitTime, TimeUnit.MILLISECONDS); this.latch = null; &#125; return true; &#125; public void unlock() &#123; try &#123; // 删除/locks/10000000000节点 // 删除/locks/10000000001节点 System.out.println("unlock " + lockNode); zk.delete(lockNode, -1); lockNode = null; zk.close(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (KeeperException e) &#123; e.printStackTrace(); &#125; &#125; public class LockException extends RuntimeException &#123; private static final long serialVersionUID = 1L; public LockException(String e) &#123; super(e); &#125; public LockException(Exception e) &#123; super(e); &#125; &#125;&#125; 小结 ZooKeeper 版本的分布式锁问题相对比较来说少。 锁的占用时间限制：redis 就有占用时间限制，而 ZooKeeper 则没有，最主要的原因是 redis 目前没有办法知道已经获取锁的客户端的状态，是已经挂了呢还是正在执行耗时较长的业务逻辑。而 ZooKeeper 通过临时节点就能清晰知道，如果临时节点存在说明还在执行业务逻辑，如果临时节点不存在说明已经执行完毕释放锁或者是挂了。由此看来 redis 如果能像 ZooKeeper 一样添加一些与客户端绑定的临时键，也是一大好事。 是否单点故障：redis 本身有很多中玩法，如客户端一致性 hash，服务器端 sentinel 方案或者 cluster 方案，很难做到一种分布式锁方式能应对所有这些方案。而 ZooKeeper 只有一种玩法，多台机器的节点数据是一致的，没有 redis 的那么多的麻烦因素要考虑。 总体上来说 ZooKeeper 实现分布式锁更加的简单，可靠性更高。但 ZooKeeper 因为需要频繁的创建和删除节点，性能上不如 Redis 方式。 分布式锁方案对比 数据库分布式锁，问题比较多，解决起来比较麻烦，不推荐 redis 分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能。 zk 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。 另外一点就是，如果是 redis 获取锁的那个客户端出现 bug 挂了，那么只能等待超时时间之后才能释放锁；而 zk 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁。 总体上来说，ZooKeeper 实现分布式锁更加的简单，可靠性更高。 参考资料 分布式锁实现汇总]]></content>
      <categories>
        <category>design</category>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>distributed</tag>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式会话]]></title>
    <url>%2Fblog%2F2019%2F06%2F04%2Fdesign%2Fdistributed%2Fdistributed-session%2F</url>
    <content type="text"><![CDATA[分布式会话 概念 什么是 Session？ session 是啥？浏览器有个 cookie，在一段时间内这个 cookie 都存在，然后每次发请求过来都带上一个特殊的 jsessionid cookie，就根据这个东西，在服务端可以维护一个对应的 session 域，里面可以放点数据。 一般的话只要你没关掉浏览器，cookie 还在，那么对应的那个 session 就在，但是如果 cookie 没了，session 也就没了。常见于什么购物车之类的东西，还有登录状态保存之类的。 什么是分布式 Session？ 在分布式场景下，一个用户的 Session 如果只存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器上，该服务器没有用户的 Session，就可能导致用户需要重新进行登录等操作。 分布式 Session 的几种实现策略： 粘性 session 应用服务器间的 session 复制共享 基于缓存的 session 共享 ✅ 推荐：基于缓存的 session 共享 粘性 Session 粘性 Session（Sticky Sessions）需要配置负载均衡器，使得一个用户的所有请求都路由到一个服务器节点上，这样就可以把用户的 Session 存放在该服务器节点中。 缺点：当服务器节点宕机时，将丢失该服务器节点上的所有 Session。 session 复制共享 Session 复制共享（Session Replication）在服务器节点之间进行 Session 同步操作，这样的话用户可以访问任何一个服务器节点。 缺点：占用过多内存；同步过程占用网络带宽以及服务器处理器时间。 基于缓存的 session 共享 使用一个单独的存储服务器存储 Session 数据，可以存在 MySQL 数据库上，也可以存在 Redis 或者 Memcached 这种内存型数据库。 缺点：需要去实现存取 Session 的代码。 具体实现 JWT Token 使用 JWT Token 储存用户身份，然后再从数据库或者 cache 中获取其他的信息。这样无论请求分配到哪个服务器都无所谓。 tomcat + redis 这个其实还挺方便的，就是使用 session 的代码，跟以前一样，还是基于 tomcat 原生的 session 支持即可，然后就是用一个叫做 Tomcat RedisSessionManager 的东西，让所有我们部署的 tomcat 都将 session 数据存储到 redis 即可。 在 tomcat 的配置文件中配置： &lt;Valve className="com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve" /&gt;&lt;Manager className="com.orangefunction.tomcat.redissessions.RedisSessionManager" host="&#123;redis.host&#125;" port="&#123;redis.port&#125;" database="&#123;redis.dbnum&#125;" maxInactiveInterval="60"/&gt; 然后指定 redis 的 host 和 port 就 ok 了。 &lt;Valve className="com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve" /&gt;&lt;Manager className="com.orangefunction.tomcat.redissessions.RedisSessionManager" sentinelMaster="mymaster" sentinels="&lt;sentinel1-ip&gt;:26379,&lt;sentinel2-ip&gt;:26379,&lt;sentinel3-ip&gt;:26379" maxInactiveInterval="60"/&gt; 还可以用上面这种方式基于 redis 哨兵支持的 redis 高可用集群来保存 session 数据，都是 ok 的。 spring session + redis 上面那种 tomcat + redis 的方式好用，但是会严重依赖于 web 容器，不好将代码移植到其他 web 容器上去，尤其是你要是换了技术栈咋整？比如换成了 spring cloud 或者是 spring boot 之类的呢？ 所以现在比较好的还是基于 Java 一站式解决方案，也就是 spring。人家 spring 基本上承包了大部分我们需要使用的框架，spirng cloud 做微服务，spring boot 做脚手架，所以用 sping session 是一个很好的选择。 在 pom.xml 中配置： &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;version&gt;1.2.1.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.8.1&lt;/version&gt;&lt;/dependency&gt; 在 spring 配置文件中配置： &lt;bean id="redisHttpSessionConfiguration" class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration"&gt; &lt;property name="maxInactiveIntervalInSeconds" value="600"/&gt;&lt;/bean&gt;&lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxTotal" value="100" /&gt; &lt;property name="maxIdle" value="10" /&gt;&lt;/bean&gt;&lt;bean id="jedisConnectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory" destroy-method="destroy"&gt; &lt;property name="hostName" value="$&#123;redis_hostname&#125;"/&gt; &lt;property name="port" value="$&#123;redis_port&#125;"/&gt; &lt;property name="password" value="$&#123;redis_pwd&#125;" /&gt; &lt;property name="timeout" value="3000"/&gt; &lt;property name="usePool" value="true"/&gt; &lt;property name="poolConfig" ref="jedisPoolConfig"/&gt;&lt;/bean&gt; 在 web.xml 中配置： &lt;filter&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 示例代码： @RestController@RequestMapping("/test")public class TestController &#123; @RequestMapping("/putIntoSession") public String putIntoSession(HttpServletRequest request, String username) &#123; request.getSession().setAttribute("name", "leo"); return "ok"; &#125; @RequestMapping("/getFromSession") public String getFromSession(HttpServletRequest request, Model model)&#123; String name = request.getSession().getAttribute("name"); return name; &#125;&#125; 上面的代码就是 ok 的，给 sping session 配置基于 redis 来存储 session 数据，然后配置了一个 spring session 的过滤器，这样的话，session 相关操作都会交给 spring session 来管了。接着在代码中，就用原生的 session 操作，就是直接基于 spring sesion 从 redis 中获取数据了。 实现分布式的会话有很多种方式，我说的只不过是比较常见的几种方式，tomcat + redis 早期比较常用，但是会重耦合到 tomcat 中；近些年，通过 spring session 来实现。 参考资料 集群/分布式环境 Session 的几种策略]]></content>
      <categories>
        <category>design</category>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>distributed</tag>
        <tag>session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Title]]></title>
    <url>%2Fblog%2F2019%2F03%2F08%2Fdesign%2Farchitecture%2FREADME%2F</url>
    <content type="text"><![CDATA[架构设计 架构设计是为业务服务，脱离业务实际的架构设计都是纸上谈兵。 架构设计需要根据架构师自身的经验，在实现业务功能、性能、扩展性、系统复杂度等维度上综合考量以及权衡。而架构设计的经验需要架构师不断的学习、不断的积累。性能、扩展性、系统复杂度等方面有很多个专题，有必要针对每个专题由浅入深的去理解、掌握。 专题 如何设计 第一步：需求分析 需求分析阶段，要做的就是分析使用场景，约束和假设。 这个阶段，应该以审视的角度，不断提问、求证，以挖掘用户真实的需求。 系统是什么？系统有什么功能？ 谁是系统的用户群体？用户群体的规模是多大？ 系统的输入输出分别是什么？ 系统希望处理多少数据？ 系统希望每秒钟处理多少请求？ 系统希望的读写比率？ 第二步：概要设计 创造一个高层级的设计 第三步：详细设计 数据库选型：SQL 还是 NOSQL 数据库模型 API 和面向对象设计 第四步：扩展设计 负载均衡 水平扩展 缓存 数据库分片 消息队列 扩展阅读 参考资料 文章 系统设计入门]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase 维护]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fbigdata%2Fhbase%2Fhbase-ops%2F</url>
    <content type="text"><![CDATA[HBase 维护 配置文件 环境要求 引用和引申 引申 配置文件 backup-masters - 默认情况下不存在。列出主服务器应在其上启动备份主进程的主机，每行一个主机。 hadoop-metrics2-hbase.properties - 用于连接 HBase Hadoop 的 Metrics2 框架。 hbase-env.cmd and hbase-env.sh - 用于 Windows 和 Linux / Unix 环境的脚本，用于设置 HBase 的工作环境，包括 Java，Java 选项和其他环境变量的位置。 hbase-policy.xml - RPC 服务器用于对客户端请求进行授权决策的默认策略配置文件。仅在启用 HBase 安全性时使用。 hbase-site.xml - 主要的 HBase 配置文件。此文件指定覆盖 HBase 默认配置的配置选项。您可以在 docs / hbase-default.xml 中查看（但不要编辑）默认配置文件。您还可以在 HBase Web UI 的 HBase 配置选项卡中查看群集的整个有效配置（默认值和覆盖）。 log4j.properties - log4j 日志配置。 regionservers - 包含应在 HBase 集群中运行 RegionServer 的主机列表。默认情况下，此文件包含单个条目 localhost。它应包含主机名或 IP 地址列表，每行一个，并且如果群集中的每个节点将在其 localhost 接口上运行 RegionServer，则应仅包含 localhost。 环境要求 Java HBase 2.0+ 要求 JDK8+ HBase 1.2+ 要求 JDK7+ SSH - 环境要支持 SSH DNS - 环境中要在 hosts 配置本机 hostname 和本机 IP NTP - HBase 集群的时间要同步，可以配置统一的 NTP 平台 - 生产环境不推荐部署在 Windows 系统中 Hadoop - 依赖 Hadoop 配套版本 Zookeeper - 依赖 Zookeeper 配套版本 运行模式 单点 hbase-site.xml 配置如下： &lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://namenode.example.org:8020/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 分布式 hbase-site.xm 配置如下： &lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://namenode.example.org:8020/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node-a.example.com,node-b.example.com,node-c.example.com&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 引用和引申 扩展阅读 Apache HBase Configuration]]></content>
  </entry>
  <entry>
    <title><![CDATA[项目规范]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fmethod%2Fproject-style%2F</url>
    <content type="text"><![CDATA[项目规范 软件项目开发规范。 项目结构 目录 文件 命名规则 目录名 文件名 Java 日志规范 参考资料 项目结构 以下为项目根目录下的文件和目录的组织结构： 目录 codes - 代码目录。 configurations - 配置目录。一般存放项目相关的配置文件。如 maven 的 settings.xml，nginx 的 nginx.conf 等。 demos - 示例目录。 docs - 文档目录。 libs - 第三方库文件。 scripts - 脚本目录。一般存放用于启动、构建项目的可执行脚本文件。 packages - 打包文件目录。Java 项目中可能是 jar、war 等；前端项目中可能是 zip、rar 等；电子书项目中可能是 pdf 等。 文件 .gitignore - git 忽略规则。 .gitattributes - git 属性规则。 .editorconfig - 编辑器书写规则。 README.md - 项目说明文件。 LICENSE - 开源协议。如果项目是开源文件，需要添加。 命名规则 目录名 目录名必须使用半角字符，不得使用全角字符。这也意味着，中文不能用于文件名。 目录名建议只使用小写字母，不使用大写字母。 不佳： Test正确： test 目录名可以使用数字，但不应该是首字符。 不佳： 1-demo正确： demo1 目录名包含多个单词时，单词之间建议使用半角的连词线（-）分隔。 不佳： common_demo正确： common-demo 文件名 文档的文件名不得含有空格。 文件名必须使用半角字符，不得使用全角字符。这也意味着，中文不能用于文件名。 错误： 名词解释.md正确： glossary.md 文件名建议只使用小写字母，不使用大写字母。 错误：TroubleShooting.md正确：troubleshooting.md 为了醒目，某些说明文件的文件名，可以使用大写字母，比如README、LICENSE。 一些约定俗成的习惯可以保持传统写法，如：Java 的文件名一般使用驼峰命名法，且首字母大写；配置文件 applicationContext.xml ；React 中的 JSX 组件文件名一般使用驼峰命名法，且首字母大写等。 文件名包含多个单词时，单词之间建议使用半角的连词线（-）分隔。 不佳：advanced_usage.md正确：advanced-usage.md Java 日志规范 这里基于阿里巴巴 Java 开发手册日志规约章节，结合自己的开发经验做了一些增删和调整。 【强制】应用中不可直接使用日志系统（Log4j、Logback）中的 API，而应依赖使用日志框架 SLF4J 中的 API，使用门面模式的日志框架，有利于维护和各个类的日志处理方式统一。 import org.slf4j.Logger;import org.slf4j.LoggerFactory;private static final Logger logger = LoggerFactory.getLogger(Abc.class); 【强制】日志文件推荐至少保存 30 天，因为有些异常具备以“周”为频次发生的特点。 【强制】应用中的扩展日志（如打点、临时监控、访问日志等）命名方式：appName_logType_logName.log。logType:日志类型，推荐分类有 stats/desc/monitor/visit 等；logName:日志描述。这种命名的好处：通过文件名就可知道日志文件属于什么应用，什么类型，什么目的，也有利于归类查找。 正例：mppserver 应用中单独监控时区转换异常，如：mppserver_monitor_timeZoneConvert.log 说明：推荐对日志进行分类，如将错误日志和业务日志分开存放，便于开发人员查看，也便于通过日志对系统进行及时监控。 【强制】对 trace/debug/info 级别的日志输出，必须使用条件输出形式或者使用占位符的方式。 说明：logger.debug(&quot;Processing trade with id: &quot; + id + &quot; and symbol: &quot; + symbol); 如果日志级别是 warn，上述日志不会打印，但是会执行字符串拼接操作，如果 symbol 是对象，会执行 toString()方法，浪费了系统资源，执行了上述操作，最终日志却没有打印。 正例：（条件） if (logger.isDebugEnabled()) &#123;logger.debug("Processing trade with id: " + id + " and symbol: " + symbol);&#125; 正例：（占位符） logger.debug("Processing trade with id: &#123;&#125; and symbol : &#123;&#125; ", id, symbol); 【强制】避免重复打印日志，浪费磁盘空间。务必在 log4j.xml 或 logback.xml 中设置 additivity=false。 正例： &lt;logger name="com.taobao.dubbo.config" additivity="false"&gt; 【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过关键字 throws 往上抛出。 正例：logger.error(各类参数或者对象 toString + “_” + e.getMessage(), e); 【强制】日志格式遵循如下格式： 打印出的日志信息如： 2018-03-29 15:06:57.277 [javalib] [main] [TRACE] i.g.dunwu.javalib.log.LogbackDemo#main - 这是一条 trace 日志记录2018-03-29 15:06:57.282 [javalib] [main] [DEBUG] i.g.dunwu.javalib.log.LogbackDemo#main - 这是一条 debug 日志记录2018-03-29 15:06:57.282 [javalib] [main] [INFO] i.g.dunwu.javalib.log.LogbackDemo#main - 这是一条 info 日志记录2018-03-29 15:06:57.282 [javalib] [main] [WARN] i.g.dunwu.javalib.log.LogbackDemo#main - 这是一条 warn 日志记录2018-03-29 15:06:57.282 [javalib] [main] [ERROR] i.g.dunwu.javalib.log.LogbackDemo#main - 这是一条 error 日志记录 【参考】slf4j 支持的日志级别，按照级别从低到高，分别为：trace &lt; debug &lt; info &lt; warn &lt; error。 建议只使用 debug &lt; info &lt; warn &lt; error 四个级别。 error 日志级别只记录系统逻辑出错、异常等重要的错误信息。如非必要，请不要在此场景打出 error 级别。 warn 日志级别记录用户输入参数错误的情况，避免用户投诉时，无所适从。 info 日志级别记录业务逻辑中一些重要步骤信息。 debug 日志级别记录一些用于调试的信息。 【参考】有一些第三方框架或库的日志对于排查问题具有一定的帮助，如 Spring、Dubbo、Mybatis 等。这些框架所使用的日志库未必和本项目一样，为了避免出现日志无法输出的问题，请引入对应的桥接 jar 包。 参考资料 阿里巴巴 Java 开发手册日志规约章节]]></content>
      <categories>
        <category>method</category>
      </categories>
      <tags>
        <tag>method</tag>
        <tag>project</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目录规范]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fmethod%2Fdir-style%2F</url>
    <content type="text"><![CDATA[目录规范 1. 目录结构规范 2. 文件管理软件 2.1. Clover 2.2. Everything 2.3. Wox 2.4. Q-dir 1. 目录结构规范 作为程序员，想必每个人都会有大量的资料、数据。按照条理清晰的目录结构去分类化存储，十分有助于管理文件。 以下是我个人整理的目录结构： .├── Codes #代码目录│ ├── Other #第三方代码目录│ ├── My #个人代码目录│ └── Work #工作代码目录├── Data #数据目录├── Downloads #下载文件目录├── Docs #文档目录│ ├── Books #电子书目录│ ├── My #个人文档目录│ └── Work #工作文档目录├── Movies #视频目录├── Music #音乐目录├── Pictures #图片目录├── Public #共享目录├── Temp #临时文件目录└── Tools #工具软件目录 └── Packages #安装包目录 注：如果您使用的操作系统是 Mac 这种可以为目录或文件添加 tag 的操作系统，那么您可以根据自己的喜好更细致化的管理。 2. 文件管理软件 选用便利的文件管理软件，可以让你的文件管理如虎添翼。这里推荐几款经典的文件管理工具。 2.1. Clover Clover 是 Windows Explorer 资源管理器的一个扩展，为其增加类似谷歌 Chrome 浏览器的多标签页功能。 2.2. Everything Everything 可以立即在 windows 系统中找到制定名称的文件和文件夹。 2.3. Wox Wox 是一款简单易用的 Windows 启动器。可以把它视为 windows 版的 Alfred。 2.4. Q-dir Q-dir 是轻量的文件管理器,特点鲜明,各种布局视图切换灵活,默认四个小窗口组成一个大窗口,操作快捷。]]></content>
      <categories>
        <category>method</category>
      </categories>
      <tags>
        <tag>method</tag>
        <tag>doc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络之数据链路层]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fcommunication%2Fnetwork-data-link%2F</url>
    <content type="text"><![CDATA[计算机网络之数据链路层 数据链路层（Data Link Layer） - 网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。 主要协议：PPP、CSMA/CD 等。 数据单元：帧（frame）。 典型设备：二层交换机、网桥、网卡。 简介 基本问题 封装成帧 透明传输 差错检测 点对点信道 PPP 协议 广播信道 CSMA/CD 协议 局域网 以太网 MAC 地址 设备 适配器 集线器 网桥 以太网交换机 简介 链路是从一个节点到相邻节点的一段物理线路，数据链路则是在链路的基础上增加了一些必要的硬件（网络适配器）和软件（协议）。 数据链路层三个基本问题：封装成帧、透明传输、差错检测。 数据链路层有两种信道类型：点对点信道（主要使用 PPP）和广播信道（主要使用 CSMA/CD）。 以太网 MAC 层的地址。 适配器、转发器、集线器、网桥、以太网交换机的作用及使用场合。 基本问题 封装成帧 为网络层传下来的 IP 数据报添加首部和尾部，用于标记帧的开始和结束。 为了提高传输效率，应该让数据部分长度尽可能大于首部和尾部。但是，每种链路层协议都限制了帧的数据部分长度上线——最大传送单元 MTU（Maximum Transfer Unit） 透明传输 透明表示：某一个实际存在的事物看起来好像不存在一样。 帧使用首部和尾部进行定界，如果帧的数据部分含有和首部尾部相同的内容，那么帧的开始和结束位置就会被错误的判定。需要在数据部分出现首部尾部相同的内容前面插入转义字符。如果数据部分出现转义字符，那么就在转义字符前面再加个转义字符。在接收端进行处理之后可以还原出原始数据。这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。 差错检测 目前数据链路层广泛使用了循环冗余检验 CRC（Cyclic redundancy check）来检查比特差错。 点对点信道 点对点信道使用一对一的点对点通信方式。 对于点对点的链路，点对点协议 PPP（Point-to-Point Protocol）是使用最广泛的数据链路层协议。 PPP 协议 互联网用户通常都要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。 PPP（点到点协议）是为在同等单元之间传输数据包这样的简单链路设计的链路层协议。这种链路提供全双工操作，并按照顺序传递数据包。设计目的主要是用来通过拨号或专线方式建立点对点连接发送数据，使其成为各种主机、网桥和路由器之间简单连接的一种共通的解决方案。 PPP 的帧格式： F 字段为帧的定界符 A 和 C 字段暂时没有意义 FCS 字段是使用 CRC 的检验序列 信息部分的长度不超过 1500 广播信道 广播信道(broadcast channel)是通过广播的方式传输信息的信息通道。 所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。 主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用 CSMA/CD 协议。 CSMA/CD 协议 CSMA/CD（Carrier Sense Multiple Access with Collision Detection）即带冲突检测的载波监听多路访问技术(载波监听多点接入/碰撞检测)。 多点接入 ：说明这是总线型网络，许多计算机以多点接入的方式连接在一根总线上。 载波监听 ：每个主机都必须不停地监听信道。发送前监听，如果忙则等待，如果空闲则发送。 碰撞检测 ：即边发送边检测。若检测到信道有干扰信号，则表示产生了碰撞，于是就要停止发送数据，计算出退避等待时间，然后使用 CSMA 方法继续尝试发送。计算退避等待时间采用的是二进制指数退避算法。 局域网 局域网 LAN（Local Area Network）是指在某一区域内由多台计算机互联成的计算机组。 局域网的拓扑结构通常为总线型和环型。 局域网技术主要有：以太网、令牌环网、FDDI 网和无线局域网等。 以太网 以太网（Ethernet）是一种星型拓扑结构局域网。 以太网是目前应用最广泛的局域网。 以太网使用 CSMA/CD 协议。 MAC 地址 MAC 地址（Media Access Control Address），也称为以太网地址或物理地址，它是一个用来确认网上设备位置的地址。 MAC 地址长度为 6 字节（48 位），用于唯一标识网络适配器（网卡）。 一台主机拥有多少个网络适配器就有多少个 MAC 地址。 设备 适配器 网络适配器一般指网卡。 网卡是工作在链路层的网络组件，是局域网中连接计算机和传输介质的接口，不仅能实现与局域网传输介质之间的物理连接和电信号匹配，还涉及帧的发送与接收、帧的封装与拆封、介质访问控制、数据的编码与解码以及数据缓存的功能等。 网卡和局域网之间的通信是通过电缆或双绞线以串行传输方式进行的。而网卡和计算机之间的通信则是通过计算机主板上的 I/O 总线以并行传输方式进行。 集线器 集线器（Hub）的主要功能是对接收到的信号进行再生整形放大，以扩大网络的传输距离，同时把所有节点集中在以它为中心的节点上。 使用集线器可以在物理层扩展以太网。 网桥 网桥（Bridge）是早期的两端口二层网络设备，用来连接不同网段。网桥的两个端口分别有一条独立的交换信道，不是共享一条背板总线，可隔离冲突域。网桥比集线器（Hub）性能更好，集线器上各端口都是共享同一条背板总线的。后来，网桥被具有更多端口、同时也可隔离冲突域的交换机（Switch）所取代。 以太网交换机 以太网交换机是基于以太网传输数据的交换机，以太网采用共享总线型传输媒体方式的局域网。以太网交换机的结构是每个端口都直接与主机相连，并且一般都工作在全双工方式。交换机能同时连通许多对端口，使每一对相互通信的主机都能像独占通信媒体那样，进行无冲突地传输数据。 以太网交换机的每个端口都直接与主机相连，并且一般都工作在全双工方式。 交换机能同时连通许多对的端口，使每一对相互通信的主机都能像独占通信媒体那样，进行无冲突地传输数据。 用户独占传输媒体的带宽，若一个接口到主机的带宽是 10Mbit 每秒，那么有 10 个接口的交换机的总容量是 100Mbit 每秒。这是交换机的最大优点。]]></content>
      <categories>
        <category>communication</category>
      </categories>
      <tags>
        <tag>communication</tag>
        <tag>network</tag>
        <tag>data link</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络之应用层]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fcommunication%2Fnetwork-application%2F</url>
    <content type="text"><![CDATA[计算机网络之应用层 HTTP DNS FTP DHCP TELNET 电子邮件协议 1. SMTP 2. POP3 3. IMAP 常用端口 Web 页面请求过程 1. DHCP 配置主机信息 2. ARP 解析 MAC 地址 3. DNS 解析域名 4. HTTP 请求页面 HTTP 超文本传输协议（英语：HyperText Transfer Protocol，缩写：HTTP）是一种用于分布式、协作式和超媒体信息系统的应用层协议。HTTP 是万维网的数据通信的基础。 设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。通过 HTTP 或者 HTTPS 协议请求的资源由统一资源标识符（Uniform Resource Identifiers，URI）来标识。 安全套接字层超文本传输协议 HTTPS 为了数据传输的安全，HTTPS 在 HTTP 的基础上加入了 SSL 协议，SSL 依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。 👉 扩展阅读：HTTP DNS 域名服务器 DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。 域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。 DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传来保证可靠性。在两种情况下会使用 TCP 进行传输： 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 👉 扩展阅读：DNS FTP 文件传送协议 FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件： 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。 根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式： 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。 主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。 FTPS 是一种对常用的文件传输协议（FTP）添加传输层安全（TLS）和安全套接层（SSL）加密协议支持的扩展协议。 DHCP 动态主机配置协议 DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要去手动配置 IP 地址等信息。 DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。 DHCP 工作过程如下： 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。 DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。 DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。 TELNET 远程登录协议 TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。 TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。 电子邮件协议 一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。 邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。 1. SMTP SMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。 2. POP3 POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。 3. IMAP IMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。 常用端口 应用 应用层协议 端口号 传输层协议 备注 域名解析 DNS 53 UDP/TCP 长度超过 512 字节时使用 TCP 动态主机配置协议 DHCP 67/68 UDP 简单网络管理协议 SNMP 161/162 UDP 文件传送协议 FTP 20/21 TCP 控制连接 21，数据连接 20 远程终端协议 TELNET 23 TCP 超文本传送协议 HTTP 80 TCP 简单邮件传送协议 SMTP 25 TCP 邮件读取协议 POP3 110 TCP 网际报文存取协议 IMAP 143 TCP Web 页面请求过程 1. DHCP 配置主机信息 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。 2. ARP 解析 MAC 地址 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。 DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。 3. DNS 解析域名 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。 4. HTTP 请求页面 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。 HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。 HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。]]></content>
      <categories>
        <category>communication</category>
      </categories>
      <tags>
        <tag>communication</tag>
        <tag>network</tag>
        <tag>application</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络之物理层]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fcommunication%2Fnetwork-physical%2F</url>
    <content type="text"><![CDATA[计算机网络之物理层 摘要 物理层（Physical Layer） - 物理层只接收和发送一串比特(bit)流，不考虑信息的意义和信息结构。 数据单元：比特流。 典型设备：光纤、同轴电缆、双绞线、中继器和集线器。 通信系统模型 通信方式 通信信号 调制解调 基本带通调制方法 通信媒介 信道复用 通信系统模型 通信系统模型分为三大部分：源系统（包括信源和发送器）、传输系统、目的系统（包括信宿接收器）。 重要概念： 信源 - 也叫源点。产生各类信息的实体。 信道 - 通信的通道，是信号传输的媒介。 信宿 - 传输信息的归宿。 码元 - 在数字通信中常常用时间间隔相同的符号来表示一个二进制数字，这样的时间间隔内的信号称为(二进制）码元。 通信方式 有三种通信方式： 单工通信：单向传输 半双工通信：双向交替传输 全双工通信：双向同时传输 通信信号 通信的目的是传送消息。如语音、文字、图像、视频都是消息。数据时传送消息的实体。信号是数据的电气或电磁的表现。 模拟信号和数字信号 模拟信号 - 模拟信号是连续的信号。 数字信号 - 数字信号是离散的信号。 调制解调 重要概念： 基带信号 - 来自信源的信号叫做基带信号。 调制 - 将各种数字基带信号转换成适于信道传输的数字调制信号(已调信号或频带信号)。简单来说：调制即，数字 -&gt; 模拟。 解调 - 在接收端将收到的数字频带信号还原成数字基带信号。简单来说：解调即，模拟 -&gt; 数字。 📌 提示：我们上网时所用到的调制解调器（俗称“猫”），指的就是转换数字和模拟信号的机器。 信号要在信道上传输就要经过调制。 调制分为：基带调制和带通调制 基本带通调制方法 如果你收听过广播，一定经常听到 AM、FM 这两个关键词，这是什么意思呢？答案如下： 调幅（AM） - 即载波的振幅随基带数字信号而变化。 调频（FM） - 即载波的频率随基带数字信号而变化。 调相（PM） - 即载波的初始相位随基带数字信号而变化。 📌 提示：我们收听广播时，为了接收不同广播台的信号，就要调整 AM 或 FM，指的就是这里的调制方法。 通信媒介 通信媒介分为两大类： 导引型 - 双绞线、电缆、光纤 非导引型 - 无线、红外线、大气、激光 信道复用 信道复用就是将用于传输信道的总带宽划分成若干个子频带（或称子信道），每一个子信道传输一路信号。 频分复用 时分复用 波分复用 码分复用]]></content>
      <categories>
        <category>communication</category>
      </categories>
      <tags>
        <tag>communication</tag>
        <tag>network</tag>
        <tag>physical</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络之网络层]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fcommunication%2Fnetwork-network%2F</url>
    <content type="text"><![CDATA[计算机网络之网络层 网络层（network layer） - 为分组交换网上的不同主机提供通信服务。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组或包进行传送。 主要协议：IP、ICMP。 数据单元：IP 数据报（packet）。 典型设备：网关、路由器。 概述 IP 协议 相关协议 分类的 IP 地址 IP 地址与物理地址 IP 数据报格式 地址解析协议 ARP 网际控制报文协议 ICMP 1. Ping 2. Traceroute 虚拟专用网 VPN 网络地址转换 NAT 路由器的结构 路由器分组转发流程 路由选择协议 1. 内部网关协议 RIP 2. 内部网关协议 OSPF 3. 外部网关协议 BGP 概述 网络层向上只提供简单灵活的、无连接的、尽最大努力交付的数据报服务。网络层不提供服务质量的承诺，不保证分组交付的时限，所传送的分组可能出错、丢失、重复和失序。进程间通信的可靠性由运输层负责。 IP 协议 网际协议 IP (Internet Protocol) 定义了三种功能： IP 定义了在 TCP/IP 互联网上数据传送的基本单元和数据格式。 IP 软件完成路由选择功能，选择数据传送的路径。 IP 包含了一组不可靠分组传送的规则，指明了分组处理、差错信息发生以及分组的规则。 相关协议 与 IP 协议配套使用的还有三个协议： 地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） 分类的 IP 地址 IP 地址的编址方式经历了三个历史阶段： 分类 子网划分 无分类 1. 分类 由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。 IP 地址 ::= &#123;&lt; 网络号 &gt;, &lt; 主机号 &gt;&#125; 2. 子网划分 通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。 IP 地址 ::= &#123;&lt; 网络号 &gt;, &lt; 子网号 &gt;, &lt; 主机号 &gt;&#125; 要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。 注意，外部网络看不到子网的存在。 3. 无分类 无分类编址 CIDR 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。 IP 地址 ::= &#123;&lt; 网络前缀号 &gt;, &lt; 主机号 &gt;&#125; CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。 CIDR 的地址掩码可以继续称为子网掩码，子网掩码首 1 长度为网络前缀的长度。 一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为 构成超网 。 在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。 IP 地址与物理地址 物理地址是数据链路层和物理层使用的地址。 IP 地址是网络层和以上各层使用的地址，是一种逻辑地址。 IP 数据报格式 版本 - 有 4（IPv4）和 6（IPv6）两个值。 首部长度 - 占 4 位，因此最大十进制数值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为首部固定长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 - 用来获得更好的服务，一般情况下不使用。 总长度 - 包括首部长度和数据部分长度。占 16 位，因此数据报的最大长度为 2 16 - 1 = 65535 字节。 生存时间 - TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。 协议 - 指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。 首部检验和 - 因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。 标识 - 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。 片偏移 - 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。 地址解析协议 ARP 网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。 ARP 实现由 IP 地址得到 MAC 地址。 每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。 如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。 网际控制报文协议 ICMP ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。 ICMP 报文分为差错报告报文和询问报文。 1. Ping Ping 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。 Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。 2. Traceroute Traceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。 Traceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。 源主机向目的主机发送一连串的 IP 数据报。第一个数据报 P1 的生存时间 TTL 设置为 1，当 P1 到达路径上的第一个路由器 R1 时，R1 收下它并把 TTL 减 1，此时 TTL 等于 0，R1 就把 P1 丢弃，并向源主机发送一个 ICMP 时间超过差错报告报文； 源主机接着发送第二个数据报 P2，并把 TTL 设置为 2。P2 先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 P2，并向源主机发送一个 ICMP 时间超过差错报文。 不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把 TTL 值减 1。但是因为数据报封装的是无法交付的 UDP，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。 之后源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。 虚拟专用网 VPN 由于 IP 地址的紧缺，一个机构能申请到的 IP 地址数往往远小于本机构所拥有的主机数。并且一个机构并不需要把所有的主机接入到外部的互联网中，机构内的计算机可以使用仅在本机构有效的 IP 地址（专用地址）。 有三个专用地址块： 10.0.0.0 ~ 10.255.255.255 172.16.0.0 ~ 172.31.255.255 192.168.0.0 ~ 192.168.255.255 VPN 使用公用的互联网作为本机构各专用网之间的通信载体。专用指机构内的主机只与本机构内的其它主机通信；虚拟指好像是，而实际上并不是，它有经过公用的互联网。 下图中，场所 A 和 B 的通信经过互联网，如果场所 A 的主机 X 要和另一个场所 B 的主机 Y 通信，IP 数据报的源地址是 10.1.0.1，目的地址是 10.2.0.3。数据报先发送到与互联网相连的路由器 R1，R1 对内部数据进行加密，然后重新加上数据报的首部，源地址是路由器 R1 的全球地址 125.1.2.3，目的地址是路由器 R2 的全球地址 194.4.5.6。路由器 R2 收到数据报后将数据部分进行解密，恢复原来的数据报，此时目的地址为 10.2.0.3，就交付给 Y。 网络地址转换 NAT 专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP。 在以前，NAT 将本地 IP 和全球 IP 一一对应，这种方式下拥有 n 个全球 IP 地址的专用网内最多只可以同时有 n 台主机接入互联网。为了更有效地利用全球 IP 地址，现在常用的 NAT 转换表把传输层的端口号也用上了，使得多个专用网内部的主机共用一个全球 IP 地址。使用端口号的 NAT 也叫做网络地址与端口转换 NAPT。 路由器的结构 路由器从功能上可以划分为：路由选择和分组转发。 分组转发结构由三个部分组成：交换结构、一组输入端口和一组输出端口。 路由器分组转发流程 从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。 若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付； 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器； 若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器； 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器； 报告转发分组出错。 路由选择协议 路由选择协议都是自适应的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。 互联网可以划分为许多较小的自治系统 AS，一个 AS 可以使用一种和别的 AS 不同的路由选择协议。 可以把路由选择协议划分为两大类： 自治系统内部的路由选择：RIP 和 OSPF 自治系统间的路由选择：BGP 1. 内部网关协议 RIP RIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。 RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。 距离向量算法： 对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1； 对修改后的 RIP 报文中的每一个项目，进行以下步骤： 若原来的路由表中没有目的网络 N，则把该项目添加到路由表中； 否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由表中的项目；否则：若收到的项目中的距离 d 小于路由表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。 若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。 RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。 2. 内部网关协议 OSPF 开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。 开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。 OSPF 具有以下特点： 向本自治系统中的所有路由器发送信息，这种方法是洪泛法。 发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。 只有当链路状态发生变化时，路由器才会发送信息。 所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。 3. 外部网关协议 BGP BGP（Border Gateway Protocol，边界网关协议） AS 之间的路由选择很困难，主要是由于： 互联网规模很大； 各个 AS 内部使用不同的路由选择协议，无法准确定义路径的度量； AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。 BGP 只能寻找一条比较好的路由，而不是最佳路由。 每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。]]></content>
      <categories>
        <category>communication</category>
      </categories>
      <tags>
        <tag>communication</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络之传输层]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fcommunication%2Fnetwork-transport%2F</url>
    <content type="text"><![CDATA[计算机网络之传输层 网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。 UDP 和 TCP 的特点 UDP 首部格式 TCP 首部格式 TCP 的三次握手 TCP 的四次挥手 TCP 可靠传输 TCP 滑动窗口 TCP 流量控制 TCP 拥塞控制 1. 慢开始与拥塞避免 2. 快重传与快恢复 UDP 和 TCP 的特点 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 UDP 首部格式 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。 TCP 首部格式 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 TCP 的三次握手 假设 A 为客户端，B 为服务器端。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 三次握手的原因 第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。 客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。 TCP 的四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。 A 发送连接释放报文，FIN=1。 B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 当 B 不再需要连接时，发送连接释放报文，FIN=1。 A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。 B 收到 A 的确认后释放连接。 四次挥手的原因 客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 TIME_WAIT 客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由： 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 TCP 可靠传输 TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。 一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下： 其中，0 ≤ a ＜ 1，RTTs 随着 a 的增加更容易受到 RTT 的影响。 超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下： 其中 RTTd 为偏差的加权平均值。 TCP 滑动窗口 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。 TCP 流量控制 流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 TCP 拥塞控制 如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。 TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。 发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。 为了便于讨论，做如下假设： 接收方有足够大的接收缓存，因此不会发生流量控制； 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。 1. 慢开始与拥塞避免 发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 … 注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。 如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。 2. 快重传与快恢复 在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。 在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。 在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。 慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。]]></content>
      <categories>
        <category>communication</category>
      </categories>
      <tags>
        <tag>communication</tag>
        <tag>network</tag>
        <tag>transport</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase 命令]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fbigdata%2Fhbase%2Fhbase-cli%2F</url>
    <content type="text"><![CDATA[HBase 命令 1. 连接 HBase 2. 查询帮助 3. 创建表 4. 查看表信息 5. 查看表详细信息 6. 向表中写数据 7. 扫描表 8. 查询 row 9. 禁用、启用表 10. 删除表 11. 停止 HBase 1. 连接 HBase $ ./bin/hbase shellhbase(main):001:0&gt; 2. 查询帮助 help 3. 创建表 create 'table1','columnFamliy1','columnFamliy2' 说明： 创建一张名为 table1 的 HBase 表，columnFamliy1、columnFamliy2 是 table1 表的列族。 4. 查看表信息 list 'table1' 5. 查看表详细信息 describe 'table1' 6. 向表中写数据 put 'table1', 'row1', 'columnFamliy1:a', 'valueA'put 'table1', 'row1', 'columnFamliy1:b', 'valueB'put 'table1', 'row1', 'columnFamliy1:c', 'valueC'put 'table1', 'row2', 'columnFamliy1:a', 'valueA'put 'table1', 'row2', 'columnFamliy1:b', 'valueB'put 'table1', 'row2', 'columnFamliy1:c', 'valueC'put 'table1', 'row1', 'columnFamliy2:a', 'valueA'put 'table1', 'row1', 'columnFamliy2:b', 'valueB'put 'table1', 'row1', 'columnFamliy2:c', 'valueC' 7. 扫描表 hbase&gt; scan 'hbase:meta'hbase&gt; scan 'hbase:meta', &#123;COLUMNS =&gt; 'info:regioninfo'&#125;hbase&gt; scan 'ns1:hbase&gt; scan 't1', &#123;COLUMNS =&gt; ['c1', 'c2'], LIMIT =&gt; 10, STARTROW =&gt; 'xyz'&#125;hbase&gt; scan 't1', &#123;COLUMNS =&gt; 'c1', TIMERANGE =&gt; [1303668804, 1303668904]&#125;hbase&gt; scan 't1', &#123;REVERSED =&gt; true&#125;hbase&gt; scan 't1', &#123;ALL_METRICS =&gt; true&#125;hbase&gt; scan 't1', &#123;METRICS =&gt; ['RPC_RETRIES', 'ROWS_FILTERED']&#125;hbase&gt; scan 't1', &#123;ROWPREFIXFILTER =&gt; 'row2', FILTER =&gt; " (QualifierFilter (&gt;=, 'binary:xyz')) AND (TimestampsFilter ( 123, 456))"&#125;hbase&gt; scan 't1', &#123;FILTER =&gt; org.apache.hadoop.hbase.filter.ColumnPaginationFilter.new(1, 0)&#125;hbase&gt; scan 't1', &#123;CONSISTENCY =&gt; 'TIMELINE'&#125;For setting the Operation Attributes hbase&gt; scan 't1', &#123; COLUMNS =&gt; ['c1', 'c2'], ATTRIBUTES =&gt; &#123;'mykey' =&gt; 'myvalue'&#125;&#125;hbase&gt; scan 't1', &#123; COLUMNS =&gt; ['c1', 'c2'], AUTHORIZATIONS =&gt; ['PRIVATE','SECRET']&#125;For experts, there is an additional option -- CACHE_BLOCKS -- whichswitches block caching for the scanner on (true) or off (false). Bydefault it is enabled. Examples:hbase&gt; scan 't1', &#123;COLUMNS =&gt; ['c1', 'c2'], CACHE_BLOCKS =&gt; false&#125; 8. 查询 row get 'table1', 'row1'get 'table1', 'row1', 'columnFamliy1'get 'table1', 'row1', 'columnFamliy1:a' 9. 禁用、启用表 hbase(main):008:0&gt; disable 'test'0 row(s) in 1.1820 secondshbase(main):009:0&gt; enable 'test'0 row(s) in 0.1770 seconds 10. 删除表 hbase(main):011:0&gt; drop 'test'0 row(s) in 0.1370 seconds 11. 停止 HBase $ ./bin/stop-hbase.shstopping hbase....................$]]></content>
  </entry>
  <entry>
    <title><![CDATA[HDFS 命令]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fbigdata%2Fhdfs%2Fhdfs-cli%2F</url>
    <content type="text"><![CDATA[HDFS 命令 列出目录的内容： $ hdfs dfs -ls / 将文件从本地文件系统加载到HDFS： $ hdfs dfs -put songs.txt /user/adam 从HDFS读取文件内容： $ hdfs dfs -cat /user/adam/songs.txt 更改文件的权限： $ hdfs dfs -chmod 700 /user/adam/songs.txt 将文件的复制因子设置为4： $ hdfs dfs -setrep -w 4 /user/adam/songs.txt 检查文件的大小： $ hdfs dfs -du -h /user/adam/songs.txt Create a subdirectory in your home directory.$ hdfs dfs -mkdir songs 注意，相对路径总是引用执行命令的用户的主目录。HDFS上没有“当前”目录的概念（换句话说，没有“CD”命令）： 将文件移到新创建的子目录： $ hdfs dfs -mv songs.txt songs 从HDFS中删除一个目录： $ hdfs dfs -rm -r songs]]></content>
  </entry>
  <entry>
    <title><![CDATA[军事]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fminds%2F%E4%BA%BA%E6%96%87%2F%E5%86%9B%E4%BA%8B%2FREADME%2F</url>
    <content type="text"><![CDATA[军事 军事是与战争、军队、军人等有关事务的总称。 关键词 战争、战役、战斗、战士、战略、战术、武器、兵种、进攻、防御、指挥、兵法、军衔]]></content>
  </entry>
  <entry>
    <title><![CDATA[合理编排你的技术文档]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fmethod%2Fdoc-style%2F</url>
    <content type="text"><![CDATA[技术文档规范 文档采用 Markdown 语法书写。 📚 「参考」Markdown 语法可以参考： https://github.com/guodongxiaren/README https://github.com/tchapi/markdown-cheatsheet 1. 标题 1.1. 标题层级 1.2. 标题原则 2. 文本 2.1. 字间距 2.2. 句子 2.3. 写作风格 2.4. 英文处理 3. 段落 3.1. 段落原则 3.2. 引用 3.3. 强调 4. 数值 4.1. 半角数字 4.2. 千分号 4.3. 货币 4.4. 数值范围 4.5. 变化程度的表示法 5. 符号 5.1. 符号原则 5.2. 句号 5.3. 逗号 5.4. 顿号 5.5. 分号 5.6. 引号 5.7. 圆括号 5.8. 冒号 5.9. 省略号 5.10. 感叹号 5.11. 破折号 5.12. 连接号 6. 结构 6.1. 目录结构 6.2. 文件名 7. Emoji 8. 参考 1. 标题 1.1. 标题层级 标题分为四级。 一级标题：文章的标题 二级标题：文章内容的大标题 三级标题：二级标题下一级的标题 四级标题：三级标题下一级的标题 1.2. 标题原则 一篇文章中应该尽力避免同名标题。 一级标题下，不能直接出现三级标题。 标题要避免孤立编号（即同级标题只有一个）。 下级标题不重复上一级标题的内容。 谨慎使用四级标题，尽量避免出现，保持层级的简单和防止出现过于复杂的章节。如果三级标题下有并列性的内容，建议只使用项目列表（Item list）。 2. 文本 2.1. 字间距 全角中文字符与半角英文字符之间，应有一个半角空格。 反例：本文介绍如何快速启动Windows系统。正例：本文介绍如何快速启动 Windows 系统。 全角中文字符与半角阿拉伯数字之间，有没有半角空格都可，但必须保证风格统一，不能两种风格混杂。 正例：2011年5月15日，我订购了5台笔记本电脑与10台平板电脑。正例：2011 年 5 月 15 日，我订购了 5 台笔记本电脑与 10 台平板电脑。 半角的百分号，视同阿拉伯数字。 英文单位若不翻译，单位前的阿拉伯数字与单位间不留空格。 反例：一部容量为 16 GB 的智能手机正例：一部容量为 16GB 的智能手机 半角英文字符和半角阿拉伯数字，与全角标点符号之间不留空格。 反例：他的电脑是 MacBook Air 。正例：他的电脑是 MacBook Air。 2.2. 句子 避免使用长句。一个句子建议不超过 100 字或者正文的 3 行。 尽量使用简单句和并列句，避免使用复合句。 2.3. 写作风格 尽量不使用被动语态，改为使用主动语态。 反例：假如此软件尚未被安装，正例：假如尚未安装这个软件， 不使用非正式的语言风格。 反例：Lady Gaga 的演唱会真是酷毙了，从没看过这么给力的表演！！！正例：无法参加本次活动，我深感遗憾。 用对“的”、“地”、“得”。 她露出了开心的笑容。（形容词＋的＋名词）她开心地笑了。（副词＋地＋动词）她笑得很开心。（动词＋得＋副词） 使用代词时（比如“其”、“该”、“此”、“这”等词），必须明确指代的内容，保证只有一个含义。 反例：从管理系统可以监视中继系统和受其直接控制的分配系统。正例：从管理系统可以监视两个系统：中继系统和受中继系统直接控制的分配系统。 名词前不要使用过多的形容词。 反例：此设备的使用必须在接受过本公司举办的正式的设备培训的技师的指导下进行。正例：此设备必须在技师的指导下使用，且指导技师必须接受过由本公司举办的正式设备培训。 单个句子的长度尽量保持在 20 个字以内；20 ～ 29 个字的句子，可以接受；30 ～ 39 个字的句子，语义必须明确，才能接受；多于 40 个字的句子，在任何情况下都不能接受。 反例：本产品适用于从由一台服务器进行动作控制的单一节点结构到由多台服务器进行动作控制的并行处理程序结构等多种体系结构。正例：本产品适用于多种体系结构。无论是由一台服务器（单一节点结构），还是由多台服务器（并行处理结构）进行动作控制，均可以使用本产品。 同样一个意思，尽量使用肯定句表达，不使用否定句表达。 反例：请确认没有接通装置的电源。正例：请确认装置的电源已关闭。 避免使用双重否定句。 反例：没有删除权限的用户，不能删除此文件。正例：用户必须拥有删除权限，才能删除此文件。 2.4. 英文处理 英文原文如果使用了复数形式，翻译成中文时，应该将其还原为单数形式。 英文：⋯information stored in random access memory (RAMs)⋯中文：……存储在随机存取存储器（RAM）里的信息…… 外文缩写可以使用半角圆点(.)表示缩写。 U.S.A.Apple, Inc. 表示中文时，英文省略号（⋯）应改为中文省略号（……）。 英文：5 minutes later⋯中文：5 分钟过去了⋯⋯ 英文书名或电影名改用中文表达时，双引号应改为书名号。 英文：He published an article entitled "The Future of the Aviation".中文：他发表了一篇名为《航空业的未来》的文章。 第一次出现英文词汇时，在括号中给出中文标注。此后再次出现时，直接使用英文缩写即可。 IOC（International Olympic Committee，国际奥林匹克委员会）。这样定义后，便可以直接使用“IOC”了。 专有名词中每个词第一个字母均应大写，非专有名词则不需要大写。 “American Association of Physicists in Medicine”（美国医学物理学家协会）是专有名词，需要大写。“online transaction processing”（在线事务处理）不是专有名词，不应大写。 3. 段落 3.1. 段落原则 一个段落只能有一个主题，或一个中心句子。 段落的中心句子放在段首，对全段内容进行概述。后面陈述的句子为核心句服务。 一个段落的长度不能超过七行，最佳段落长度小于等于四行。 段落的句子语气要使用陈述和肯定语气，避免使用感叹语气。 段落之间使用一个空行隔开。 段落开头不要留出空白字符。 3.2. 引用 引用第三方内容时，应注明出处。 One man’s constant is another man’s variable. — Alan Perlis 如果是全篇转载，请在全文开头显著位置注明作者和出处，并链接至原文。 本文转载自 WikiQuote 使用外部图片时，必须在图片下方或文末标明来源。 本文部分图片来自 Wikipedia 3.3. 强调 一些特殊的强调内容可以按照如下方式书写： 🔔 『注意』 💡 『提示』 📚 『参考』 4. 数值 4.1. 半角数字 数字一律使用半角形式，不得使用全角形式。 反例： 这件商品的价格是１０００元。正例： 这件商品的价格是 1000 元。 4.2. 千分号 数值为千位以上，应添加千分号（半角逗号）。 XXX 公司的实收资本为 RMB1,258,000。 对于 4 ～ 6 位的数值，千分号是选用的，比如1000和1,000都可以接受。对于 7 位及以上的数值，千分号是必须的。 多位小数要从小数点后从左向右添加千分号，比如4.234,345。 4.3. 货币 货币应为阿拉伯数字，并在数字前写出货币符号，或在数字后写出货币中文名称。 $1,0001,000 美元 4.4. 数值范围 表示数值范围时，用～连接。参见《标点符号》一节的“连接号”部分。 带有单位或百分号时，两个数字都要加上单位或百分号，不能只加后面一个。 反例：132～234kg正例：132kg～234kg反例：67～89%正例：67%～89% 4.5. 变化程度的表示法 数字的增加要使用“增加了”、“增加到”。“了”表示增量，“到”表示定量。 增加到过去的两倍（过去为一，现在为二）增加了两倍（过去为一，现在为三） 数字的减少要使用“降低了”、“降低到”。“了”表示增量，“到”表示定量。 降低到百分之八十（定额是一百，现在是八十）降低了百分之八十（原来是一百，现在是二十） 不能用“降低 N 倍”或“减少 N 倍”的表示法，要用“降低百分之几”或“减少百分之几”。因为减少（或降低）一倍表示数值原来为一百，现在等于零。 5. 符号 5.1. 符号原则 中文语句的标点符号，均应该采取全角符号，这样可以保证视觉的一致。 如果整句为英文，则该句使用英文/半角标点。 句号、问号、叹号、逗号、顿号、分号和冒号不得出现在一行之首。 5.2. 句号 中文语句中的结尾处应该用全角句号（。）。 句子末尾用括号加注时，句号应在括号之外。 反例：关于文件的输出，请参照第 1.3 节（见第 26 页。）正例：关于文件的输出，请参照第 1.3 节（见第 26 页）。 5.3. 逗号 逗号，表示句子内部的一般性停顿。 注意避免“一逗到底”，即整个段落除了结尾，全部停顿都使用逗号。 5.4. 顿号 句子内部的并列词，应该用全角顿号(、) 分隔，而不用逗号，即使并列词是英语也是如此。 反例：我最欣赏的科技公司有 Google, Facebook, 腾讯, 阿里和百度等。正例：我最欣赏的科技公司有 Google、Facebook、腾讯、阿里和百度等。 英文句子中，并列词语之间使用半角逗号（,）分隔。 例句：Microsoft Office includes Word, Excel, PowerPoint, Outlook and other components. 5.5. 分号 分号；表示复句内部并列分句之间的停顿。 5.6. 引号 引用时，应该使用全角双引号（“ ”），注意前后双引号不同。 例句：许多人都认为客户服务的核心是“友好”和“专业”。 引号里面还要用引号时，外面一层用双引号，里面一层用单引号（‘ ’），注意前后单引号不同。 例句：鲍勃解释道：“我要放音乐，可萨利说，‘不行！’。” 5.7. 圆括号 补充说明时，使用全角圆括号（），括号前后不加空格。 例句：请确认所有的连接（电缆和接插件）均安装牢固。 5.8. 冒号 全角冒号（：）常用在需要解释的词语后边，引出解释和说明。 例句：请确认以下几项内容：时间、地点、活动名称，以及来宾数量。 表示时间时，应使用半角冒号（:）。 例句：早上 8:00 5.9. 省略号 省略号……表示语句未完、或者语气的不连续。它占两个汉字空间、包含六个省略点，不要使用。。。或...等非标准形式。 省略号不应与“等”这个词一起使用。 反例：我们为会餐准备了香蕉、苹果、梨…等各色水果。正例：我们为会餐准备了各色水果，有香蕉、苹果、梨……正例：我们为会餐准备了香蕉、苹果、梨等各色水果。 5.10. 感叹号 应该使用平静的语气叙述，尽量避免使用感叹号！。 不得多个感叹号连用，比如！！和!!!。 5.11. 破折号 破折号————一般用于做进一步解释。破折号应占两个汉字的位置。 例句：直觉————尽管它并不总是可靠的————告诉我，这事可能出了些问题。 5.12. 连接号 连接号用于连接两个类似的词。 以下场合应该使用直线连接号（-），占一个半角字符的位置。 两个名词的复合 图表编号 例句：氧化-还原反应例句：图 1-1 以下场合应该使用波浪连接号（～），占一个全角字符的位置。 数值范围（例如日期、时间或数字） 例句：2009 年～2011 年 注意，波浪连接号前后两个值都应该加上单位。 波浪连接号也可以用汉字“至”代替。 例句：周围温度：-20°C 至 -10°C 6. 结构 6.1. 目录结构 技术手册目录结构是一部完整的书，建议采用下面的结构。 简介（Introduction） - [必选][目录|文件] 提供对产品和文档本身的总体的、扼要的说明 入门篇（Quickstart） - [可选][文件] 如何最快速地使用产品 基础篇（Basics） - [必选][目录] 又称”使用篇“，提供初级的使用教程 环境准备（Prerequisite） - [可选][文件] 软件使用需要满足的前置条件 安装（Installation） - [可选][文件] 软件的安装方法 配置（Configuration） - [可选][目录|文件] 软件的配置 特性（Feature） - [必选][目录|文件] 软件的功能特性 进阶篇（Advanced） - [可选][目录] 又称”开发篇“，提供中高级的开发教程 原理（Principle） - [可选][目录|文件] 软件的原理 设计（Design） - [可选][目录|文件] 软件的设计，如：架构、设计思想等 实战篇（Action） - [可选][目录] 提供一些具有实战意义的示例说明 API（API） - [可选][目录|文件] 软件 API 的逐一介绍 常见问题（FAQ） - [可选][目录|文件] 常见问题解答 附录（Appendix） - [可选][目录] 不属于教程本身、但对阅读教程有帮助的内容 命令（Command） - [可选][目录] 命令 资源（Resource） - [必选][文件] 资源 术语（Glossary） - [可选][文件] 名词解释 技巧（Recipe） - [可选][文件] 最佳实践 版本（Changelog） - [可选][文件] 版本说明 反馈（Feedback） - [可选][文件] 反馈方式 下面是两个真实范例，可参考。 Redux 手册 Atom 手册 6.2. 文件名 文档的文件名不得含有空格。 文件名必须使用半角字符，不得使用全角字符。这也意味着，中文不能用于文件名。 反例： 名词解释.md正例： glossary.md 文件名建议只使用小写字母，不使用大写字母。 反例：TroubleShooting.md正例：troubleshooting.md 为了醒目，某些说明文件的文件名，可以使用大写字母，比如README、LICENSE。 文件名包含多个单词时，单词之间建议使用半角的连词线（-）分隔。 反例：advanced_usage.md正例：advanced-usage.md 7. Emoji 在 markdown 文档中，普遍会使用 emoji，帮助理解内容。但是，如果滥用 emoji，可能会适得其反。 这里，将一些比较约定俗成的 emoji 表情使用场景列举一下： 💡 提示 - [推荐] 🔔 注意、警告 - [推荐] ⭕ 正确 - [推荐] ❌ 错误 - [推荐] ❓ 问题 - [推荐] ⛔ 禁止 - [推荐] 🚧 未完待续、有待补充 - [推荐] 📚 参考、参考资料 - [可选] ⌨ 源码 - [可选] 8. 参考 产品手册中文写作规范, by 华为 写作规范和格式规范, by DaoCloud 技术写作技巧在日汉翻译中的应用, by 刘方 简体中文规范指南, by lengoo 文档风格指南, by LeanCloud 豌豆荚文案风格指南, by 豌豆荚 中文文案排版指北, by sparanoid 中文排版需求, by W3C 为什么文件名要小写？, by 阮一峰]]></content>
      <categories>
        <category>method</category>
      </categories>
      <tags>
        <tag>method</tag>
        <tag>doc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fbigdata%2Fhbase%2FREADME%2F</url>
    <content type="text"><![CDATA[HBase 简介 基础 原理 数据模型 HBase 架构 HBase 和 RDBMS API 附录 命令行 更多内容 扩展阅读 参考资料 简介 HBase 是建立在 HDFS 基础上的面向列的分布式数据库。 HBase 参考了谷歌的 BigTable 建模，实现的编程语言为 Java。 它是 Hadoop 项目的子项目，运行于 HDFS 文件系统之上。 HBase 适用场景：实时地随机访问超大数据集。 在 CAP 理论中，HBase 属于 CP 类型的系统。 基础 HBase 维护 原理 数据模型 HBase 是一个面向列的数据库，在表中它由行排序。 HBase 表模型结构为： 表（table）是行的集合。 行（row）是列族的集合。 列族（column family）是列的集合。 列（row）是键值对的集合。 HBase 表的单元格（cell）由行和列的坐标交叉决定，是有版本的。默认情况下，版本号是自动分配的，为 HBase 插入单元格时的时间戳。单元格的内容是未解释的字节数组。 行的键也是未解释的字节数组，所以理论上，任何数据都可以通过序列化表示成字符串或二进制，从而存为 HBase 的键值。 HBase 架构 和 HDFS、YARN 一样，HBase 也采用 master / slave 架构： HBase 有一个 master 节点。master 节点负责将区域（region）分配给 region 节点；恢复 region 节点的故障。 HBase 有多个 region 节点。region 节点负责零个或多个区域（region）的管理并相应客户端的读写请求。region 节点还负责区域的划分并通知 master 节点有了新的子区域。 HBase 依赖 ZooKeeper 来实现故障恢复。 Regin HBase 表按行键范围水平自动划分为区域（region）。每个区域由表中行的子集构成。每个区域由它所属的表、它所含的第一行及最后一行来表示。 区域只不过是表被拆分，并分布在区域服务器。 Master 服务器 区域分配、DDL(create、delete)操作由 HBase master 服务器处理。 master 服务器负责协调 region 服务器 协助区域启动，出现故障恢复或负载均衡情况时，重新分配 region 服务器 监控集群中的所有 region 服务器 支持 DDL 接口（创建、删除、更新表） Regin 服务器 区域服务器运行在 HDFS 数据节点上，具有以下组件 WAL - Write Ahead Log 是 HDFS 上的文件。WAL 存储尚未持久存储到永久存储的新数据，它用于在发生故障时进行恢复。 BlockCache - 是读缓存。它将频繁读取的数据存储在内存中。至少最近使用的数据在完整时被逐出。 MemStore - 是写缓存。它存储尚未写入磁盘的新数据。在写入磁盘之前对其进行排序。每个区域每个列族有一个 MemStore。 Hfiles - 将行存储为磁盘上的排序键值对。 ZooKeeper HBase 使用 ZooKeeper 作为分布式协调服务来维护集群中的服务器状态。Zookeeper 维护哪些服务器是活动的和可用的，并提供服务器故障通知。集群至少应该有 3 个节点。 HBase 和 RDBMS HBase RDBMS HBase 无模式，它不具有固定列模式的概念;仅定义列族。 RDBMS 有它的模式，描述表的整体结构的约束。 它专门创建为宽表。 HBase 是横向扩展。 这些都是细而专为小表。很难形成规模。 没有任何事务存在于 HBase。 RDBMS 是事务性的。 它反规范化的数据。 它具有规范化的数据。 它用于半结构以及结构化数据是非常好的。 用于结构化数据非常好。 API Java API 归纳总结在这里：Hbase Java API 附录 命令行 HBase 命令行可以参考这里：HBase 命令行 更多内容 扩展阅读 HBase 命令 HBase 配置 参考资料 官方 HBase 官网 HBase 官方文档 HBase 官方文档中文版 HBase API 文章 Bigtable: A Distributed Storage System for Structured Data https://mapr.com/blog/in-depth-look-hbase-architecture/]]></content>
  </entry>
  <entry>
    <title><![CDATA[UML 教程]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fdesign%2FUML%2F</url>
    <content type="text"><![CDATA[UML 教程 关键词：部署图, 组件图, 包图, 类图, 复合结构图, 对象图, 活动图, 状态机图, 用例图, 通信图, 交互概述图, 时序图, 时间图 简介 部署图 组件图 包图 类图 复合结构图 对象图 活动图 状态机图 用例图 通信图 交互概述图 时序图 时间图 UML 工具 更多内容 简介 UML 图类型 UML 图类型如下图所示： 结构式建模图 结构式建模图（Structure diagrams）强调的是系统式的建模。结构图定义了一个模型的静态架构。它们通常被用来对那些构成模型的‘要素’建模，诸如：类，对象，接口和物理组件。另外，它们也被用来对元素间关联和依赖关系进行建模。 类图 对象图 包图 组件图 部署图 复合结构图 行为式建模图 行为式建模图（Behavior diagrams）强调系统模型中触发的事。行为图用来记录在一个模型内部，随时间的变化，模型执行的交互变化和瞬间的状态；并跟踪系统在真实环境下如何表现，以及观察系统对一个操作或事件的反应，以及它的结果。 活动图 状态图 用例图 通信图 交互概述图 时序图 时间图 UML 概念 UML 从来源中使用相当多的概念。我们将之定义于统一建模语言术语汇表。下面仅列代表性的概念。 对于结构而言 - 执行者，属性，类，元件，接口，对象，包。 对于行为而言 - 活动（UML），事件（UML），消息（UML），方法（UML），操作（UML），状态（UML），用例（UML）。 对于关系而言 - 聚合，关联，组合，相依，广义化（or 继承）。 其他概念 构造型—这规范符号应用到的模型 多重性—多重性标记法与资料库建模基数对应，例如：1, 0..1, 1..* 部署图 部署图（Deployment Diagram）用于对系统的物理结构建模。部署图将显示系统中的软件组件和硬件组件之间的关系以及处理工作的物理分布。 节点 节点既可以是硬件元素，也可以是软件元素。它显示为一个立方体，如下图所示。 节点实例 图可以显示节点实例，实例与节点的区分是：实例的名称带下划线，冒号放在它的基本节点类型之前。实例在冒号之前可以有名称，也可以没有名称。下图显示了一个具名的计算机实例。 节点构造型 为节点提供了许多标准的构造型，分别命名为 «cdrom»， «cd-rom»， «computer»， «disk array»， «pc»， «pc client»， «pc server»， «secure»， «server»， «storage»， «unix server»， «user pc»。 并在节点符号的右上角显示适当的图标。 工件 工件是软件开发过程中的产品。包括过程模型（如：用例模型，设计模型等），源文件，执行文件，设计文档，测试报告，构造型，用户手册等等。 工件表示为带有工件名称的矩形，并显示«artifact»关键字和文档符号。 关联 在部署图的上下文联系中，关联代表节点间的联系通道。下图显示了一个网络系统的部署图，描述了网络协议为构造型和关联终端的多重性， 作为容器的节点 节点可以包含其他元素，如组件和工件。下图显示了一个嵌入式系统某个部分的部署图。描写了一个被主板节点包含的可执行工件。 组件图 组件图（Component Diagram）描绘了组成一个软件系统的模块和嵌入控件。组件图比类图具有更高层次的抽象－通常运行时一个组件被一个或多个类（或对象）实现。它们象积木那样使得组件能最终构成系统的绝大部分。 上图演示了一些组件和它们的内部关系。装配连接器（Assembly connectors）“连接”由&quot;Product&quot;和&quot;Customer&quot;的提供接口到由 &quot;Order&quot;指定的需求接口。 一个依赖关系映射了客户相关的帐户信息到“Order”需要的 &quot;Payment&quot;需求接口。 实际上，组件图同包图很相似，它们都有明确的界限，把元素分组到逻辑结构中。他们之间的不同是：组件图提供了语义更丰富的分组机制，在组件图中，所有的模型元素都是私有的，而包图只显示公有的成员。 表现组件 组件可表示为带关键字 «component»的矩形类元；也可用右上角有组件图标的矩形表示。 装配连接器 装配连接器在组件 “Component1”的需求接口和另一个组件 “Component2”的提供接口之间建立桥梁; 这个桥梁使得一个组件能提供另一个组件所需要的服务。 带端口组件 使用端口的组件图允许在它的环境指定一个服务和行为，同时这个服务和行为也是组件需要的。当端口进行双向操作的时候，它可以指定输入和输出。下图详述了用于在线服务的带端口组件，它有两个提供接口 “order entry”和 “tracking”，也有 “payment” 需求接口。 包图 包图（Package Diagram）用来表现包和它所包含元素的组织。当用来代表类元素时，包图提供了命名空间的可视化。包图最常用的用途是用来组织用例图和类图，尽管它不局限于这些 UML 元素。 下面是一个包图的例子。 包中的元素共享相同的命名空间，因此，一个指定命名空间的元素必须有唯一的名称。 包可以用来代表物理或逻辑关系。选择把类包括在指定的包里，有助于在同一个包里赋予这些类相同继承层次。通常认为把通过复合相关联的类，以及与它们相协作的类放在同一个包里。 在 UML2.5 中，包用文件夹来表示，包中的元素共享同一个命名空间，并且必须是可识别的，因此要有唯一的名称或类型。包必须显示包名，在附属方框部分有选择的显示包内的元素。 包的合并 - 包之间的合并连接符«merge»定义了源包元素与目标包同名元素之间的泛化关系。源包元素的定义被扩展来包含目标包元素定义。当源包元素与目标包内没有同名元素时，目标包元素的定义不受影响。 包的导入 - 导入连接符 «import»表明目标包的元素，在该例中是一个类 ，在源包中被引用要用非限定修饰名。源包的命名空间获得目标类的接口，目标包的命名空间则不受影响。 嵌套连接符 - 源包和目标包间的嵌套连接符说明目标包完全包含源包。 类图 类图（Class Diagram）展示了面向对象系统的构造模块。描绘了模型或部分模型的静态视图，显示它包含的属性和行为，而不是详细描述操作的功能或完善方法。类图最常用来表达多个类和接口之间的关系。泛化（Generalizations），聚合（aggregations）和关联（associations）分别是类之间继承，复合或应用，及连接的表现。 下面的图显示了类之间的聚合关系。弱聚合（浅色箭头）表现在类 “Account” 使用 “AddressBook”，但是不必要包含它的一个实例。强聚合（图中的黑色箭头）表示了目标类包含源类，例如，“Contact” 和 &quot;ContactGroup&quot;值被包含在 &quot;AddressBook&quot;中。 类（Classes） 类是定义对象所具有的属性和行为的元素。行为用类能理解的合适消息和适合每条消息的操作来描述。 类中也可能定义约束，标记值，构造型。 类的标柱（Class Notation） 类用矩形表示。除类的名称外，还可以选择性地显示属性和操作。 分栏分别用来显示类的名称，属性和操作。 在下面图中，类的类名显示在最上面的分栏，它下面的分栏显示详细属性，如：“center” 属性显示初始化的值。最后面的分栏显示操作，如： setWidth，setLength 和 setPosition 以及他们的参数。 属性和操作名前的标注表示了该属性或操作的可见性: 如果使用 &quot;+&quot;号，这个属性或操作是公共的 ; “-” 号则代表这个属性或操作是私有的。 “#“号是这个属性或操作被定义为保护的，” ~” 号代表包的可见性。 接口（Interfaces） 接口是实施者同意满足的行为规范，是一种约定。实现一个接口，类必需支持其要求的行为，使系统按照同样的方式，即公共的接口，处理不相关的元素。 接口有相似于类的外形风格，含有指定的操作，如下图所示。如果没有明确的详细操作，也可以画成一个圆环。当画成圆环的时候，到这个环形标柱的实现连接没有目标箭头。 表（Tables） 表尽管不是基本 UML 的一部分，仍然是“图型”能完成的实例用。在右上角画一个表的小图标来表示。表属性用“图型” «column»表示。 绝大多数表单有一个主键，是由一个或几个字段组成的一个唯一的字码组合加主键操作来访问表格，主键操作“图型”为«PK»。 一些表有一个或多个外键，使用一个或多个字段加一个外键操作，映射到相关表的主键上去，外键操作“图型”为«FK»。 关联（Associations） 关联表明两个模型元素之间有关系，通常用在一个类中被实现为一个实例变量。连接符可以包含两端的命名的角色，基数性，方向和约束。关联是元素之间普通的关系。如果多于两个元素，也可以使用菱形的关联关系。当从类图生成代码时，关联末端的对象将变成目标类中实例变量。见下图示例 “playsFor” 将变成&quot;Player&quot;类中的实例变量。 泛化（Generalizations） 泛化被用来说明继承关系。连接从特定类元到一般类元。泛化的含义是源类继承了目标类的特性。下图的图显示了一个父类泛化一个子类， 类“Circle”的一个实例将会有属性 “ x_position”，“ y_position” ， “radius” 和 方法 “display()”。 注意：类 “Shape” 是抽象的，类名显示为斜体。 下图显示了与上图相同信息的视图。 聚合（Aggregations） 聚合通常被用来描述由更小的组件所构成的元素。聚合关系表示为白色菱形箭头指向目标类或父类。 聚合的更强形式 -组合聚合（强聚合） - 显示为黑色菱形箭头，用来组合每次最大化的包含组件。如果一个组合聚合的父类被删除，通常与他相关的所有部分都会被删除，但是，如果一个部件从组合中去掉，将不用删除整个组合。组合是可迁，非对称的关系和递归的。 下面的图示：显示了弱聚合和强聚合的不同。“ address book” 由许多 “contacts” 和 “contact groups”组成。 “contact group” 是一个“contacts”的虚分组; “contact”可以被包含在不止一个 “ contact group”。 如果你删除一个“ address book”，所有的 “contacts” 和 “contact groups” 也将会被删除；如果你删除“ contact group”， 没有 “contacts”会被删除。 关联类（Association Classes） 关联类是一个允许关联连接有属性和操作的构造。下面的示例：显示了远不止简单连接两个类的连接，如给“employee”分配项目。“ employee”在项目中所起的作用是一个复杂的实体，既有自身的也有不属于“employee” 或 “project” 类的细节。 例如，“ employee”可以同时为几个项目工作，有不同的职务头衔和对应的安全权限。 依赖（Dependencies） 依赖被用来描述模型元素间广泛的依赖关系。通常在设计过程早期显示两个元素之间存在某种关系，因为是初期而不能确定具体是什么关系，在设计过程末期，该继承关系会被归入已有构造型 (构造型 可以是实例化 «instantiate»，跟踪 «trace»，导入 «import»， 和其它的关系)，或被替换成一个更明确类型的连接符。 跟踪（Traces） 跟踪关系是一种特殊化的依赖关系。连接模型元素或跨模型但是具有相同概念的模型元素集。跟踪被经常用来追踪需求和模型的变化。由于变化是双向的，这种依赖关系的顺序通常被忽略。这种关系的属性可以被指定为单向映射，但跟踪是双向的，非正式的和很少可计算的。 实现（Realizations） 是源对象执行或实现目标，实现被用来表达模型的可跟踪性和完整性－业务模型或需求被一个或多个用例实现，用例则被类实现，类被组件实现，等等。这种实现贯穿于系统设计的映射需求和类等，直至抽象建模水平级。从而确保整个系统的一张宏图，它也反映系统的所有微小组成，以及约束和定义它的细节。实现关系用带虚线的实箭头表示。 嵌套（Nestings） 嵌套连接符用来表示源元素嵌套在目标元素中。下图显示“ inner class”的定义，尽管在 EA 中，更多地按照着他们在项目层次视图中的位置来显示这种关系。 复合结构图 复合结构图显示类的内部结构，包括它与系统其他部分的交互点。也显示各部分的配置与关系，这些部分一起执行类元的行为。 类元素已经在类图部分被详细地阐述，这部分用来说明类表现复合元素的方式，如：暴露接口，包含端口和部件。 部件 部件是代表一组（一个或多个）实例的元素，这组实例的拥有者是一类元实例，例如：如果一个图的实例有一组图形元素，则这些图形元素可以被表示为部件，并可以对他们之间的某种关系建模。注意：一个部件可以在它的父类被删除之前从父类中被去掉，这样部件就不会被同时删除了。 部件在类或组件内部显示为不加修饰的方框。 端口 端口是类型化的元素，代表一个包含类元实例的外部可视的部分。端口定义了类元和它的环境之间的交互。端口显示在包含它的部件，类或组合结构的边缘上。端口指定了类元提供的服务，以及类元要求环境提供的服务。 端口显示为所属类元边界指定的方框。 接口 接口与类相似，但是有一些限制，所有的接口操作都是公共和抽象的，不提供任何默认的实现。所有的接口属性都必须是常量。然而，当一个类从一个单独的超级类继承而来，它可以实现多个接口。 当一个接口在图中单列出来，它既可以显示为类元素的方框，带 «interface» 关键字和表明它是抽象的斜体名称，也可以显示为圆环。 注意：圆环标注不显示接口操作。当接口显示为类所有的接口，它们会被当作暴露接口引用。暴露接口可以定义为是提供的，还是需求的。提供接口确认包含它的类元提供指定接口元素定义的操作，可通过类和接口间实现的连接来定义。需求接口说明该类元能与其他类元进行通信，这些类元提供了指定接口元素所定义的操作。需求接口可通过在类和接口间建立依赖连接来定义。 提供接口显示为“带棒球体”，依附在类元边缘。需求接口显示为“带棒杯体”，也是依附在类元边缘。 委托 委托连接器用来定义组件外部端口和接口的内部工作方式。委托连接器表示为带有 «delegate» 关键字的箭头。它连接组件的外部约定，表现为它的端口，到组件部件行为的内部实现。 协作 协作定义了一系列共同协作的角色，它们集体展示一个指定的设计功能。协作图应仅仅显示完成指定任务或功能的角色与属性。隔离主要角色是用来简化结构和澄清行为，也用于重用。一个协作通常实现一个模式。 协作元素显示为椭圆。 角色绑定 角色绑定连接器是一条从连接协作到所要完成该任务类元的连线。它显示为虚线，并在类元端显示作用名。 表现 表现连接器用于连接协作到类元来表示此类元中使用了该协作。显示为带关键字 «represents»的虚线箭头。 发生 发生连接器用于连接协作到类元来表示此协作表现了（同原文）该类元；显示为带关键字«occurrence»的虚线箭头。 对象图 对象图（Object Diagram）可以认为是类图的特殊情形，是类图元素子集，被用来及时强调在某些点，类的实例间的关系。这对理解类图很有帮助。他们在构造上与类图显示没有不同，但是反映出多样性和作用。 类和对象元素 下面的图显示了类元素和对象元素外观上的不同。注意：类元素包括三个部分，分别是名字栏，属性栏和操作栏；对象元素默认为没有分栏。名称显示也有不同：对象名称有下划线，并可能显示该对象实例化所用类元的名称。 运行状态 类元元素可以有任意数量的属性和操作。在对象实例中不会被显示出来。但可能定义对象的运行状态，显示特殊实例的属性设置值。 类和对象图示例 下图是一个对象图，其中插入了类定义图。它例示如何用对象图来测试类图中任务多重性的方法。“car” 类对 “wheel” 类有“1 对多” 的多重性，但是如果已经选择用“1 对 4” 来替代，那样就不会在对象图显示“3 个轮子”的汽车。 活动图 UML 中，活动图用来展示活动的顺序。显示了从起始点到终点的工作流，描述了活动图中存在于事件进程的判断路径。活动图可以用来详细阐述某些活动执行中发生并行处理的情况。活动图对业务建模也比较有用，用来详细描述发生在业务活动中的过程。 一个活动图的示例如下所示。 下面描述组成活动图的元素。 活动 活动是行为参数化顺序的规范。活动被表示为圆角矩形，内含全部的动作，工作流和其他组成活动的元素。 动作 一个动作代表活动中的一个步骤。动作用圆角矩形表示。 动作约束 动作可以附带约束，下图显示了一个带前置条件和后置条件的动作。 控制流 控制流显示一个动作到下一个动作的流。表示为带箭头实线 初始节点 一个开始或起始点用大黑圆点表示，如下图。 结束节点 结束节点有两种类型：活动结束节点和流结束节点。活动结束节点表示为中心带黑点的圆环。 流结束节点表示为内部为叉号的圆环。 这两种不同类型节点的区别为：流结束节点表明单独的控制流的终点。活动结束终点是活动图内所有控制流的结束。 对象和对象流 对象流是对象和数据转递的通道。对象显示为矩形。 对象流显示为带箭头的连接器，表明方向和通过的对象。 一个对象流在它的至少一个终端有一个对象。在上图中，可以采用带输入输出引脚的速记标柱表示。 数据存储显示为带 «datastore» 关键字的对象。 判断节点和合并节点 判断节点和合并节点是相同标注：菱形。它们可以被命名。从判断节点出来的控制流有监护条件，当监护条件满足时，可以对流控制。下图显示了判断节点和合并节点的使用。 分叉和结合节点 分叉和结合节点有同样的标柱：垂直或水平条（方向取决于工作流从左到右，还是从上到下）。它们说明了控制的并发线程的起始和终点，下图显示他们的使用示例。 结合节点与合并节点不同之处在于：结合节点同步两个输入量，产生一个单独的输出量。来自结合节点的输出量要接收到所有的输入量后才能执行。合并节点直接将控制流传递通过。如果两个或更多的输入量到达合并节点。则它的输出流指定的动作会被执行两次或更多次。 扩展域 扩展域是会执行多次的结构活动域。输入输出扩展节点表示为一组“3 厢” ，代表多个选择项。关键词 “iterative”， “parallel” 或 &quot;stream&quot;显示在区域的左上角 异常处理器 异常处理器在活动图中可以建模。 可中断活动区 可中断活动区环绕一组可以中断的动作。在下面非常简单的例子中： 当控制被传递到结束订单 “Close Order” 动作，定单处理&quot;Process Order&quot; 动作会执行直到完成，除非&quot;Cancel Request&quot;取消请求中断被接受，这会将控制传递给&quot;Cancel Order&quot;动作。 分割 一个活动分割显示为垂直或水平泳道。在下图中，分割被用来在活动图中分隔动作，有在 &quot;accounting department&quot;中执行的，有在 &quot;customer&quot;中执行的。 状态机图 状态机图（state-machine-diagram）对一个单独对象的行为建模，指明对象在它的整个生命周期里，响应不同事件时，执行相关事件的顺序。 如下示例， 下列的状态机图显示了门在它的整个生命周期里如何运作。 门可以处于以下的三种状态之一： &quot;Opened&quot;打开状态， &quot;Closed&quot;关闭状态，或者&quot;Locked&quot;锁定状态。 它分别响应事件：“Open”开门， “Close”关门， “Lock”锁门 和 “Unlock”解锁。 注意：不是所有的事件，在所有的状态下都是有效的。如：一个门打开的时候是不可能锁定的，除非你关上门。并且，状态转移可能有附加监护条件：假设门是开的，如果“doorWay-&gt;isEmpty”（门是空的）被满足，那么它只能响应关门事件。状态机图使用的语法和约定将在下面的部分进行讨论。 状态 状态被表示为圆角矩形，状态名写在里面。 起始和结束状态 初始状态表示为实心黑圆环，可以标注名称。结束状态表示为中心带黑点圆环，也可以被标注名称。 转移 一个状态到下一个状态的转移表示为带箭头实线。转移可以有一个“Trigger”触发器，一个“Guard”监护条件和一个“effect”效果。如下所示： &quot;Trigger&quot;触发器是转移的起因，它可以是某个条件下的一个信号，一个事件，一个变化或一个时间通路。&quot;Guard&quot;监护是一个条件，而且必须为真，以便于让触发器引起转移。效果&quot;Effect&quot;是直接作用到对象上的一个动作，该对象具有做为转移结果的状态机。 状态活动 在上面的状态转移示例中，一个效果与该转移相关联。如果目标状态有多个转移到达，并且每一个转移都有相同的效果与它相关联，那最好将该效果与目标状态相关联，而不与转移相关联。你可以通过为这个状态定义初始动作来实现。下图显示了一个带入口动作和出口动作的状态。 可以定义发生在事件上的动作或一直发生的动作。每一种类型的动作是可以定义任意数量的。 自转移 一个状态可能有一个返回到自身的转移，如下图。效果与转移关联是十分有帮助。 复合状态 一个状态机图可以有子状态机图，如下图所示： 可选择不同方式显示相同信息，如下图所示： 上面版本的标注说明&quot;Check PIN&quot;的子状态机图显示在单独的图中。 入口点 有时，你不想在正常的初始状态进入子状态机。例如下面的子状态机，它通常从&quot;初始化&quot;状态开始，但是如果因为某些原因，它不必执行初始化，可能靠转移到指定的入口点来从 “Ready” 状态开始。 下图显示了状态机的上一层。 出口点 有与入口点相类似的方式，它可能也指定可选择的出口点。下图给出了主处理状态执行后，所执行状态的去向将取决于该状态转移时所使用的路径。 选择伪状态 选择伪状态显示为菱形，有一个转移输入，两个或多个输出。下图显示不管到达哪一个状态，经过选择伪状态后的去向，取决于在伪状态中执行时所选择的消息格式。 连接伪状态 连接伪状态用来将多个状态转移链接在一起。一个单独的连接伪状态可以有一个或多个输入和一个或多个输出，监护可能应用于每一个转移，连接是没有语义的。连接可以把一个输入转移分成多个输出转移来实现一个静态分支。与之对照的是选择伪状态实现一个动态条件分支。 终止伪状态 进入终止伪状态是指状态机生命线已经终止。终止伪状态表示为叉号。 历史状态 历史状态用来当状态机中断时，恢复状态机之前状态。下面例图说明了历史状态的使用。这个例子是关于洗衣机的状态机。 在这个状态机中，当洗衣机运行时，它会按照&quot;Washing&quot; 到 Rinsing&quot;再到&quot;Spinning&quot;来进行。如果电源被切断 ，洗衣机会停止运行并进入&quot;Power Off&quot; 状态。当电源恢复，运行状态在&quot;History State&quot;符号处进入，表示它会从上次离开的地方恢复。 并发区 一个状态可以被分成几个不同的区，包含同时存在和执行的子状态。下面的例子显示状态 “Applying Brakes”， “front brake&quot;和&quot;rear brakes” 将同时独立运作。注意使用了分叉和结合伪状态而不是选择和合并伪状态。这些符号用来同步并发的线程。 用例图 用例图用来记录系统的需求，它提供系统与用户及其他参与者的一种通信手段。 执行者 用例图显示了系统和系统外实体之间的交互。这些实体被引用为执行者。执行者代表角色，可以包括：用户，外部硬件和其他系统。执行者往往被画成简笔画小人。也可以用带«actor»关键字的类矩形表示。 在下图中，执行者可以详细的泛化其他执行者: 用例 用例是有意义的单独工作单元。它向系统外部的人或事提供一个易于观察的高层次行为视图。 用例的标注符号是一个椭圆。 使用用例的符号是带可选择箭头的连接线，箭头显示控制的方向。下图说明执行者 &quot;Customer&quot;使用 &quot;Withdraw&quot;用例。 用途连接器（uses connector）可以有选择性的在每一个端点有多重性值，如下图，显示客户一次可能只执行一次取款交易。但是银行可以同时执行许多取款交易。 用例定义 一个典型的用例包括: 名称和描述 - 用例通常用一个动词词组定义，而且有一个简短的文字说明。 需求 - 需求定义了一个用例必须提供给终端用户的正式功能性需求。它们符合构造方法建立的功能性规范。一个需求是用例将执行一个动作或提供多个值给系统的约定或承诺。 约束 - 一个约束是一个用例运行的条件或限制。它包括：前置条件，后置条件和不变化条件 。前置条件指明了用例在发生之前需要符合的条件。后置条件用来说明在用例执行之后一些条件必须为&quot;真&quot;。不变化条件说明用例整个执行过程中该条件始终为&quot;真&quot;。 情形 - 情形是用例的实例在执行过程中，事件发生流程的形式描述。它定义了系统和外部执行者之间的事件指定顺序。通常用文本方式来表示，并对应时序图中的文字描述。 情形图 附加信息 包含用例 用例可能包含其他用例的功能来作为它正常处理的一部分。通常它假设，任何被包含的用例在基本程序运行时每一次都会被调用。下面例子：用例“卡的确认” 在运行时，被用例“取钱”当作一个子部分。 用例可以被一个或多个用例包含。通过提炼通用的行为，将它变成可以多次重复使用的用例。有助于降低功能重复级别。 扩展用例 一个用例可以被用来扩展另一个用例的行为，通常使用在特别情况下。例如：假设在修改一个特别类型的客户订单之前，用户必须得到某种更高级别的许可，然后“获得许可”用例将有选择的扩展常规的“修改订单”用例。 扩展点 - 扩展用例的加入点被定义为扩展点。 系统边界 - 它用来显示用例在系统内部，执行者在系统的外部。 通信图 通信图，以前称之为协作图，是一种交互图，所显示消息与时序图相似，但是它更侧重于对象间的联系。 在通信图中，对象之间显示关联连接器。消息附加到这些关联上，显示短箭头指向消息流的方向。消息的顺序通过编号码显示。 下面的两个图用通信图和时序图分别显示相同的信息。尽管我们可能从通信图的编号码得到消息顺序，但它不是立即可见的。通信图十分清楚的显示了邻近对象间全部完整的消息传递。 交互概述图 一个交互概览图是活动图的一种形式，它的节点代表交互图。交互图包含时序图，通信图，交互概览图和时间图。 大多数交互概览图标注与活动图一样。例如：起始，结束，判断，合并，分叉和结合节点是完全相同。并且，交互概览图介绍了两种新的元素：交互发生和交互元素。 交互发生 交互发生引用现有的交互图。显示为一个引用框，左上角显示 “ref” 。被引用的图名显示在框的中央。 交互元素 交互元素与交互发生相似之处在于都是在一个矩形框中显示一个现有的交互图。不同之处在内部显示参考图的内容不同。 将它们放在一起 所有的活动图控件，都可以相同地被使用于交互概览图，如：分叉，结合，合并等等。它把控制逻辑放入较低一级的图中。下面的例子就说明了一个典型的销售过程。子过程是从交互发生抽象而来。 时序图 时序图是交互图的一种形式，它显示对象沿生命线发展，对象之间随时间的交互表示为从源生命线指向目标生命线的消息。时序图能很好地显示那些对象与其它那些对象通信，什么消息触发了这些通信，时序图不能很好显示复杂过程的逻辑。 生命线 一条生命线在时序图中代表一个独立的参与者。表示为包含对象名的矩形，如果它的名字是&quot;self&quot;，则说明该生命线代表控制带时序图的类元。 有时，时序图会包含一个顶端是执行者的生命线。这情况说明掌握这个时序图的是用例。健壮图中的边界，控制和实体元素也可以有生命线。 消息 消息显示为箭头。消息可以完成传输，也可能丢失和找回，它可以是同步的，也可以是异步的，即可以是调用，也可以是信号。在下图中，第一条消息是同步消息(标为实箭头)完成传输，并隐含一条返回消息。第二条消息是异步消息 (标为实线箭头)，第三条是异步返回消息(标为虚线)。 执行发生 向下延伸的细条状矩形表示执行事件或控制焦点的激活。在上图中有三个执行事件。第一个是源对象发送两条消息和收到两条回复。第二个是目标对象收到一条同步消息并返回一条回复。第三个是目标对象收到一条异步消息并返回一条回复。 内部通信 内部消息表现为一个操作的递归调用，或一个方法调用属于同一个对象的其他方法。显示为生命线上执行事件的嵌套控制焦点。 迷路消息和拾取消息 迷路消息是那些发送了却没有到达指定接收者，或者到达的接收者不再当前图中。拾取消息是收到来自那些未知的发送者，或者来自没有显示在当前图的发送者的消息。它们都表明是去往或来自一个终点元素。 生命线开始与结束 生命线可以在时序图时间刻度范围内创建和销毁，在下面的例子中，生命线被停止符号（叉号）终止。在前面的例子中，生命线顶端的符号（Child）显示在比创建它的对象符号（parent）沿页面要低的位置上。下图显示创建和终止对象。 时间和期限约束 消息默认显示为水平线。因为生命线显示为沿屏幕向下的时间通道，所以当给实时系统建模，或是有时间约束的业务过程建模，考虑执行动作所需时间长度是很重要的。因此可以给消息设置一个期限约束，这样的消息显示为下斜线。 复合片段 如前面所说，时序图不适合表达复杂的过程逻辑。在一种情况下，有许多机制允许把一定程度的过程逻辑加入到图中，并把它们放到复合片段的标题下。复合片段是一个或多个处理顺序被包含在一个框架中，并在指定名称的环境下执行。片段可以是: 选择性片段 (显示 “alt”) 为 if…then…else 结构建模。 选项片段 (显示 “opt”) 为 “switch”(开关) 结构建模。 中断片段对被处理事件的可选择顺序建模，而不是该图的其他部分。 并行片段(显示 “par”) 为并发处理建模。 弱顺序片段 (显示 “seq”) 包含了一组消息，这组消息必须在后继片段开始之前被处理。但不会把片段内消息的先后顺序强加到不共享同一条生命线的消息上。 严格顺序片段 (显示 “strict”) 包含了一系列需要按照给定顺序处理的消息。 非片段 (显示 “neg”) 包含了一系列不可用的消息。 关键片段 具有关键部分。 忽略片段 声明一个没有意义的消息，如果它出现在当前上下文中。 考虑片段与忽略片段相反，不包含在考虑片段内的消息都应该被忽略。 断言片段 (显示 “assert”)标明任何没有显示为声明操作数的顺序都是无效的。 循环片段 包含一系列被重复的消息。 下图显示的是循环片段： 这也是一个类似于复合片段的交互发生。 交互发生被其他图参考，显示为左上角带&quot;ref&quot;，将被参考图名显示在方框的中间。 门 门是连接片段内消息和片段外消息的连接点。 在 EA 中，门显示为片段框架上的小正方形。作用为时序图与页面外的连接器。 用来表示进来的消息源，或者出去消息的终点。下面两个图显示它们在实践中的使用。注意：&quot; top level diagram&quot;中的门用消息箭头指向参考片段，在这里没有必要把它画成方块。 部分分解 一个对象可以引出多条生命线，使得对象内部和对象之间的消息显示在同一图上。 状态常量/延续 状态常量是生命线的约束，运行时始终为&quot;真&quot;。显示为两侧半圆的矩形，如下图： 延续虽与状态常量有同样的标注，但是被用于复合片段，并可以延伸跨越多条生命线。 时间图 UML 时间图被用来显示随时间变化，一个或多个元素的值或状态的更改。也显示时控事件之间的交互和管理它们的时间和期限约束。 状态生命线 状态生命线显示随时间变化，一个单项状态的改变。不论时间单位如何选择，X 轴显示经过的时间，Y 轴被标为给出状态的列表。状态生命线如下所示： 值生命线 值生命线显示随时间变化，一个单项的值的变化。X 轴显示经过的时间，时间单位为任意，和状态生命线一样。平行线之间显示值，每次值变化，平行线交叉。如下图所示。 将它们放在一起 状态和值的生命线能叠加组合。它们必须有相同的 X 轴。 消息可以从一个生命线传递到另一个。每一个状态和值的变换能有一个定义的事件，一个时间限制是指一个事件何时必须发生，和一个期限限制说明状态或值多长时间必须有效。一旦这些已经被应用，其时间图可能显示如下。 UML 工具 UML 工具非常多，到底哪种工具好，真的是仁者见仁智者见智。这里列举一些我接触过的 UML 工具： 亿图 国内开发的、收费的绘图工具。图形模板、素材非常全面，样式也很精美，可以导出为 word、pdf、图片。 亿图官网 Visio Office 的绘图工具，特点是简单、清晰。 Visio 官网 StarUML 样式精美，功能全面的 UML 工具。 StarUML 官网 Astah 样式不错，功能全面的绘图工具。 Astah 官网 ArgoUML UML 工具。 ArgoUML 官网 ProcessOn 在线绘图工具，特点是简洁、清晰。 ProcessOn 官网 drawio 开源的在线绘图工具，特点是简洁、清晰。 drawio 官网 更多内容 📓 本文已归档到：「blog」 参考资料 Wiki-UML Sparx UML 教程 OMG UML UML Tutorial W3Cschool UML 教程 UML 学习入门就这一篇文章 http://www.cnblogs.com/ywqu/category/223486.html]]></content>
      <categories>
        <category>design</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>uml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase Java API]]></title>
    <url>%2Fblog%2F2019%2F03%2F06%2Fbigdata%2Fhbase%2Fhbase-api-java%2F</url>
    <content type="text"><![CDATA[HBase Java API 更多内容 参考资料 更多内容 📓 本文已归档到：「blog」 参考资料 https://blog.csdn.net/jiyiqinlovexx/article/details/36526433 https://blog.csdn.net/u010967382/article/details/38046821]]></content>
  </entry>
  <entry>
    <title><![CDATA[计算机网络概述]]></title>
    <url>%2Fblog%2F2019%2F02%2F20%2Fcommunication%2Fnetwork-guide%2F</url>
    <content type="text"><![CDATA[计算机网络概述 计算机网络是指将地理位置不同的具有独立功能的多台计算机及其外部设备，通过通信线路连接起来，在网络操作系统，网络管理软件及网络通信协议的管理和协调下，实现资源共享和信息传递的计算机系统。 💡 指南 学习之前，先看一下入门三问： 一、什么是计算机网络？ 计算机网络是指将地理位置不同的具有独立功能的多台计算机及其外部设备，通过通信线路连接起来，在网络操作系统，网络管理软件及网络通信协议的管理和协调下，实现资源共享和信息传递的计算机系统。 ——摘自百度百科 二、为什么学习计算机网络？ 计算机网络是计算机科学的基础课程，也是计算机专业考研必考科目，可见其重要性。作为一名程序员，了解计算机网络，对于 Web 领域，通信领域的开发有莫大的帮助。 在浏览器中访问网页的原理是什么？Wifi 是如何工作的？防火墙是如何保障网络安全的？什么是安全证书？Cookie 和 Session 是什么东西？。。。 如果你接触过这些技术，如果你想了解这些技术的原理，那么你就有必要学习一下计算机网络了。 三、如何学习计算机网络？ 本人有 2 年通信领域开发经验，从事通信设备上的协议开发。就我个人的学习经验来看，学习计算机网络可以分为以下阶段： 基础阶段——一般性的了解网络协议分层及各层功能 了解计算机网络协议分层（OSI）有哪些层，分层的依据是什么（即每层的功能是什么） 了解每层的主要通信设备有哪些； 了解每层有哪些重要网络协议，这些协议有什么作用，基本原理是什么？ 了解每层的传输数据形式（如：报文、帧等） 进阶阶段——系统学习计算机网络知识，将各层主要协议功能串联起来 学习 TCP/IP 详解 卷 1、卷 2、卷 3（内容详实，但文字较为晦涩，不适合初学者） 专业阶段——根据业务领域，有针对性的学习 网络协议很多，而且专业性非常强。精通所有协议，几乎是不可能的，所以有必要根据自己的业务领域，有针对性的深入学习协议。如果你是做 web 开发，那么你很有必要认真学习一下 HTTP、DNS 协议；如果你是做路由器、交换机领域通信开发，那么你应该更深入学习一下 IP/TCP/UDP 协议。。。 如何深入学习协议，最好的学习方式，就是深入学习 RFC，并结合实际的协议报文去了解。 核心概念 计算机网络 - 计算机网络（computer network），通常也简称网络，是利用通信设备和线路将地理位置不同的、功能独立的多个计算机系统连接起来，以功能完善的网络软件实现网络的硬件、软件及资源共享和信息传递的系统。简单的说即连接两台或多台计算机进行通信的系统。 互联网 - 互联网（Internet），即网络的网络。 拓扑结构 计算机网络的拓扑结构可分为： 网型拓扑网型网（Mesh network） 环型拓扑环型网（Ring network） 星型拓扑星型网（Star network） 树状拓扑树型网（Tree network） 总线拓扑总线网（Bus network） 作用范围 广域网 WAN（Wide Area Network） 城域网 MAN（Metropolitan Area Network） 局域网 LAN（Local Area Network） 个人区域网 PAN（Personal Area Network） 性能指标 速率 - 速率的单位是 bit/s（比特每秒）。 带宽（bandwidth） - 带宽有以下两种不同的意义。 信号的带宽是指该信号所包含的各种不同频率成分所占据的频率范围。这种意义的带宽的单位是赫 （或千赫，兆赫，吉赫等）。 网络的带宽表示在单位时间内从网络中的某一点到另一点所能通过的最高数据率。这种意义的带宽的单位是 bit/s（比特每秒）。 吞吐量（throughput） - 吞吐量表示在单位时间内通过某个网络（或信道、接口）的数据量。例如，对于一个 100 Mbit/s 的以太网，其额定速率是 100 Mbit/s。 时延（delay） 总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延 体系结构 物理层 - 关键词：调制、解调、数字信号、模拟信号、通信媒介、信道复用 数据链路层 - 关键词：点对点信道、广播信道、PPP、CSMA/CD、局域网、以太网、MAC、适配器、集线器、网桥、交换机 网络层 - 关键词：IP、ICMP、ARP、路由 传输层 - 关键词：UDP、TCP、滑动窗口、拥塞控制、三次握手 应用层 - 关键词：HTTP、DNS、FTP、TELNET、DHCP 物理层（Physical Layer） - 物理层只接收和发送一串比特(bit)流，不考虑信息的意义和信息结构。 数据单元：比特流。 典型设备：光纤、同轴电缆、双绞线、中继器和集线器。 数据链路层（Data Link Layer） - 网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。 主要协议：PPP、CSMA/CD 等。 数据单元：帧（frame）。 典型设备：二层交换机、网桥、网卡。 网络层（network layer） - 为分组交换网上的不同主机提供通信服务。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组或包进行传送。 主要协议：IP。 数据单元：IP 数据报（packet）。 典型设备：网关、路由器。 传输层（transport layer） - 为两台主机中进程间的通信提供通用的数据传输服务。 主要协议：TCP、UDP。 数据单元：报文段（segment）或用户数据报。 会话层（Session Layer） - 会话层不参与具体的传输，它提供包括访问验证和会话管理在内的建立和维护应用之间通信的机制。 表示层（Presentation Layer） - 表示层是为在应用过程之间传送的信息提供表示方法的服务，它关心的只是发出信息的语法与语义。表示层要完成某些特定的功能，主要有不同数据编码格式的转换，提供数据压缩、解压缩服务，对数据进行加密、解密。 应用层（application layer） - 通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程间通信和交互的规则。 主要协议：HTTP、DNS、SMTP、Telnet、FTP、SNMP 等。 数据单元：报文（message）。 📚 学习资源 书 谢希仁, 计算机网络 - 国内很多大学将其作为计算机网络课程的指定教材，通俗易懂，适合作为入门教材。 W·Richard Stevens, TCP/IP 详解 卷 1：协议 - TCP/IP 详解三部曲，适合作为进阶教材 W·Richard Stevens, TCP/IP 详解 卷 2：实现 W·Richard Stevens, TCP/IP 详解 卷 3：TCP 事务协议、HTTP、NNTP 和 UNIX 域协议 站点 https://www.rfc-editor.org/ - 在线查阅、下载 RFC 文档 🚪 传送门 | 回首頁 |]]></content>
      <categories>
        <category>communication</category>
      </categories>
      <tags>
        <tag>communication</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络协议之 DNS]]></title>
    <url>%2Fblog%2F2018%2F10%2F17%2Fcommunication%2Fdns%2F</url>
    <content type="text"><![CDATA[网络协议之 DNS 📓 本文已归档到：「blog」 域名系统（英文：Domain Name System，缩写：DNS）是互联网的一项服务。它作为将域名和 IP 地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS 使用 TCP 和 UDP 端口 53。当前，对于每一级域名长度的限制是 63 个字符，域名总长度则不能超过 253 个字符。 关键词：DNS, 域名解析 简介 什么是 DNS？ 什么是域名？ DNS 的分层 DNS 服务类型 记录类型 域名解析 Linux 上的域名相关命令 hostname nslookup 更多内容 简介 什么是 DNS？ DNS 是一个应用层协议。 域名系统 (DNS) 的作用是将人类可读的域名 (如，www.example.com) 转换为机器可读的 IP 地址 (如，192.0.2.44)。 什么是域名？ 域名是由一串用点分隔符 . 组成的互联网上某一台计算机或计算机组的名称，用于在数据传输时标识计算机的方位。域名可以说是一个 IP 地址的代称，目的是为了便于记忆后者。例如，wikipedia.org 是一个域名，和 IP 地址 208.80.152.2 相对应。人们可以直接访问 wikipedia.org 来代替 IP 地址，然后域名系统（DNS）就会将它转化成便于机器识别的 IP 地址。这样，人们只需要记忆 wikipedia.org 这一串带有特殊含义的字符，而不需要记忆没有含义的数字。 DNS 的分层 域名系统是分层次的。 在域名系统的层次结构中，各种域名都隶属于域名系统根域的下级。域名的第一级是顶级域，它包括通用顶级域，例如 .com、.net 和 .org；以及国家和地区顶级域，例如 .us、.cn 和 .tk。顶级域名下一层是二级域名，一级一级地往下。这些域名向人们提供注册服务，人们可以用它创建公开的互联网资源或运行网站。顶级域名的管理服务由对应的域名注册管理机构（域名注册局）负责，注册服务通常由域名注册商负责。 DNS 服务类型 授权型 DNS - 一种授权型 DNS 服务提供一种更新机制，供开发人员用于管理其公用 DNS 名称。然后，它响应 DNS 查询，将域名转换为 IP 地址，以便计算机可以相互通信。授权型 DNS 对域有最终授权且负责提供递归型 DNS 服务器对 IP 地址信息的响应。Amazon Route 53 是一种授权型 DNS 系统。 递归型 DNS - 客户端通常不会对授权型 DNS 服务直接进行查询。而是通常连接到称为解析程序的其他类型 DNS 服务，或递归型 DNS 服务。递归型 DNS 服务就像是旅馆的门童：尽管没有任何自身的 DNS 记录，但是可充当代表您获得 DNS 信息的中间程序。如果递归型 DNS 拥有已缓存或存储一段时间的 DNS 参考，那么它会通过提供源或 IP 信息来响应 DNS 查询。如果没有，则它会将查询传递到一个或多个授权型 DNS 服务器以查找信息。 记录类型 DNS 中，常见的资源记录类型有： NS 记录（域名服务） ─ 指定解析域名或子域名的 DNS 服务器。 MX 记录（邮件交换） ─ 指定接收信息的邮件服务器。 A 记录（地址） ─ 指定域名对应的 IPv4 地址记录。 AAAA 记录（地址） ─ 指定域名对应的 IPv6 地址记录。 CNAME（规范） ─ 一个域名映射到另一个域名或 CNAME 记录（ example.com 指向 www.example.com ）或映射到一个 A记录。 PTR 记录（反向记录） ─ PTR 记录用于定义与 IP 地址相关联的名称。 PTR 记录是 A 或 AAAA 记录的逆。 PTR 记录是唯一的，因为它们以 .arpa 根开始并被委派给 IP 地址的所有者。 详细可以参考：维基百科 - 域名服务器记录类型列表 域名解析 主机名到 IP 地址的映射有两种方式： 静态映射 - 在本机上配置域名和 IP 的映射，旨在本机上使用。Windows 和 Linux 的 hosts 文件中的内容就属于静态映射。 动态映射 - 建立一套域名解析系统（DNS），只在专门的 DNS 服务器上配置主机到 IP 地址的映射，网络上需要使用主机名通信的设备，首先需要到 DNS 服务器查询主机所对应的 IP 地址。 通过域名去查询域名服务器，得到 IP 地址的过程叫做域名解析。在解析域名时，一般先静态域名解析，再动态解析域名。可以将一些常用的域名放入静态域名解析表中，这样可以大大提高域名解析效率。 上图展示了一个动态域名解析的流程，步骤如下： 用户打开 Web 浏览器，在地址栏中输入 www.example.com，然后按 Enter 键。 www.example.com 的请求被路由到 DNS 解析程序，这一般由用户的 Internet 服务提供商 (ISP) 进行管理，例如有线 Internet 服务提供商、DSL 宽带提供商或公司网络。 ISP 的 DNS 解析程序将 www.example.com 的请求转发到 DNS 根名称服务器。 ISP 的 DNS 解析程序再次转发 www.example.com 的请求，这次转发到 .com 域的一个 TLD 名称服务器。.com 域的名称服务器使用与 example.com 域相关的四个 Amazon Route 53 名称服务器的名称来响应该请求。 ISP 的 DNS 解析程序选择一个 Amazon Route 53 名称服务器，并将 www.example.com 的请求转发到该名称服务器。 Amazon Route 53 名称服务器在 example.com 托管区域中查找 www.example.com 记录，获得相关值，例如，Web 服务器的 IP 地址 (192.0.2.44)，并将 IP 地址返回至 DNS 解析程序。 ISP 的 DNS 解析程序最终获得用户需要的 IP 地址。解析程序将此值返回至 Web 浏览器。DNS 解析程序还会将 example.com 的 IP 地址缓存 (存储) 您指定的时长，以便它能够在下次有人浏览 example.com 时更快地作出响应。有关更多信息，请参阅存活期 (TTL)。 Web 浏览器将 www.example.com 的请求发送到从 DNS 解析程序中获得的 IP 地址。这是您的内容所处位置，例如，在 Amazon EC2 实例中或配置为网站终端节点的 Amazon S3 存储桶中运行的 Web 服务器。 192.0.2.44 上的 Web 服务器或其他资源将 www.example.com 的 Web 页面返回到 Web 浏览器，且 Web 浏览器会显示该页面。 🔔 注意：只有配置了域名服务器，才能执行域名解析。 例如，在 Linux 中执行 vim /etc/resolv.conf 命令，在其中添加下面的内容来配置域名服务器地址： &gt; nameserver 218.2.135.1&gt; Linux 上的域名相关命令 hostname hostname 命令用于查看和设置系统的主机名称。环境变量 HOSTNAME 也保存了当前的主机名。在使用 hostname 命令设置主机名后，系统并不会永久保存新的主机名，重新启动机器之后还是原来的主机名。如果需要永久修改主机名，需要同时修改 /etc/hosts 和 /etc/sysconfig/network 的相关内容。 参考：http://man.linuxde.net/hostname 示例： $ hostnameAY1307311912260196fcZ nslookup nslookup 命令是常用域名查询工具，就是查 DNS 信息用的命令。 参考：http://man.linuxde.net/nslookup 示例： [root@localhost ~]# nslookup www.jsdig.comServer: 202.96.104.15Address: 202.96.104.15#53Non-authoritative answer:www.jsdig.com canonical name = host.1.jsdig.com.Name: host.1.jsdig.comAddress: 100.42.212.8 更多内容 维基百科 - 域名 维基百科 - 域名系统 维基百科 - 域名服务器记录类型列表 什么是 DNS？ RFC 1034 RFC 1035]]></content>
      <categories>
        <category>communication</category>
      </categories>
      <tags>
        <tag>communication</tag>
        <tag>network</tag>
        <tag>protocol</tag>
        <tag>application</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码坏味道之变革的障碍]]></title>
    <url>%2Fblog%2F2018%2F10%2F13%2Fdesign%2Frefactor%2F%E4%BB%A3%E7%A0%81%E5%9D%8F%E5%91%B3%E9%81%93%E4%B9%8B%E5%8F%98%E9%9D%A9%E7%9A%84%E9%9A%9C%E7%A2%8D%2F</url>
    <content type="text"><![CDATA[代码坏味道之变革的障碍 📓 本文已归档到：「blog」 翻译自：https://sourcemaking.com/refactoring/smells/change-preventers 变革的障碍(Change Preventers)这组坏味道意味着：当你需要改变一处代码时，却发现不得不改变其他的地方。这使得程序开发变得复杂、代价高昂。 发散式变化 平行继承体系 霰弹式修改 扩展阅读 参考资料 发散式变化 发散式变化(Divergent Change) 类似于 霰弹式修改(Shotgun Surgery) ，但实际上完全不同。发散式变化(Divergent Change) 是指一个类受多种变化的影响。霰弹式修改(Shotgun Surgery) 是指多种变化引发多个类相应的修改。 特征 你发现你想要修改一个函数，却必须要同时修改许多不相关的函数。例如，当你想要添加一个新的产品类型时，你需要同步修改对产品进行查找、显示、排序的函数。 问题原因 通常，这种发散式修改是由于编程结构不合理或者“复制-粘贴式编程”。 解决办法 运用 提炼类(Extract Class) 拆分类的行为。 收益 提高代码组织结构 减少重复代码 重构方法说明 提炼类(Extract Class) 问题 某个类做了不止一件事。 解决 建立一个新类，将相关的字段和函数从旧类搬移到新类。 平行继承体系 平行继承体系(Parallel Inheritance Hierarchies) 其实是 霰弹式修改(Shotgun Surgery) 的特殊情况。 特征 每当你为某个类添加一个子类，必须同时为另一个类相应添加一个子类。这种情况的典型特征是：某个继承体系的类名前缀或类名后缀完全相同。 问题原因 起初的继承体系很小，随着不断添加新类，继承体系越来越大，也越来越难修改。 解决方法 一般策略是：让一个继承体系的实例引用另一个继承体系的实例。如果再接再厉运用 搬移函数(Move Method) 和 搬移字段(Move Field)，就可以消除引用端的继承体系。 收益 更好的代码组织 减少重复代码 何时忽略 有时具有并行类层次结构只是一种为了避免程序体系结构更混乱的方法。如果你发现尝试消除平行继承体系导致代码更加丑陋，那么你应该回滚你的修改。 重构方法说明 搬移函数(Move Method) 问题 你的程序中，有个函数与其所驻类之外的另一个类进行更多交流：调用后者，或被后者调用。 解决 在该函数最常引用的类中建立一个有着类似行为的新函数。将旧函数变成一个单纯的委托函数，或是旧函数完全移除。 搬移字段(Move Field) 问题 在你的程序中，某个字段被其所驻类之外的另一个类更多地用到。 解决 在目标类新建一个字段，修改源字段的所有用户，令他们改用新字段。 霰弹式修改 霰弹式修改(Shotgun Surgery) 类似于 发散式变化(Divergent Change) ，但实际上完全不同。发散式变化(Divergent Change) 是指一个类受多种变化的影响。霰弹式修改(Shotgun Surgery) 是指多种变化引发多个类相应的修改。 特征 任何修改都需要在许多不同类上做小幅度修改。 问题原因 一个单一的职责被拆分成大量的类。 解决方法 运用搬移函数(Move Method) 和 搬移字段(Move Field) 来搬移不同类中相同的行为到一个独立类中。如果没有适合存放搬移函数或字段的类，就创建一个新类。 通常，可以运用 将类内联化(Inline Class) 将一些列相关行为放进同一个类。 收益 更好的代码组织 减少重复代码 更易维护 重构方法说明 搬移函数(Move Method) 问题 你的程序中，有个函数与其所驻类之外的另一个类进行更多交流：调用后者，或被后者调用。 解决 在该函数最常引用的类中建立一个有着类似行为的新函数。将旧函数变成一个单纯的委托函数，或是旧函数完全移除。 搬移字段(Move Field) 问题 在你的程序中，某个字段被其所驻类之外的另一个类更多地用到。 解决 在目标类新建一个字段，修改源字段的所有用户，令他们改用新字段。 将类内联化(Inline Class) 问题 某个类没有做太多事情。 解决 将这个类的所有特性搬移到另一个类中，然后移除原类。 扩展阅读 代码的坏味道和重构 代码坏味道之代码臃肿 代码坏味道之滥用面向对象 代码坏味道之变革的障碍 代码坏味道之非必要的 代码坏味道之耦合 参考资料 重构——改善既有代码的设计 - by Martin Fowler https://sourcemaking.com/refactoring]]></content>
      <categories>
        <category>design</category>
        <category>refactor</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>refactor</tag>
        <tag>code-smell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码坏味道之非必要的]]></title>
    <url>%2Fblog%2F2018%2F10%2F13%2Fdesign%2Frefactor%2F%E4%BB%A3%E7%A0%81%E5%9D%8F%E5%91%B3%E9%81%93%E4%B9%8B%E9%9D%9E%E5%BF%85%E8%A6%81%E7%9A%84%2F</url>
    <content type="text"><![CDATA[代码坏味道之非必要的 📓 本文已归档到：「blog」 翻译自：https://sourcemaking.com/refactoring/smells/dispensables 非必要的(Dispensables)这组坏味道意味着：这样的代码可有可无，它的存在反而影响整体代码的整洁和可读性。 冗余类 夸夸其谈未来性 纯稚的数据类 过多的注释 重复代码 扩展阅读 参考资料 冗余类 冗余类(Lazy Class) 理解和维护总是费时费力的。如果一个类不值得你花费精力，它就应该被删除。 问题原因 也许一个类的初始设计是一个功能完全的类，然而随着代码的变迁，变得没什么用了。 又或者类起初的设计是为了支持未来的功能扩展，然而却一直未派上用场。 解决方法 没什么用的类可以运用 将类内联化(Inline Class) 来干掉。 如果子类用处不大，试试 折叠继承体系(Collapse Hierarchy) 。 收益 减少代码量 易于维护 何时忽略 有时，创建冗余类是为了描述未来开发的意图。在这种情况下，尝试在代码中保持清晰和简单之间的平衡。 重构方法说明 将类内联化(Inline Class) 问题 某个类没有做太多事情。 解决 将这个类的所有特性搬移到另一个类中，然后移除原类。 折叠继承体系(Collapse Hierarchy) 问题 超类和子类之间无太大区别。 解决 将它们合为一体。 夸夸其谈未来性 夸夸其谈未来性(Speculative Generality) 存在未被使用的类、函数、字段或参数。 问题原因 有时，代码仅仅为了支持未来的特性而产生，然而却一直未实现。结果，代码变得难以理解和维护。 解决方法 如果你的某个抽象类其实没有太大作用，请运用 折叠继承体系(Collapse Hierarch) 。 不必要的委托可运用 将类内联化(Inline Class) 消除。 无用的函数可运用 内联函数(Inline Method) 消除。 函数中有无用的参数应该运用 移除参数(Remove Parameter) 消除。 无用字段可以直接删除。 收益 减少代码量。 更易维护。 何时忽略 如果你在一个框架上工作，创建框架本身没有使用的功能是非常合理的，只要框架的用户需要这个功能。 删除元素之前，请确保它们不在单元测试中使用。如果测试需要从类中获取某些内部信息或执行特殊的测试相关操作，就会发生这种情况。 重构方法说明 折叠继承体系(Collapse Hierarchy) 问题 超类和子类之间无太大区别。 解决 将它们合为一体。 将类内联化(Inline Class) 问题 某个类没有做太多事情。 解决 将这个类的所有特性搬移到另一个类中，然后移除原类。 内联函数(Inline Method) 问题 一个函数的本体比函数名更清楚易懂。 class PizzaDelivery &#123; //... int getRating() &#123; return moreThanFiveLateDeliveries() ? 2 : 1; &#125; boolean moreThanFiveLateDeliveries() &#123; return numberOfLateDeliveries &gt; 5; &#125;&#125; 解决 在函数调用点插入函数本体，然后移除该函数。 class PizzaDelivery &#123; //... int getRating() &#123; return numberOfLateDeliveries &gt; 5 ? 2 : 1; &#125;&#125; 移除参数(Remove Parameter) 问题 函数本体不再需要某个参数。 解决 将该参数去除。 纯稚的数据类 纯稚的数据类(Data Class) 指的是只包含字段和访问它们的 getter 和 setter 函数的类。这些仅仅是供其他类使用的数据容器。这些类不包含任何附加功能，并且不能对自己拥有的数据进行独立操作。 问题原因 当一个新创建的类只包含几个公共字段（甚至可能几个 getters / setters）是很正常的。但是对象的真正力量在于它们可以包含作用于数据的行为类型或操作。 解决方法 如果一个类有公共字段，你应该运用 封装字段(Encapsulated Field) 来隐藏字段的直接访问方式。 如果这些类含容器类的字段，你应该检查它们是不是得到了恰当的封装；如果没有，就运用 封装集合(Encapsulated Collection) 把它们封装起来。 找出这些 getter/setter 函数被其他类运用的地点。尝试以 搬移函数(Move Method) 把那些调用行为搬移到 纯稚的数据类(Data Class) 来。如果无法搬移这个函数，就运用 提炼函数(Extract Method) 产生一个可搬移的函数。 在类已经充满了深思熟虑的函数之后，你可能想要摆脱旧的数据访问方法，以提供适应面较广的类数据访问接口。为此，可以运用 移除设置函数(Remove Setting Method) 和 隐藏函数(Hide Method) 。 收益 提高代码的可读性和组织性。特定数据的操作现在被集中在一个地方，而不是在分散在代码各处。 帮助你发现客户端代码的重复处。 重构方法说明 封装字段(Encapsulated Field) 问题 你的类中存在 public 字段。 class Person &#123; public String name;&#125; 解决 将它声明为 private，并提供相应的访问函数。 class Person &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String arg) &#123; name = arg; &#125;&#125; 封装集合(Encapsulated Collection) 问题 有个函数返回一个集合。 解决 让该函数返回该集合的一个只读副本，并在这个类中提供添加、移除集合元素的函数。 搬移函数(Move Method) 问题 你的程序中，有个函数与其所驻类之外的另一个类进行更多交流：调用后者，或被后者调用。 解决 在该函数最常引用的类中建立一个有着类似行为的新函数。将旧函数变成一个单纯的委托函数，或是旧函数完全移除。 提炼函数(Extract Method) 问题 你有一段代码可以组织在一起。 void printOwing() &#123; printBanner(); //print details System.out.println("name: " + name); System.out.println("amount: " + getOutstanding());&#125; 解决 移动这段代码到一个新的函数中，使用函数的调用来替代老代码。 void printOwing() &#123; printBanner(); printDetails(getOutstanding());&#125;void printDetails(double outstanding) &#123; System.out.println("name: " + name); System.out.println("amount: " + outstanding);&#125; 移除设置函数(Remove Setting Method) 问题 类中的某个字段应该在对象创建时被设值，然后就不再改变。 解决 去掉该字段的所有设值函数。 隐藏函数(Hide Method) 问题 有一个函数，从来没有被其他任何类用到。 解决 将这个函数修改为 private。 过多的注释 过多的注释(Comments) 注释本身并不是坏事。但是常常有这样的情况：一段代码中出现长长的注释，而它之所以存在，是因为代码很糟糕。 问题原因 注释的作者意识到自己的代码不直观或不明显，所以想使用注释来说明自己的意图。这种情况下，注释就像是烂代码的除臭剂。 最好的注释是为函数或类起一个恰当的名字。 如果你觉得一个代码片段没有注释就无法理解，请先尝试重构，试着让所有注释都变得多余。 解决方法 如果一个注释是为了解释一个复杂的表达式，可以运用 提炼变量(Extract Variable) 将表达式切分为易理解的子表达式。 如果你需要通过注释来解释一段代码做了什么，请试试 提炼函数(Extract Method) 。 如果函数已经被提炼，但仍需要注释函数做了什么，试试运用 函数改名(Rename Method) 来为函数起一个可以自解释的名字。 如果需要对系统某状态进行断言，请运用 引入断言(Introduce Assertion) 。 收益 代码变得更直观和明显。 何时忽略 注释有时候很有用： 当解释为什么某事物要以特殊方式实现时。 当解释某种复杂算法时。 当你实在不知可以做些什么时。 重构方法说明 提炼变量(Extract Variable) 问题 你有个难以理解的表达式。 void renderBanner() &#123; if ((platform.toUpperCase().indexOf("MAC") &gt; -1) &amp;&amp; (browser.toUpperCase().indexOf("IE") &gt; -1) &amp;&amp; wasInitialized() &amp;&amp; resize &gt; 0 ) &#123; // do something &#125;&#125; 解决 将表达式的结果或它的子表达式的结果用不言自明的变量来替代。 void renderBanner() &#123; final boolean isMacOs = platform.toUpperCase().indexOf("MAC") &gt; -1; final boolean isIE = browser.toUpperCase().indexOf("IE") &gt; -1; final boolean wasResized = resize &gt; 0; if (isMacOs &amp;&amp; isIE &amp;&amp; wasInitialized() &amp;&amp; wasResized) &#123; // do something &#125;&#125; 提炼函数(Extract Method) 问题 你有一段代码可以组织在一起。 void printOwing() &#123; printBanner(); //print details System.out.println("name: " + name); System.out.println("amount: " + getOutstanding());&#125; 解决 移动这段代码到一个新的函数中，使用函数的调用来替代老代码。 void printOwing() &#123; printBanner(); printDetails(getOutstanding());&#125;void printDetails(double outstanding) &#123; System.out.println("name: " + name); System.out.println("amount: " + outstanding);&#125; 函数改名(Rename Method) 问题 函数的名称未能恰当的揭示函数的用途。 class Person &#123; public String getsnm();&#125; 解决 修改函数名。 class Person &#123; public String getSecondName();&#125; 引入断言(Introduce Assertion) 问题 某一段代码需要对程序状态做出某种假设。 double getExpenseLimit() &#123; // should have either expense limit or a primary project return (expenseLimit != NULL_EXPENSE) ? expenseLimit: primaryProject.getMemberExpenseLimit();&#125; 解决 以断言明确表现这种假设。 double getExpenseLimit() &#123; Assert.isTrue(expenseLimit != NULL_EXPENSE || primaryProject != null); return (expenseLimit != NULL_EXPENSE) ? expenseLimit: primaryProject.getMemberExpenseLimit();&#125; 注：请不要滥用断言。不要使用它来检查”应该为真“的条件，只能使用它来检查“一定必须为真”的条件。实际上，断言更多是用于自我检测代码的一种手段。在产品真正交付时，往往都会消除所有断言。 重复代码 重复代码(Duplicate Code) 重复代码堪称为代码坏味道之首。消除重复代码总是有利无害的。 问题原因 重复代码通常发生在多个程序员同时在同一程序的不同部分上工作时。由于他们正在处理不同的任务，他们可能不知道他们的同事已经写了类似的代码。 还有一种更隐晦的重复，特定部分的代码看上去不同但实际在做同一件事。这种重复代码往往难以找到和消除。 有时重复是有目的性的。当急于满足 deadline，并且现有代码对于要交付的任务是“几乎正确的”时，新手程序员可能无法抵抗复制和粘贴相关代码的诱惑。在某些情况下，程序员只是太懒惰。 解决方法 同一个类的两个函数含有相同的表达式，这时可以采用 提炼函数(Extract Method) 提炼出重复的代码，然后让这两个地点都调用被提炼出来的那段代码。 如果两个互为兄弟的子类含有重复代码： 首先对两个类都运用 提炼函数(Extract Method) ，然后对被提炼出来的函数运用 函数上移(Pull Up Method) ，将它推入超类。 如果重复代码在构造函数中，运用 构造函数本体上移(Pull Up Constructor Body) 。 如果重复代码只是相似但不是完全相同，运用 塑造模板函数(Form Template Method) 获得一个 模板方法模式(Template Method) 。 如果有些函数以不同的算法做相同的事，你可以选择其中较清晰地一个，并运用 替换算法(Substitute Algorithm) 将其他函数的算法替换掉。 如果两个毫不相关的类中有重复代码： 请尝试运用 提炼超类(Extract Superclass) ，以便为维护所有先前功能的这些类创建一个超类。 如果创建超类十分困难，可以在一个类中运用 提炼类(Extract Class) ，并在另一个类中使用这个新的组件。 如果存在大量的条件表达式，并且它们执行完全相同的代码（仅仅是它们的条件不同），可以运用 合并条件表达式(Consolidate Conditional Expression) 将这些操作合并为单个条件，并运用 提炼函数(Extract Method) 将该条件放入一个名字容易理解的独立函数中。 如果条件表达式的所有分支都有部分相同的代码片段：可以运用 合并重复的条件片段(Consolidate Duplicate Conditional Fragments) 将它们都存在的代码片段置于条件表达式外部。 收益 合并重复代码会简化代码的结构，并减少代码量。 代码更简化、更易维护。 重构方法说明 提炼函数(Extract Method) 问题 你有一段代码可以组织在一起。 void printOwing() &#123; printBanner(); //print details System.out.println("name: " + name); System.out.println("amount: " + getOutstanding());&#125; 解决 移动这段代码到一个新的函数中，使用函数的调用来替代老代码。 void printOwing() &#123; printBanner(); printDetails(getOutstanding());&#125;void printDetails(double outstanding) &#123; System.out.println("name: " + name); System.out.println("amount: " + outstanding);&#125; 函数上移(Pull Up Method) 问题 有些函数，在各个子类中产生完全相同的结果。 解决 将该函数移至超类。 构造函数本体上移(Pull Up Constructor Body) 问题 你在各个子类中拥有一些构造函数，它们的本体几乎完全一致。 class Manager extends Employee &#123; public Manager(String name, String id, int grade) &#123; this.name = name; this.id = id; this.grade = grade; &#125; //...&#125; 解决 在超类中新建一个构造函数，并在子类构造函数中调用它。 class Manager extends Employee &#123; public Manager(String name, String id, int grade) &#123; super(name, id); this.grade = grade; &#125; //...&#125; 塑造模板函数(Form Template Method) 问题 你有一些子类，其中相应的某些函数以相同的顺序执行类似的操作，但各个操作的细节上有所不同。 解决 将这些操作分别放进独立函数中，并保持它们都有相同的签名，于是原函数也就变得相同了。然后将原函数上移至超类。 注：这里只提到具体做法，建议了解一下模板方法设计模式。 替换算法(Substitute Algorithm) 问题 你想要把某个算法替换为另一个更清晰的算法。 String foundPerson(String[] people)&#123; for (int i = 0; i &lt; people.length; i++) &#123; if (people[i].equals("Don"))&#123; return "Don"; &#125; if (people[i].equals("John"))&#123; return "John"; &#125; if (people[i].equals("Kent"))&#123; return "Kent"; &#125; &#125; return "";&#125; 解决 将函数本体替换为另一个算法。 String foundPerson(String[] people)&#123; List candidates = Arrays.asList(new String[] &#123;"Don", "John", "Kent"&#125;); for (int i=0; i &lt; people.length; i++) &#123; if (candidates.contains(people[i])) &#123; return people[i]; &#125; &#125; return "";&#125; 提炼超类(Extract Superclass) 问题 两个类有相似特性。 解决 为这两个类建立一个超类，将相同特性移至超类。 提炼类(Extract Class) 问题 某个类做了不止一件事。 解决 建立一个新类，将相关的字段和函数从旧类搬移到新类。 合并条件表达式(Consolidate Conditional Expression) 问题 你有一系列条件分支，都得到相同结果。 double disabilityAmount() &#123; if (seniority &lt; 2) &#123; return 0; &#125; if (monthsDisabled &gt; 12) &#123; return 0; &#125; if (isPartTime) &#123; return 0; &#125; // compute the disability amount //...&#125; 解决 将这些条件分支合并为一个条件，并将这个条件提炼为一个独立函数。 double disabilityAmount() &#123; if (isNotEligableForDisability()) &#123; return 0; &#125; // compute the disability amount //...&#125; 合并重复的条件片段(Consolidate Duplicate Conditional Fragments) 问题 在条件表达式的每个分支上有着相同的一段代码。 if (isSpecialDeal()) &#123; total = price * 0.95; send();&#125;else &#123; total = price * 0.98; send();&#125; 解决 将这段重复代码搬移到条件表达式之外。 if (isSpecialDeal()) &#123; total = price * 0.95;&#125;else &#123; total = price * 0.98;&#125;send(); 扩展阅读 代码的坏味道和重构 代码坏味道之代码臃肿 代码坏味道之滥用面向对象 代码坏味道之变革的障碍 代码坏味道之非必要的 代码坏味道之耦合 参考资料 重构——改善既有代码的设计 - by Martin Fowler https://sourcemaking.com/refactoring]]></content>
      <categories>
        <category>design</category>
        <category>refactor</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>refactor</tag>
        <tag>code-smell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码坏味道之代码臃肿]]></title>
    <url>%2Fblog%2F2018%2F10%2F13%2Fdesign%2Frefactor%2F%E4%BB%A3%E7%A0%81%E5%9D%8F%E5%91%B3%E9%81%93%E4%B9%8B%E4%BB%A3%E7%A0%81%E8%87%83%E8%82%BF%2F</url>
    <content type="text"><![CDATA[代码坏味道之代码臃肿 📓 本文已归档到：「blog」 翻译自：https://sourcemaking.com/refactoring/smells/bloaters 代码臃肿(Bloated)这组坏味道意味着：代码中的类、函数、字段没有经过合理的组织，只是简单的堆砌起来。这一类型的问题通常在代码的初期并不明显，但是随着代码规模的增长而逐渐积累（特别是当没有人努力去根除它们时）。 基本类型偏执 数据泥团 过大的类 过长函数 过长参数列 扩展阅读 参考资料 基本类型偏执 基本类型偏执(Primitive Obsession) 使用基本类型而不是小对象来实现简单任务（例如货币、范围、电话号码字符串等）。 使用常量编码信息（例如一个用于引用管理员权限的常量USER_ADMIN_ROLE = 1 ）。 使用字符串常量作为字段名在数组中使用。 问题原因 类似其他大部分坏味道，基本类型偏执诞生于类初建的时候。一开始，可能只是不多的字段，随着表示的特性越来越多，基本数据类型字段也越来越多。 基本类型常常被用于表示模型的类型。你有一组数字或字符串用来表示某个实体。 还有一个场景：在模拟场景，大量的字符串常量被用于数组的索引。 解决方法 大多数编程语言都支持基本数据类型和结构类型（类、结构体等）。结构类型允许程序员将基本数据类型组织起来，以代表某一事物的模型。 基本数据类型可以看成是机构类型的积木块。当基本数据类型数量成规模后，将它们有组织地结合起来，可以更方便的管理这些数据。 如果你有大量的基本数据类型字段，就有可能将其中部分存在逻辑联系的字段组织起来，形成一个类。更进一步的是，将与这些数据有关联的方法也一并移入类中。为了实现这个目标，可以尝试 以类取代类型码(Replace Type Code with Class) 。 如果基本数据类型字段的值是用于方法的参数，可以使用 引入参数对象(Introduce Parameter Object) 或 保持对象完整(Preserve Whole Object) 。 如果想要替换的数据值是类型码，而它并不影响行为，则可以运用 以类取代类型码(Replace Type Code with Class) 将它替换掉。如果你有与类型码相关的条件表达式，可运用 以子类取代类型码(Replace Type Code with Subclass) 或 以状态/策略模式取代类型码(Replace Type Code with State/Strategy) 加以处理。 如果你发现自己正从数组中挑选数据，可运用 以对象取代数组(Replace Array with Object) 。 收益 多亏了使用对象替代基本数据类型，使得代码变得更加灵活。 代码变得更加易读和更加有组织。特殊数据可以集中进行操作，而不像之前那样分散。不用再猜测这些陌生的常量的意义以及它们为什么在数组中。 更容易发现重复代码。 重构方法说明 以类取代类型码(Replace Type Code with Class) 问题 类之中有一个数值类型码，但它并不影响类的行为。 解决 以一个新的类替换该数值类型码。 引入参数对象(Introduce Parameter Object) 问题 某些参数总是很自然地同时出现。 解决 以一个对象来取代这些参数。 保持对象完整(Preserve Whole Object) 问题 你从某个对象中取出若干值，将它们作为某一次函数调用时的参数。 int low = daysTempRange.getLow();int high = daysTempRange.getHigh();boolean withinPlan = plan.withinRange(low, high); 解决 改为传递整个对象。 boolean withinPlan = plan.withinRange(daysTempRange); 以子类取代类型码(Replace Type Code with Subclass) 问题 你有一个不可变的类型码，它会影响类的行为。 解决 以子类取代这个类型码。 以状态/策略模式取代类型码(Replace Type Code with State/Strategy) 问题 你有一个类型码，它会影响类的行为，但你无法通过继承消除它。 解决 以状态对象取代类型码。 以对象取代数组(Replace Array with Object) 问题 你有一个数组，其中的元素各自代表不同的东西。 String[] row = new String[3];row[0] = "Liverpool";row[1] = "15"; 解决 以对象替换数组。对于数组中的每个元素，以一个字段来表示。 Performance row = new Performance();row.setName("Liverpool");row.setWins("15"); 数据泥团 数据泥团(Data Clumps) 有时，代码的不同部分包含相同的变量组（例如用于连接到数据库的参数）。这些绑在一起出现的数据应该拥有自己的对象。 问题原因 通常，数据泥团的出现时因为糟糕的编程结构或“复制-粘贴式编程”。 有一个判断是否是数据泥团的好办法：删掉众多数据中的一项。这么做，其他数据有没有因而失去意义？如果它们不再有意义，这就是个明确的信号：你应该为它们产生一个新的对象。 解决方法 首先找出这些数据以字段形式出现的地方，运用 提炼类(Extract Class) 将它们提炼到一个独立对象中。 如果数据泥团在函数的参数列中出现，运用 引入参数对象(Introduce Parameter Object) 将它们组织成一个类。 如果数据泥团的部分数据出现在其他函数中，考虑运用 保持对象完整(Preserve Whole Object) 将整个数据对象传入到函数中。 检视一下使用这些字段的代码，也许，将它们移入一个数据类是个不错的主意。 收益 提高代码易读性和组织性。对于特殊数据的操作，可以集中进行处理，而不像以前那样分散。 减少代码量。 何时忽略 有时为了对象中的部分数据而将整个对象作为参数传递给函数，可能会产生让两个类之间不收欢迎的依赖关系，这中情况下可以不传递整个对象。 重构方法说明 提炼类(Extract Class) 问题 某个类做了不止一件事。 解决 建立一个新类，将相关的字段和函数从旧类搬移到新类。 引入参数对象(Introduce Parameter Object) 问题 某些参数总是很自然地同时出现。 解决 以一个对象来取代这些参数。 保持对象完整(Preserve Whole Object) 问题 你从某个对象中取出若干值，将它们作为某一次函数调用时的参数。 int low = daysTempRange.getLow();int high = daysTempRange.getHigh();boolean withinPlan = plan.withinRange(low, high); 解决 改为传递整个对象。 boolean withinPlan = plan.withinRange(daysTempRange); 过大的类 过大的类(Large Class) 一个类含有过多字段、函数、代码行。 问题原因 类通常一开始很小，但是随着程序的增长而逐渐膨胀。 类似于过长函数，程序员通常觉得在一个现存类中添加新特性比创建一个新的类要容易。 解决方法 设计模式中有一条重要原则：职责单一原则。一个类应该只赋予它一个职责。如果它所承担的职责太多，就该考虑为它减减负。 如果过大类中的部分行为可以提炼到一个独立的组件中，可以使用 提炼类(Extract Class)。 如果过大类中的部分行为可以用不同方式实现或使用于特殊场景，可以使用 提炼子类(Extract Subclass)。 如果有必要为客户端提供一组操作和行为，可以使用 提炼接口(Extract Interface)。 如果你的过大类是个 GUI 类，可能需要把数据和行为移到一个独立的领域对象去。你可能需要两边各保留一些重复数据，并保持两边同步。 复制被监视数据(Duplicate Observed Data) 可以告诉你怎么做。 收益 重构过大的类可以使程序员不必记住一个类中大量的属性。 在大多数情况下，分割过大的类可以避免代码和功能的重复。 重构方法说明 提炼类(Extract Class) 问题 某个类做了不止一件事。 解决 建立一个新类，将相关的字段和函数从旧类搬移到新类。 提炼子类(Extract Subclass) 问题 一个类中有些特性仅用于特定场景。 解决 创建一个子类，并将用于特殊场景的特性置入其中。 提炼接口(Extract Interface) 问题 多个客户端使用一个类部分相同的函数。另一个场景是两个类中的部分函数相同。 解决 移动相同的部分函数到接口中。 复制被监视数据(Duplicate Observed Data) 问题 如果存储在类中的数据是负责 GUI 的。 解决 一个比较好的方法是将负责 GUI 的数据放入一个独立的类，以确保 GUI 数据与域类之间的连接和同步。 过长函数 过长函数(Long Method) 一个函数含有太多行代码。一般来说，任何函数超过 10 行时，你就可以考虑是不是过长了。 函数中的代码行数原则上不要超过 100 行。 问题的原因 通常情况下，创建一个新函数的难度要大于添加功能到一个已存在的函数。大部分人都觉得：“我就添加这么两行代码，为此新建一个函数实在是小题大做了。”于是，张三加两行，李四加两行，王五加两行。。。函数日益庞大，最终烂的像一锅浆糊，再也没人能完全看懂了。于是大家就更不敢轻易动这个函数了，只能恶性循环的往其中添加代码。所以，如果你看到一个超过 200 行的函数，通常都是多个程序员东拼西凑出来的。 解决函数 一个很好的技巧是：寻找注释。添加注释，一般有这么几个原因：代码逻辑较为晦涩或复杂；这段代码功能相对独立；特殊处理。 如果代码前方有一行注释，就是在提醒你：可以将这段代码替换成一个函数，而且可以在注释的基础上给这个函数命名。如果函数有一个描述恰当的名字，就不需要去看内部代码究竟是如何实现的。就算只有一行代码，如果它需要以注释来说明，那也值得将它提炼到独立函数中。 为了给一个函数瘦身，可以使用 提炼函数(Extract Method)。 如果局部变量和参数干扰提炼函数，可以使用 以查询取代临时变量(Replace Temp with Query)，引入参数对象(Introduce Parameter Object) 或 保持对象完整(Preserve Whole Object) 。 如果前面两条没有帮助，可以通过 以函数对象取代函数(Replace Method with Method Object) 尝试移动整个函数到一个独立的对象中。 条件表达式和循环常常也是提炼的信号。对于条件表达式，可以使用 分解条件表达式(Decompose Conditional) 。至于循环，应该使用 提炼函数(Extract Method) 将循环和其内的代码提炼到独立函数中。 收益 在所有类型的面向对象代码中，函数比较短小精悍的类往往生命周期较长。一个函数越长，就越不容易理解和维护。 此外，过长函数中往往含有难以发现的重复代码。 性能 是否像许多人说的那样，增加函数的数量会影响性能？在几乎绝大多数情况下，这种影响是可以忽略不计，所以不用担心。 此外，现在有了清晰和易读的代码，在需要的时候，你将更容易找到真正有效的函数来重组代码和提高性能。 重构方法说明 提炼函数(Extract Method) 问题 你有一段代码可以组织在一起。 void printOwing() &#123; printBanner(); //print details System.out.println("name: " + name); System.out.println("amount: " + getOutstanding());&#125; 解决 移动这段代码到一个新的函数中，使用函数的调用来替代老代码。 void printOwing() &#123; printBanner(); printDetails(getOutstanding());&#125;void printDetails(double outstanding) &#123; System.out.println("name: " + name); System.out.println("amount: " + outstanding);&#125; 以查询取代临时变量(Replace Temp with Query) 问题 将表达式的结果放在局部变量中，然后在代码中使用。 double calculateTotal() &#123; double basePrice = quantity * itemPrice; if (basePrice &gt; 1000) &#123; return basePrice * 0.95; &#125; else &#123; return basePrice * 0.98; &#125;&#125; 解决 将整个表达式移动到一个独立的函数中并返回结果。使用查询函数来替代使用变量。如果需要，可以在其他函数中合并新函数。 double calculateTotal() &#123; if (basePrice() &gt; 1000) &#123; return basePrice() * 0.95; &#125; else &#123; return basePrice() * 0.98; &#125;&#125;double basePrice() &#123; return quantity * itemPrice;&#125; 引入参数对象(Introduce Parameter Object) 问题 某些参数总是很自然地同时出现。 解决 以一个对象来取代这些参数。 保持对象完整(Preserve Whole Object) 问题 你从某个对象中取出若干值，将它们作为某一次函数调用时的参数。 int low = daysTempRange.getLow();int high = daysTempRange.getHigh();boolean withinPlan = plan.withinRange(low, high); 解决 改为传递整个对象。 boolean withinPlan = plan.withinRange(daysTempRange); 以函数对象取代函数(Replace Method with Method Object) 问题 你有一个过长函数，它的局部变量交织在一起，以致于你无法应用提炼函数(Extract Method) 。 class Order &#123; //... public double price() &#123; double primaryBasePrice; double secondaryBasePrice; double tertiaryBasePrice; // long computation. //... &#125;&#125; 解决 将函数移到一个独立的类中，使得局部变量成了这个类的字段。然后，你可以将函数分割成这个类中的多个函数。 class Order &#123; //... public double price() &#123; return new PriceCalculator(this).compute(); &#125;&#125;class PriceCalculator &#123; private double primaryBasePrice; private double secondaryBasePrice; private double tertiaryBasePrice; public PriceCalculator(Order order) &#123; // copy relevant information from order object. //... &#125; public double compute() &#123; // long computation. //... &#125;&#125; 分解条件表达式(Decompose Conditional) 问题 你有复杂的条件表达式。 if (date.before(SUMMER_START) || date.after(SUMMER_END)) &#123; charge = quantity * winterRate + winterServiceCharge;&#125;else &#123; charge = quantity * summerRate;&#125; 解决 根据条件分支将整个条件表达式分解成几个函数。 if (notSummer(date)) &#123; charge = winterCharge(quantity);&#125;else &#123; charge = summerCharge(quantity);&#125; 过长参数列 过长参数列(Long Parameter List) 一个函数有超过 3、4 个入参。 问题原因 过长参数列可能是将多个算法并到一个函数中时发生的。函数中的入参可以用来控制最终选用哪个算法去执行。 过长参数列也可能是解耦类之间依赖关系时的副产品。例如，用于创建函数中所需的特定对象的代码已从函数移动到调用函数的代码处，但创建的对象是作为参数传递到函数中。因此，原始类不再知道对象之间的关系，并且依赖性也已经减少。但是如果创建的这些对象，每一个都将需要它自己的参数，这意味着过长参数列。 太长的参数列难以理解，太多参数会造成前后不一致、不易使用，而且一旦需要更多数据，就不得不修改它。 解决方案 如果向已有的对象发出一条请求就可以取代一个参数，那么你应该使用 以函数取代参数(Replace Parameter with Methods) 。在这里，，“已有的对象”可能是函数所属类里的一个字段，也可能是另一个参数。 你还可以运用 保持对象完整(Preserve Whole Object) 将来自同一对象的一堆数据收集起来，并以该对象替换它们。 如果某些数据缺乏合理的对象归属，可使用 引入参数对象(Introduce Parameter Object) 为它们制造出一个“参数对象”。 收益 更易读，更简短的代码。 重构可能会暴露出之前未注意到的重复代码。 何时忽略 这里有一个重要的例外：有时候你明显不想造成&quot;被调用对象&quot;与&quot;较大对象&quot;间的某种依赖关系。这时候将数据从对象中拆解出来单独作为参数，也很合情理。但是请注意其所引发的代价。如果参数列太长或变化太频繁，就需要重新考虑自己的依赖结构了。 重构方法说明 以函数取代参数(Replace Parameter with Methods) 问题 对象调用某个函数，并将所得结果作为参数，传递给另一个函数。而接受该参数的函数本身也能够调用前一个函数。 int basePrice = quantity * itemPrice;double seasonDiscount = this.getSeasonalDiscount();double fees = this.getFees();double finalPrice = discountedPrice(basePrice, seasonDiscount, fees); 解决 让参数接受者去除该项参数，并直接调用前一个函数。 int basePrice = quantity * itemPrice;double finalPrice = discountedPrice(basePrice); 保持对象完整(Preserve Whole Object) 问题 你从某个对象中取出若干值，将它们作为某一次函数调用时的参数。 int low = daysTempRange.getLow();int high = daysTempRange.getHigh();boolean withinPlan = plan.withinRange(low, high); 解决 改为传递整个对象。 boolean withinPlan = plan.withinRange(daysTempRange); 引入参数对象(Introduce Parameter Object) 问题 某些参数总是很自然地同时出现。 解决 以一个对象来取代这些参数。 扩展阅读 代码的坏味道和重构 代码坏味道之代码臃肿 代码坏味道之滥用面向对象 代码坏味道之变革的障碍 代码坏味道之非必要的 代码坏味道之耦合 参考资料 重构——改善既有代码的设计 - by Martin Fowler https://sourcemaking.com/refactoring]]></content>
      <categories>
        <category>design</category>
        <category>refactor</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>refactor</tag>
        <tag>code-smell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码坏味道之滥用面向对象]]></title>
    <url>%2Fblog%2F2018%2F10%2F13%2Fdesign%2Frefactor%2F%E4%BB%A3%E7%A0%81%E5%9D%8F%E5%91%B3%E9%81%93%E4%B9%8B%E6%BB%A5%E7%94%A8%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[代码坏味道之滥用面向对象 📓 本文已归档到：「blog」 翻译自：https://sourcemaking.com/refactoring/smells/oo-abusers 滥用面向对象(Object-Orientation Abusers)这组坏味道意味着：代码部分或完全地违背了面向对象编程原则。 Switch 声明 临时字段 异曲同工的类 被拒绝的馈赠 扩展阅读 参考资料 Switch 声明 Switch 声明(Switch Statements) 你有一个复杂的 switch 语句或 if 序列语句。 问题原因 面向对象程序的一个最明显特征就是：少用 switch 和 case 语句。从本质上说，switch 语句的问题在于重复（if 序列也同样如此）。你常会发现 switch 语句散布于不同地点。如果要为它添加一个新的 case 子句，就必须找到所有 switch 语句并修改它们。面向对象中的多态概念可为此带来优雅的解决办法。 大多数时候，一看到 switch 语句，就应该考虑以多态来替换它。 解决方法 问题是多态该出现在哪？switch 语句常常根据类型码进行选择，你要的是“与该类型码相关的函数或类”，所以应该运用 提炼函数(Extract Method) 将 switch 语句提炼到一个独立函数中，再以 搬移函数(Move Method) 将它搬移到需要多态性的那个类里。 如果你的 switch 是基于类型码来识别分支，这时可以运用 以子类取代类型码(Replace Type Code with Subclass) 或 以状态/策略模式取代类型码(Replace Type Code with State/Strategy) 。 一旦完成这样的继承结构后，就可以运用 以多态取代条件表达式(Replace Conditional with Polymorphism) 了。 如果条件分支并不多并且它们使用不同参数调用相同的函数，多态就没必要了。在这种情况下，你可以运用 以明确函数取代参数(Replace Parameter with Explicit Methods) 。 如果你的选择条件之一是 null，可以运用 引入 Null 对象(Introduce Null Object) 。 收益 提升代码组织性。 何时忽略 如果一个 switch 操作只是执行简单的行为，就没有重构的必要了。 switch 常被工厂设计模式族（工厂方法模式(Factory Method)和抽象工厂模式(Abstract Factory)）所使用，这种情况下也没必要重构。 重构方法说明 提炼函数(Extract Method) 问题 你有一段代码可以组织在一起。 void printOwing() &#123; printBanner(); //print details System.out.println("name: " + name); System.out.println("amount: " + getOutstanding());&#125; 解决 移动这段代码到一个新的函数中，使用函数的调用来替代老代码。 void printOwing() &#123; printBanner(); printDetails(getOutstanding());&#125;void printDetails(double outstanding) &#123; System.out.println("name: " + name); System.out.println("amount: " + outstanding);&#125; 搬移函数(Move Method) 问题 你的程序中，有个函数与其所驻类之外的另一个类进行更多交流：调用后者，或被后者调用。 解决 在该函数最常引用的类中建立一个有着类似行为的新函数。将旧函数变成一个单纯的委托函数，或是旧函数完全移除。 以子类取代类型码(Replace Type Code with Subclass) 问题 你有一个不可变的类型码，它会影响类的行为。 解决 以子类取代这个类型码。 以状态/策略模式取代类型码(Replace Type Code with State/Strategy) 问题 你有一个类型码，它会影响类的行为，但你无法通过继承消除它。 解决 以状态对象取代类型码。 以多态取代条件表达式(Replace Conditional with Polymorphism) 问题 你手上有个条件表达式，它根据对象类型的不同而选择不同的行为。 class Bird &#123; //... double getSpeed() &#123; switch (type) &#123; case EUROPEAN: return getBaseSpeed(); case AFRICAN: return getBaseSpeed() - getLoadFactor() * numberOfCoconuts; case NORWEGIAN_BLUE: return (isNailed) ? 0 : getBaseSpeed(voltage); &#125; throw new RuntimeException("Should be unreachable"); &#125;&#125; 解决 将这个条件表达式的每个分支放进一个子类内的覆写函数中，然后将原始函数声明为抽象函数。 abstract class Bird &#123; //... abstract double getSpeed();&#125;class European extends Bird &#123; double getSpeed() &#123; return getBaseSpeed(); &#125;&#125;class African extends Bird &#123; double getSpeed() &#123; return getBaseSpeed() - getLoadFactor() * numberOfCoconuts; &#125;&#125;class NorwegianBlue extends Bird &#123; double getSpeed() &#123; return (isNailed) ? 0 : getBaseSpeed(voltage); &#125;&#125;// Somewhere in client codespeed = bird.getSpeed(); 以明确函数取代参数(Replace Parameter with Explicit Methods) 问题 你有一个函数，其中完全取决于参数值而采取不同的行为。 void setValue(String name, int value) &#123; if (name.equals("height")) &#123; height = value; return; &#125; if (name.equals("width")) &#123; width = value; return; &#125; Assert.shouldNeverReachHere();&#125; 解决 针对该参数的每一个可能值，建立一个独立函数。 void setHeight(int arg) &#123; height = arg;&#125;void setWidth(int arg) &#123; width = arg;&#125; 引入 Null 对象(Introduce Null Object) 问题 你需要再三检查某对象是否为 null。 if (customer == null) &#123; plan = BillingPlan.basic();&#125;else &#123; plan = customer.getPlan();&#125; 解决 将 null 值替换为 null 对象。 class NullCustomer extends Customer &#123; Plan getPlan() &#123; return new NullPlan(); &#125; // Some other NULL functionality.&#125;// Replace null values with Null-object.customer = (order.customer != null) ? order.customer : new NullCustomer();// Use Null-object as if it's normal subclass.plan = customer.getPlan(); 临时字段 临时字段(Temporary Field)的值只在特定环境下有意义，离开这个环境，它们就什么也不是了。 问题原因 有时你会看到这样的对象：其内某个实例变量仅为某种特定情况而设。这样的代码让人不易理解，因为你通常认为对象在所有时候都需要它的所有变量。在变量未被使用的情况下猜测当初设置目的，会让你发疯。 通常，临时字段是在某一算法需要大量输入时而创建。因此，为了避免函数有过多参数，程序员决定在类中创建这些数据的临时字段。这些临时字段仅仅在算法中使用，其他时候却毫无用处。 这种代码不好理解。你期望查看对象字段的数据，但是出于某种原因，它们总是为空。 解决方法 可以通过 提炼类(Extract Class) 将临时字段和操作它们的所有代码提炼到一个单独的类中。此外，你可以运用 以函数对象取代函数(Replace Method with Method Object) 来实现同样的目的。 引入 Null 对象(Introduce Null Object) 在“变量不合法”的情况下创建一个 null 对象，从而避免写出条件表达式。 收益 更好的代码清晰度和组织性。 重构方法说明 提炼类(Extract Class) 问题 某个类做了不止一件事。 解决 建立一个新类，将相关的字段和函数从旧类搬移到新类。 以函数对象取代函数(Replace Method with Method Object) 问题 你有一个过长函数，它的局部变量交织在一起，以致于你无法应用提炼函数(Extract Method) 。 class Order &#123; //... public double price() &#123; double primaryBasePrice; double secondaryBasePrice; double tertiaryBasePrice; // long computation. //... &#125;&#125; 解决 将函数移到一个独立的类中，使得局部变量成了这个类的字段。然后，你可以将函数分割成这个类中的多个函数。 class Order &#123; //... public double price() &#123; return new PriceCalculator(this).compute(); &#125;&#125;class PriceCalculator &#123; private double primaryBasePrice; private double secondaryBasePrice; private double tertiaryBasePrice; public PriceCalculator(Order order) &#123; // copy relevant information from order object. //... &#125; public double compute() &#123; // long computation. //... &#125;&#125; 引入 Null 对象(Introduce Null Object) 问题 你需要再三检查某对象是否为 null。 if (customer == null) &#123; plan = BillingPlan.basic();&#125;else &#123; plan = customer.getPlan();&#125; 解决 将 null 值替换为 null 对象。 class NullCustomer extends Customer &#123; Plan getPlan() &#123; return new NullPlan(); &#125; // Some other NULL functionality.&#125;// Replace null values with Null-object.customer = (order.customer != null) ? order.customer : new NullCustomer();// Use Null-object as if it's normal subclass.plan = customer.getPlan(); 异曲同工的类 异曲同工的类(Alternative Classes with Different Interfaces) 两个类中有着不同的函数，却在做着同一件事。 问题原因 这种情况往往是因为：创建这个类的程序员并不知道已经有实现这个功能的类存在了。 解决方法 如果两个函数做同一件事，却有着不同的签名，请运用 函数改名(Rename Method) 根据它们的用途重新命名。 运用 搬移函数(Move Method) 、 添加参数(Add Parameter) 和 令函数携带参数(Parameterize Method) 来使得方法的名称和实现一致。 如果两个类仅有部分功能是重复的，尝试运用 提炼超类(Extract Superclass) 。这种情况下，已存在的类就成了超类。 当最终选择并运用某种方法来重构后，也许你就能删除其中一个类了。 收益 消除了不必要的重复代码，为代码瘦身了。 代码更易读（不再需要猜测为什么要有两个功能相同的类）。 何时忽略 有时合并类是不可能的，或者是如此困难以至于没有意义。例如：两个功能相似的类存在于不同的 lib 库中。 重构方法说明 函数改名(Rename Method) 问题 函数的名称未能恰当的揭示函数的用途。 class Person &#123; public String getsnm();&#125; 解决 修改函数名。 class Person &#123; public String getSecondName();&#125; 搬移函数(Move Method) 问题 你的程序中，有个函数与其所驻类之外的另一个类进行更多交流：调用后者，或被后者调用。 解决 在该函数最常引用的类中建立一个有着类似行为的新函数。将旧函数变成一个单纯的委托函数，或是旧函数完全移除。 添加参数(Add Parameter) 问题 某个函数需要从调用端得到更多信息。 class Customer &#123; public Contact getContact();&#125; 解决 为此函数添加一个对象函数，让改对象带进函数所需信息。 class Customer &#123; public Contact getContact(Date date);&#125; 令函数携带参数(Parameterize Method) 问题 若干函数做了类似的工作，但在函数本体中却包含了不同的值。 **解决** 建立单一函数，以参数表达哪些不同的值。 提炼超类(Extract Superclass) 问题 两个类有相似特性。 解决 为这两个类建立一个超类，将相同特性移至超类。 被拒绝的馈赠 被拒绝的馈赠(Refused Bequest) 子类仅仅使用父类中的部分方法和属性。其他来自父类的馈赠成为了累赘。 问题原因 有些人仅仅是想重用超类中的部分代码而创建了子类。但实际上超类和子类完全不同。 解决方法 如果继承没有意义并且子类和父类之间确实没有共同点，可以运用 以委托取代继承(Replace Inheritance with Delegation) 消除继承。 如果继承是适当的，则去除子类中不需要的字段和方法。运用 提炼超类(Extract Superclass) 将所有超类中对于子类有用的字段和函数提取出来，置入一个新的超类中，然后让两个类都继承自它。 收益 提高代码的清晰度和组织性。 重构方法说明 以委托取代继承(Replace Inheritance with Delegation) 问题 某个子类只使用超类接口中的一部分，或是根本不需要继承而来的数据。 解决 在子类中新建一个字段用以保存超类； 调整子类函数，令它改而委托超类； 然后去掉两者之间的继承关系。 提炼超类(Extract Superclass) 问题 两个类有相似特性。 解决 为这两个类建立一个超类，将相同特性移至超类。 扩展阅读 代码的坏味道和重构 代码坏味道之代码臃肿 代码坏味道之滥用面向对象 代码坏味道之变革的障碍 代码坏味道之非必要的 代码坏味道之耦合 参考资料 重构——改善既有代码的设计 - by Martin Fowler https://sourcemaking.com/refactoring]]></content>
      <categories>
        <category>design</category>
        <category>refactor</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>refactor</tag>
        <tag>code-smell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负载均衡]]></title>
    <url>%2Fblog%2F2018%2F10%2F13%2Fdesign%2Farchitecture%2F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[负载均衡 1. 负载均衡原理 2. 负载均衡分类 2.1. DNS 负载均衡 2.2. IP 负载均衡 2.3. 链路层负载均衡 2.4. 混合型负载均衡 3. 负载均衡算法 3.1. 轮询 3.2. 随机 3.3. 最少连接 3.4. Hash（源地址散列） 3.5. 加权 4. 硬件负载均衡 5. Ngnix 负载均衡 5.1. Ngnix 特点 5.2. Ngnix 功能 5.3. Ngnix 架构 5.4. Ngnix 均衡策略 5.5. Ngnix 场景 6. LVS 负载均衡 6.1. LVS 功能 6.2. LVS 架构 6.3. LVS 均衡策略 6.4. LVS 场景 7. HaProxy 负载均衡 7.1. HaProxy 特点 7.2. HaProxy 均衡策略 8. 资料 1. 负载均衡原理 系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。纵向扩展，是从单机的角度通过增加硬件处理能力，比如 CPU 处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。这就是典型的集群和负载均衡架构：如下图： 应用集群：将同一应用部署到多台机器上，组成处理集群，接收负载均衡设备分发的请求，进行处理，并返回相应数据。 负载均衡设备：将用户访问的请求，根据负载均衡算法，分发到集群中的一台处理服务器。（一种把网络请求分散到一个服务器集群中的可用服务器上去的设备） 负载均衡的作用（解决的问题）： 解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）； 提供故障转移，实现高可用； 通过添加或减少服务器数量，提供网站伸缩性（扩展性）； 安全防护；（负载均衡设备上做一些过滤，黑白名单等处理） 2. 负载均衡分类 根据实现技术不同，可分为 DNS 负载均衡，HTTP 负载均衡，IP 负载均衡，链路层负载均衡等。 2.1. DNS 负载均衡 最早的负载均衡技术，利用域名解析实现负载均衡，在 DNS 服务器，配置多个 A 记录，这些 A 记录对应的服务器构成集群。大型网站总是部分使用 DNS 解析，作为第一级负载均衡。如下图： 优点 使用简单：负载均衡工作，交给 DNS 服务器处理，省掉了负载均衡服务器维护的麻烦 提高性能：可以支持基于地址的域名解析，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能； 缺点 可用性差：DNS 解析是多级解析，新增/修改 DNS 后，解析时间较长；解析过程中，用户访问网站将失败； 扩展性低：DNS 负载均衡的控制权在域名商那里，无法对其做更多的改善和扩展； 维护性差：也不能反映服务器的当前运行状态；支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载） 实践建议 将 DNS 作为第一级负载均衡，A 记录对应着内部负载均衡的 IP 地址，通过内部负载均衡将请求分发到真实的 Web 服务器上。一般用于互联网公司，复杂的业务系统不合适使用。如下图： 2.2. IP 负载均衡 在网络层通过修改请求目标地址进行负载均衡。 用户请求数据包，到达负载均衡服务器后，负载均衡服务器在操作系统内核进程获取网络数据包，根据负载均衡算法得到一台真实服务器地址，然后将请求目的地址修改为，获得的真实 ip 地址，不需要经过用户进程处理。 真实服务器处理完成后，响应数据包回到负载均衡服务器，负载均衡服务器，再将数据包源地址修改为自身的 ip 地址，发送给用户浏览器。如下图： IP 负载均衡，真实物理服务器返回给负载均衡服务器，存在两种方式： 负载均衡服务器在修改目的 ip 地址的同时修改源地址。将数据包源地址设为自身盘，即源地址转换（snat）。 将负载均衡服务器同时作为真实物理服务器集群的网关服务器。 优点：在内核进程完成数据分发，比在应用层分发性能更好； 缺点：所有请求响应都需要经过负载均衡服务器，集群最大吞吐量受限于负载均衡服务器网卡带宽； 2.3. 链路层负载均衡 在通信协议的数据链路层修改 mac 地址，进行负载均衡。 数据分发时，不修改 ip 地址，指修改目标 mac 地址，配置真实物理服务器集群所有机器虚拟 ip 和负载均衡服务器 ip 地址一致，达到不修改数据包的源地址和目标地址，进行数据分发的目的。 实际处理服务器 ip 和数据请求目的 ip 一致，不需要经过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。也称为直接路由模式（DR 模式）。如下图： 优点：性能好； 缺点：配置复杂； 实践建议：DR 模式是目前使用最广泛的一种负载均衡方式。 2.4. 混合型负载均衡 由于多个服务器群内硬件设备、各自的规模、提供的服务等的差异，可以考虑给每个服务器群采用最合适的负载均衡方式，然后又在这多个服务器群间再一次负载均衡或群集起来以一个整体向外界提供服务（即把这多个服务器群当做一个新的服务器群），从而达到最佳的性能。将这种方式称之为混合型负载均衡。 此种方式有时也用于单台均衡设备的性能不能满足大量连接请求的情况下。是目前大型互联网公司，普遍使用的方式。 方式一，如下图： 以上模式适合有动静分离的场景，反向代理服务器（集群）可以起到缓存和动态请求分发的作用，当时静态资源缓存在代理服务器时，则直接返回到浏览器。如果动态页面则请求后面的应用负载均衡（应用集群）。 方式二，如下图： 以上模式，适合动态请求场景。 因混合模式，可以根据具体场景，灵活搭配各种方式，以上两种方式仅供参考。 3. 负载均衡算法 常用的负载均衡算法有：轮询、随机、最少连接、源地址散列、加权等方式。 3.1. 轮询 将所有请求，依次分发到每台服务器上，适合服务器硬件同相同的场景。 优点：服务器请求数目相同； 缺点：服务器压力不一样，不适合服务器配置不同的情况； 3.2. 随机 请求随机分配到各个服务器。 优点：使用简单； 缺点：不适合机器配置不同的场景； 3.3. 最少连接 将请求分配到连接数最少的服务器（目前处理请求最少的服务器）。 优点：根据服务器当前的请求处理情况，动态分配； 缺点：算法实现相对复杂，需要监控服务器请求连接数； 3.4. Hash（源地址散列） 根据 IP 地址进行 Hash 计算，得到 IP 地址。 优点：将来自同一 IP 地址的请求，同一会话期内，转发到相同的服务器；实现会话粘滞。 缺点：目标服务器宕机后，会话会丢失； 3.5. 加权 在轮询，随机，最少链接，Hash’等算法的基础上，通过加权的方式，进行负载服务器分配。 优点：根据权重，调节转发服务器的请求数目； 缺点：使用相对复杂； 4. 硬件负载均衡 采用硬件的方式实现负载均衡，一般是单独的负载均衡服务器，价格昂贵，一般土豪级公司可以考虑，业界领先的有两款，F5 和 A10。 使用硬件负载均衡，主要考虑一下几个方面： （1）功能考虑：功能全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡； （2）性能考虑：一般软件负载均衡支持到 5 万级并发已经很困难了，硬件负载均衡可以支持 （3）稳定性：商用硬件负载均衡，经过了良好的严格的测试，从经过大规模使用，在稳定性方面高； （4）安全防护：硬件均衡设备除具备负载均衡功能外，还具备防火墙，防 DDOS 攻击等安全功能； （5）维护角度：提供良好的维护管理界面，售后服务和技术支持； （6）土豪公司：F5 Big Ip 价格：15w~55w 不等；A10 价格：55w-100w 不等； 缺点 （1）价格昂贵； （2）扩展能力差； 小结 （1）一般硬件的负载均衡也要做双机高可用，因此成本会比较高。 （2）互联网公司一般使用开源软件，因此大部分应用采用软件负载均衡；部分采用硬件负载均衡。 比如某互联网公司，目前是使用几台 F5 做全局负载均衡，内部使用 Nginx 等软件负载均衡。 5. Ngnix 负载均衡 Ngnix 是一款轻量级的 Web 服务器/反向代理服务器，工作在七层 Http 协议的负载均衡系统。具有高性能、高并发、低内存使用等特点。是一个轻量级的 Http 和反向代理服务器。Nginx 使用 epoll and kqueue 作为开发模型。能够支持高达 50,000 个并发连接数的响应。 操作系统：Liunx，Windows（Linux、FreeBSD、Solaris、Mac OS X、AIX 以及 Microsoft Windows） 开发语言：C 并发性能：官方支持每秒 5 万并发，实际国内一般到每秒 2 万并发，有优化到每秒 10 万并发的。具体性能看应用场景。 5.1. Ngnix 特点 1.模块化设计：良好的扩展性，可以通过模块方式进行功能扩展。 2.高可靠性：主控进程和 worker 是同步实现的，一个 worker 出现问题，会立刻启动另一个 worker。 3.内存消耗低：一万个长连接（keep-alive）,仅消耗 2.5MB 内存。 4.支持热部署：不用停止服务器，实现更新配置文件，更换日志文件、更新服务器程序版本。 5.并发能力强：官方数据每秒支持 5 万并发； 6.功能丰富：优秀的反向代理功能和灵活的负载均衡策略 5.2. Ngnix 功能 基本功能 支持静态资源的 web 服务器。 http,smtp,pop3 协议的反向代理服务器、缓存、负载均衡； 支持 FASTCGI（fpm） 支持模块化，过滤器（让文本可以实现压缩，节约带宽）,ssl 及图像大小调整。 内置的健康检查功能 基于名称和 ip 的虚拟主机 定制访问日志 支持平滑升级 支持 KEEPALIVE 支持 url rewrite 支持路径别名 支持基于 IP 和用户名的访问控制。 支持传输速率限制，支持并发数限制。 扩展功能 性能 Nginx 的高并发，官方测试支持 5 万并发连接。实际生产环境能到 2-3 万并发连接数。10000 个非活跃的 HTTP keep-alive 连接仅占用约 2.5MB 内存。三万并发连接下，10 个 Nginx 进程，消耗内存 150M。淘宝 tengine 团队测试结果是“24G 内存机器上，处理并发请求可达 200 万”。 5.3. Ngnix 架构 Nginx 的基本工作模式 一个 master 进程，生成一个或者多个 worker 进程。但是这里 master 是使用 root 身份启动的，因为 nginx 要工作在 80 端口。而只有管理员才有权限启动小于低于 1023 的端口。master 主要是负责的作用只是启动 worker，加载配置文件，负责系统的平滑升级。其它的工作是交给 worker。那么当 worker 被启动之后，也只是负责一些 web 最简单的工作，而其他的工作都是有 worker 中调用的模块来实现的。 模块之间是以流水线的方式实现功能的。流水线，指的是一个用户请求，由多个模块组合各自的功能依次实现完成的。比如：第一个模块只负责分析请求首部，第二个模块只负责查找数据，第三个模块只负责压缩数据，依次完成各自工作。来实现整个工作的完成。 他们是如何实现热部署的呢？其实是这样的，我们前面说 master 不负责具体的工作，而是调用 worker 工作，他只是负责读取配置文件，因此当一个模块修改或者配置文件发生变化，是由 master 进行读取，因此此时不会影响到 worker 工作。在 master 进行读取配置文件之后，不会立即的把修改的配置文件告知 worker。而是让被修改的 worker 继续使用老的配置文件工作，当 worker 工作完毕之后，直接当掉这个子进程，更换新的子进程，使用新的规则。 Nginx 支持的 sendfile 机制 Sendfile 机制，用户将请求发给内核，内核根据用户的请求调用相应用户进程，进程在处理时需要资源。此时再把请求发给内核（进程没有直接 IO 的能力），由内核加载数据。内核查找到数据之后，会把数据复制给用户进程，由用户进程对数据进行封装，之后交给内核，内核在进行 tcp/ip 首部的封装，最后再发给客户端。这个功能用户进程只是发生了一个封装报文的过程，却要绕一大圈。因此 nginx 引入了 sendfile 机制，使得内核在接受到数据之后，不再依靠用户进程给予封装，而是自己查找自己封装，减少了一个很长一段时间的浪费，这是一个提升性能的核心点。 以上内容摘自网友发布的文章，简单一句话是资源的处理，直接通过内核层进行数据传递，避免了数据传递到应用层，应用层再传递到内核层的开销。 目前高并发的处理，一般都采用 sendfile 模式。通过直接操作内核层数据，减少应用与内核层数据传递。 Nginx 通信模型（I/O 复用机制） 开发模型：epoll 和 kqueue。 支持的事件机制：kqueue、epoll、rt signals、/dev/poll 、event ports、select 以及 poll。 支持的 kqueue 特性包括 EV_CLEAR、EV_DISABLE、NOTE_LOWAT、EV_EOF，可用数据的数量，错误代码. 支持 sendfile、sendfile64 和 sendfilev;文件 AIO；DIRECTIO;支持 Accept-filters 和 TCP_DEFER_ACCEP. 以上概念较多，大家自行百度或谷歌，知识领域是网络通信（BIO,NIO,AIO）和多线程方面的知识。 5.4. Ngnix 均衡策略 nginx 的负载均衡策略可以划分为两大类：内置策略和扩展策略。内置策略包含加权轮询和 ip hash，在默认情况下这两种策略会编译进 nginx 内核，只需在 nginx 配置中指明参数即可。扩展策略有很多，如 fair、通用 hash、consistent hash 等，默认不编译进 nginx 内核。由于在 nginx 版本升级中负载均衡的代码没有本质性的变化，因此下面将以 nginx1.0.15 稳定版为例，从源码角度分析各个策略。 加权轮询（weighted round robin） 轮询的原理很简单，首先我们介绍一下轮询的基本流程。如下是处理一次请求的流程图： 图中有两点需要注意，第一，如果可以把加权轮询算法分为先深搜索和先广搜索，那么 nginx 采用的是先深搜索算法，即将首先将请求都分给高权重的机器，直到该机器的权值降到了比其他机器低，才开始将请求分给下一个高权重的机器；第二，当所有后端机器都 down 掉时，nginx 会立即将所有机器的标志位清成初始状态，以避免造成所有的机器都处在 timeout 的状态，从而导致整个前端被夯住。 ip hash ip hash 是 nginx 内置的另一个负载均衡的策略，流程和轮询很类似，只是其中的算法和具体的策略有些变化，如下图所示： fair fair 策略是扩展策略，默认不被编译进 nginx 内核。其原理是根据后端服务器的响应时间判断负载情况，从中选出负载最轻的机器进行分流。这种策略具有很强的自适应性，但是实际的网络环境往往不是那么简单，因此要慎用。 通用 hash、一致性 hash 这两种也是扩展策略，在具体的实现上有些差别，通用 hash 比较简单，可以以 nginx 内置的变量为 key 进行 hash，一致性 hash 采用了 nginx 内置的一致性 hash 环，可以支持 memcache。 5.5. Ngnix 场景 Ngnix 一般作为入口负载均衡或内部负载均衡，结合反向代理服务器使用。以下架构示例，仅供参考，具体使用根据场景而定。 入口负载均衡架构 Ngnix 服务器在用户访问的最前端。根据用户请求再转发到具体的应用服务器或二级负载均衡服务器（LVS） 内部负载均衡架构 LVS 作为入口负载均衡，将请求转发到二级 Ngnix 服务器，Ngnix 再根据请求转发到具体的应用服务器。 Ngnix 高可用 分布式系统中，应用只部署一台服务器会存在单点故障，负载均衡同样有类似的问题。一般可采用主备或负载均衡设备集群的方式节约单点故障或高并发请求分流。 Ngnix 高可用，至少包含两个 Ngnix 服务器，一台主服务器，一台备服务器，之间使用 Keepalived 做健康监控和故障检测。开放 VIP 端口，通过防火墙进行外部映射。 DNS 解析公网的 IP 实际为 VIP。 6. LVS 负载均衡 LVS 是一个开源的软件，由毕业于国防科技大学的章文嵩博士于 1998 年 5 月创立，用来实现 Linux 平台下的简单负载均衡。LVS 是 Linux Virtual Server 的缩写，意思是 Linux 虚拟服务器。 基于 IP 层的负载均衡调度技术，它在操作系统核心层上，将来自 IP 层的 TCP/UDP 请求均衡地转移到不同的 服务器，从而将一组服务器构成一个高性能、高可用的虚拟服务器。 操作系统：Liunx 开发语言：C 并发性能：默认 4096，可以修改但需要重新编译。 6.1. LVS 功能 LVS 的主要功能是实现 IP 层（网络层）负载均衡，有 NAT,TUN,DR 三种请求转发模式。 LVS/NAT 方式的负载均衡集群 NAT 是指 Network Address Translation，它的转发流程是：Director 机器收到外界请求，改写数据包的目标地址，按相应的调度算法将其发送到相应 Real Server 上，Real Server 处理完该请求后，将结果数据包返回到其默认网关，即 Director 机器上，Director 机器再改写数据包的源地址，最后将其返回给外界。这样就完成一次负载调度。 构架一个最简单的 LVS/NAT 方式的负载均衡集群 Real Server 可以是任何的操作系统，而且无需做任何特殊的设定，惟一要做的就是将其默认网关指向 Director 机器。Real Server 可以使用局域网的内部 IP(192.168.0.0/24)。Director 要有两块网卡，一块网卡绑定一个外部 IP 地址 (10.0.0.1)，另一块网卡绑定局域网的内部 IP(192.168.0.254)，作为 Real Server 的默认网关。 LVS/NAT 方式实现起来最为简单，而且 Real Server 使用的是内部 IP，可以节省 Real IP 的开销。但因为执行 NAT 需要重写流经 Director 的数据包，在速度上有一定延迟； 当用户的请求非常短，而服务器的回应非常大的情况下，会对 Director 形成很大压力，成为新的瓶颈，从而使整个系统的性能受到限制。 LVS/TUN 方式的负载均衡集群 TUN 是指 IP Tunneling，它的转发流程是：Director 机器收到外界请求，按相应的调度算法,通过 IP 隧道发送到相应 Real Server，Real Server 处理完该请求后，将结果数据包直接返回给客户。至此完成一次负载调度。 最简单的 LVS/TUN 方式的负载均衡集群架构使用 IP Tunneling 技术，在 Director 机器和 Real Server 机器之间架设一个 IP Tunnel，通过 IP Tunnel 将负载分配到 Real Server 机器上。Director 和 Real Server 之间的关系比较松散，可以是在同一个网络中，也可以是在不同的网络中，只要两者能够通过 IP Tunnel 相连就行。收到负载分配的 Real Server 机器处理完后会直接将反馈数据送回给客户，而不必通过 Director 机器。实际应用中，服务器必须拥有正式的 IP 地址用于与客户机直接通信，并且所有服务器必须支持 IP 隧道协议。 该方式中 Director 将客户请求分配到不同的 Real Server，Real Server 处理请求后直接回应给用户，这样 Director 就只处理客户机与服务器的一半连接，极大地提高了 Director 的调度处理能力，使集群系统能容纳更多的节点数。另外 TUN 方式中的 Real Server 可以在任何 LAN 或 WAN 上运行，这样可以构筑跨地域的集群，其应对灾难的能力也更强，但是服务器需要为 IP 封装付出一定的资源开销，而且后端的 Real Server 必须是支持 IP Tunneling 的操作系统。 LVS/TUN 方式的负载均衡集群 DR 是指 Direct Routing，它的转发流程是：Director 机器收到外界请求，按相应的调度算法将其直接发送到相应 Real Server，Real Server 处理完该请求后，将结果数据包直接返回给客户，完成一次负载调度。 构架一个最简单的 LVS/DR 方式的负载均衡集群 Real Server 和 Director 都在同一个物理网段中，Director 的网卡 IP 是 192.168.0.253，再绑定另一个 IP： 192.168.0.254 作为对外界的 virtual IP，外界客户通过该 IP 来访问整个集群系统。Real Server 在 lo 上绑定 IP：192.168.0.254，同时加入相应的路由。 LVS/DR 方式与前面的 LVS/TUN 方式有些类似，前台的 Director 机器也是只需要接收和调度外界的请求，而不需要负责返回这些请求的反馈结果，所以能够负载更多的 Real Server，提高 Director 的调度处理能力，使集群系统容纳更多的 Real Server。但 LVS/DR 需要改写请求报文的 MAC 地址，所以所有服务器必须在同一物理网段内。 6.2. LVS 架构 LVS 架设的服务器集群系统有三个部分组成：最前端的负载均衡层（Loader Balancer），中间的服务器群组层，用 Server Array 表示，最底层的数据共享存储层，用 Shared Storage 表示。在用户看来所有的应用都是透明的，用户只是在使用一个虚拟服务器提供的高性能服务。 LVS 的体系架构如图： LVS 的各个层次的详细介绍： Load Balancer 层：位于整个集群系统的最前端，有一台或者多台负载调度器（Director Server）组成，LVS 模块就安装在 Director Server 上，而 Director 的主要作用类似于一个路由器，它含有完成 LVS 功能所设定的路由表，通过这些路由表把用户的请求分发给 Server Array 层的应用服务器（Real Server）上。同时，在 Director Server 上还要安装对 Real Server 服务的监控模块 Ldirectord，此模块用于监测各个 Real Server 服务的健康状况。在 Real Server 不可用时把它从 LVS 路由表中剔除，恢复时重新加入。 Server Array 层：由一组实际运行应用服务的机器组成，Real Server 可以是 WEB 服务器、MAIL 服务器、FTP 服务器、DNS 服务器、视频服务器中的一个或者多个，每个 Real Server 之间通过高速的 LAN 或分布在各地的 WAN 相连接。在实际的应用中，Director Server 也可以同时兼任 Real Server 的角色。 Shared Storage 层：是为所有 Real Server 提供共享存储空间和内容一致性的存储区域，在物理上，一般有磁盘阵列设备组成，为了提供内容的一致性，一般可以通过 NFS 网络文件系统共享数 据，但是 NFS 在繁忙的业务系统中，性能并不是很好，此时可以采用集群文件系统，例如 Red hat 的 GFS 文件系统，oracle 提供的 OCFS2 文件系统等。 从整个 LVS 结构可以看出，Director Server 是整个 LVS 的核心，目前，用于 Director Server 的操作系统只能是 Linux 和 FreeBSD，linux2.6 内核不用任何设置就可以支持 LVS 功能，而 FreeBSD 作为 Director Server 的应用还不是很多，性能也不是很好。对于 Real Server，几乎可以是所有的系统平台，Linux、windows、Solaris、AIX、BSD 系列都能很好的支持。 6.3. LVS 均衡策略 LVS 默认支持八种负载均衡策略，简述如下： 轮询调度（Round Robin） 调度器通过“轮询”调度算法将外部请求按顺序轮流分配到集群中的真实服务器上，它均等地对待每一台服务器，而不管服务器上实际的连接数和系统负载。 加权轮询（Weighted Round Robin） 调度器通过“加权轮询”调度算法根据真实服务器的不同处理能力来调度访问请求。这样可以保证处理能力强的服务器能处理更多的访问流量。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 最少链接（Least Connections） 调度器通过“最少连接”调度算法动态地将网络请求调度到已建立的链接数最少的服务器上。如果集群系统的真实服务器具有相近的系统性能，采用“最小连接”调度算法可以较好地均衡负载。 加权最少链接（Weighted Least Connections） 在集群系统中的服务器性能差异较大的情况下，调度器采用“加权最少链接”调度算法优化负载均衡性能，具有较高权值的服务器将承受较大比例的活动连接负载。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 基于局部性的最少链接（Locality-Based Least Connections） “基于局部性的最少链接”调度算法是针对目标 IP 地址的负载均衡，目前主要用于 Cache 集群系统。该算法根据请求的目标 IP 地址找出该目标 IP 地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则用“最少链接” 的原则选出一个可用的服务器，将请求发送到该服务器。 带复制的基于局部性最少链接（Locality-Based Least Connections with Replication） “带复制的基于局部性最少链接”调度算法也是针对目标 IP 地址的负载均衡，目前主要用于 Cache 集群系统。它与 LBLC 算法的不同之处是它要维护从一个目标 IP 地址到一组服务器的映射，而 LBLC 算法维护从一个目标 IP 地址到一台服务器的映射。该算法根据请求的目标 IP 地址找出该目标 IP 地址对应的服务器组，按“最小连接”原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接”原则从这个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。 目标地址散列（Destination Hashing） “目标地址散列”调度算法根据请求的目标 IP 地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。 源地址散列（Source Hashing） “源地址散列”调度算法根据请求的源 IP 地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。 除具备以上负载均衡算法外，还可以自定义均衡策略。 6.4. LVS 场景 一般作为入口负载均衡或内部负载均衡，结合反向代理服务器使用。相关架构可参考 Ngnix 场景架构。 7. HaProxy 负载均衡 HAProxy 也是使用较多的一款负载均衡软件。HAProxy 提供高可用性、负载均衡以及基于 TCP 和 HTTP 应用的代理，支持虚拟主机，是免费、快速并且可靠的一种解决方案。特别适用于那些负载特大的 web 站点。运行模式使得它可以很简单安全的整合到当前的架构中，同时可以保护你的 web 服务器不被暴露到网络上。 7.1. HaProxy 特点 支持两种代理模式：TCP（四层）和 HTTP（七层），支持虚拟主机； 配置简单，支持 url 检测后端服务器状态； 做负载均衡软件使用，在高并发情况下，处理速度高于 nginx； TCP 层多用于 Mysql 从（读）服务器负载均衡。 （对 Mysql 进行负载均衡，对后端的 DB 节点进行检测和负载均衡） 能够补充 Nginx 的一些缺点比如 Session 的保持，Cookie 引导等工作 7.2. HaProxy 均衡策略 支持四种常用算法： 1.roundrobin：轮询，轮流分配到后端服务器； 2.static-rr：根据后端服务器性能分配； 3.leastconn：最小连接者优先处理； 4.source：根据请求源 IP，与 Nginx 的 IP_Hash 类似。 8. 资料 大型网站架构系列：负载均衡详解（1） 大型网站架构系列：负载均衡详解（2） 大型网站架构系列：负载均衡详解（3） 大型网站架构系列：负载均衡详解（4）]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>load balance</tag>
        <tag>design</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式原理]]></title>
    <url>%2Fblog%2F2018%2F10%2F13%2Fdesign%2Farchitecture%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[分布式原理 1. 分布式术语 1.1. 异常 1.2. 超时 1.3. 衡量指标 2. 数据分布 2.1. 哈希分布 2.2. 顺序分布 2.3. 负载均衡 3. 分布式理论 3.1. CAP 3.2. BASE 4. 分布式事务问题 4.1. 两阶段提交（2PC） 4.2. 补偿事务（TCC） 4.3. 本地消息表（异步确保） 4.4. MQ 事务消息 5. 共识性问题 5.1. Paxos 5.2. Raft 6. 分布式缓存问题z 6.1. 缓存雪崩 6.2. 缓存穿透z 6.3. 缓存预热 6.4. 缓存更新 6.5. 缓存降级 7. 参考资料 1. 分布式术语 1.1. 异常 服务器宕机 内存错误、服务器停电等都会导致服务器宕机，此时节点无法正常工作，称为不可用。 服务器宕机会导致节点失去所有内存信息，因此需要将内存信息保存到持久化介质上。 网络异常 有一种特殊的网络异常称为——网络分区 ，即集群的所有节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。 磁盘故障 磁盘故障是一种发生概率很高的异常。 使用冗余机制，将数据存储到多台服务器。 1.2. 超时 在分布式系统中，一个请求除了成功和失败两种状态，还存在着超时状态。 可以将服务器的操作设计为具有 幂等性 ，即执行多次的结果与执行一次的结果相同。如果使用这种方式，当出现超时的时候，可以不断地重新请求直到成功。 1.3. 衡量指标 性能 常见的性能指标有：吞吐量、响应时间。 其中，吞吐量指系统在某一段时间可以处理的请求总数，通常为每秒的读操作数或者写操作数；响应时间指从某个请求发出到接收到返回结果消耗的时间。 这两个指标往往是矛盾的，追求高吞吐的系统，往往很难做到低响应时间，解释如下： 在无并发的系统中，吞吐量为响应时间的倒数，例如响应时间为 10 ms，那么吞吐量为 100 req/s，因此高吞吐也就意味着低响应时间。 但是在并发的系统中，由于一个请求在调用 I/O 资源的时候，需要进行等待。服务器端一般使用的是异步等待方式，即等待的请求被阻塞之后不需要一直占用 CPU 资源。这种方式能大大提高 CPU 资源的利用率，例如上面的例子中，单个请求在无并发的系统中响应时间为 10 ms，如果在并发的系统中，那么吞吐量将大于 100 req/s。因此为了追求高吞吐量，通常会提高并发程度。但是并发程度的增加，会导致请求的平均响应时间也增加，因为请求不能马上被处理，需要和其它请求一起进行并发处理，响应时间自然就会增高。 可用性 可用性指系统在面对各种异常时可以提供正常服务的能力。可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。 一致性 可以从两个角度理解一致性：从客户端的角度，读写操作是否满足某种特性；从服务器的角度，多个数据副本之间是否一致。 可扩展性 指系统通过扩展集群服务器规模来提高性能的能力。理想的分布式系统需要实现“线性可扩展”，即随着集群规模的增加，系统的整体性能也会线性增加。 2. 数据分布 分布式存储系统的数据分布在多个节点中，常用的数据分布方式有哈希分布和顺序分布。 数据库的水平切分（Sharding）也是一种分布式存储方法，下面的数据分布方法同样适用于 Sharding。 2.1. 哈希分布 哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。例如有 N 个节点，数据的主键为 key，则将该数据分配的节点序号为：hash(key)%N。 传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。 一致性哈希 Distributed Hash Table（DHT）：对于哈希空间 [0, 2n-1]，将该哈希空间看成一个哈希环，将每个节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。 一致性哈希的优点是在增加或者删除节点时只会影响到哈希环中相邻的节点，例如下图中新增节点 X，只需要将数据对象 C 重新存放到节点 X 上即可，对于节点 A、B、D 都没有影响。 2.2. 顺序分布 哈希分布式破坏了数据的有序性，顺序分布则不会。 顺序分布的数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。例如下图中，User 表的 ID 范围为 1 ~ 7000，使用顺序分布可以将其划分成多个子表，对应的主键范围为 1 ~ 1000，1001 ~ 2000，…，6001 ~ 7000。 顺序分布的优点是可以充分利用每个节点的空间，而哈希分布很难控制一个节点存储多少数据。 但是顺序分布需要使用一个映射表来存储数据到节点的映射，这个映射表通常使用单独的节点来存储。当数据量非常大时，映射表也随着变大，那么一个节点就可能无法存放下整个映射表。并且单个节点维护着整个映射表的开销很大，查找速度也会变慢。为了解决以上问题，引入了一个中间层，也就是 Meta 表，从而分担映射表的维护工作。 2.3. 负载均衡 衡量负载的因素很多，如 CPU、内存、磁盘等资源使用情况、读写请求数等。 分布式系统存储应当能够自动负载均衡，当某个节点的负载较高，将它的部分数据迁移到其它节点。 每个集群都有一个总控节点，其它节点为工作节点，由总控节点根据全局负载信息进行整体调度，工作节点定时发送心跳包（Heartbeat）将节点负载相关的信息发送给总控节点。 一个新上线的工作节点，由于其负载较低，如果不加控制，总控节点会将大量数据同时迁移到该节点上，造成该节点一段时间内无法工作。因此负载均衡操作需要平滑进行，新加入的节点需要较长的一段时间来达到比较均衡的状态。 3. 分布式理论 3.1. CAP 分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容忍性（P：Partition Tolerance），最多只能同时满足其中两项。 一致性 一致性指的是多个数据副本是否能保持一致的特性。 在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。 对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。 可用性 可用性指分布式系统在面对各种异常时可以提供正常服务的能力，可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。 在可用性条件下，系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。 分区容忍性 网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。 在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。 权衡 在分布式系统中，分区容忍性必不可少，因为需要总是假设网络是不可靠的。因此，CAP 理论实际在是要在可用性和一致性之间做权衡。 可用性和一致性往往是冲突的，很难都使它们同时满足。在多个节点之间进行数据同步时， 为了保证一致性（CP），就需要让所有节点下线成为不可用的状态，等待同步完成； 为了保证可用性（AP），在同步过程中允许读取所有节点的数据，但是数据可能不一致。 3.2. BASE BASE 是基本可用（Basically Available）、软状态（Soft State）和最终一致性（Eventually Consistent）三个短语的缩写。 BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 基本可用 指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。 例如，电商在做促销时，为了保证购物系统的稳定性，部分消费者可能会被引导到一个降级的页面。 软状态 指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性，即允许系统不同节点的数据副本之间进行同步的过程存在延时。 最终一致性 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。 ACID 要求强一致性，通常运用在传统的数据库系统上。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在大型分布式系统中。 在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。 4. 分布式事务问题 4.1. 两阶段提交（2PC） 两阶段提交（Two-phase Commit，2PC） 主要用于实现分布式事务，分布式事务指的是事务操作跨越多个节点，并且要求满足事务的 ACID 特性。 通过引入协调者（Coordinator）来调度参与者的行为，并最终决定这些参与者是否要真正执行事务。 运行过程 准备阶段 协调者询问参与者事务是否执行成功，参与者发回事务执行结果。 提交阶段 如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。 需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。 问题 同步阻塞 所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。 单点问题 协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响，特别是在阶段二发生故障，所有参与者会一直等待状态，无法完成其它操作。 数据不一致 在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。 太过保守 任意一个节点失败就会导致整个事务失败，没有完善的容错机制。 2PC 优缺点 优点：尽量保证了数据的强一致，适合对数据强一致要求很高的关键领域。（其实也不能 100%保证强一致） 缺点：实现复杂，牺牲了可用性，对性能影响较大，不适合高并发高性能场景。 4.2. 补偿事务（TCC） 补偿事务（TCC）其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。它分为三个阶段： Try 阶段主要是对业务系统做检测及资源预留。 Confirm 阶段主要是对业务系统做确认提交，Try 阶段执行成功并开始执行 Confirm 阶段时，默认 Confirm 阶段是不会出错的。即：只要 Try 成功，Confirm 一定成功。 Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。 举个例子，假设 Bob 要向 Smith 转账，思路大概是： 首先在 Try 阶段，要先调用远程接口把 Smith 和 Bob 的钱给冻结起来。 在 Confirm 阶段，执行远程调用的转账的操作，转账成功进行解冻。 如果第 2 步执行成功，那么转账成功，如果第二步执行失败，则调用远程冻结接口对应的解冻方法 (Cancel)。 TCC 优缺点 优点：跟 2PC 比起来，实现以及流程相对简单了一些，但数据的一致性比 2PC 也要差一些。 缺点：缺点还是比较明显的，在 2,3 步中都有可能失败。TCC 属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用 TCC 不太好定义及处理。 4.3. 本地消息表（异步确保） 本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性。 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到 Kafka 等消息队列（MQ）中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。 这种方案遵循 BASE 理论，采用的是最终一致性。 本地消息表利用了本地事务来实现分布式事务，并且使用了消息队列来保证最终一致性。 本地消息表优缺点 优点：一种非常经典的实现，避免了分布式事务，实现了最终一致性。 缺点：消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。 4.4. MQ 事务消息 有一些第三方的 MQ 是支持事务消息的，比如 RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交。但是市面上一些主流的 MQ 都是不支持事务消息的，比如 RabbitMQ 和 Kafka 都不支持。 以阿里的 RocketMQ 中间件为例，其思路大致为： Prepared 消息，会拿到消息的地址。 执行本地事务。 通过第一阶段拿到的地址去访问消息，并修改状态。 也就是说在业务方法内要想消息队列提交两次请求，一次发送消息和一次确认消息。如果确认消息发送失败了 RocketMQ 会定期扫描消息集群中的事务消息，这时候发现了 Prepared 消息，它会向消息发送者确认，所以生产方需要实现一个 check 接口，RocketMQ 会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。 MQ 事务消息优缺点 优点：实现了最终一致性，不需要依赖本地数据库事务。 缺点：实现难度大，主流 MQ 不支持。 5. 共识性问题 5.1. Paxos 用于达成共识性问题，即对多个节点产生的值，该算法能保证只选出唯一一个值。 主要有三类节点： 提议者（Proposer）：提议一个值； 接受者（Acceptor）：对每个提议进行投票； 告知者（Learner）：被告知投票的结果，不参与投票过程。 算法需要满足 safety 和 liveness 两方面的约束要求（实际上这两个基础属性是大部分分布式算法都该考虑的）： safety：保证决议结果是对的，无歧义的，不会出现错误情况。 决议（value）只有在被 proposers 提出的 proposal 才能被最终批准； 在一次执行实例中，只批准（chosen）一个最终决议，意味着多数接受（accept）的结果能成为决议； liveness：保证决议过程能在有限时间内完成。 决议总会产生，并且 learners 能获得被批准（chosen）的决议。 基本过程包括 proposer 提出提案，先争取大多数 acceptor 的支持，超过一半支持时，则发送结案结果给所有人进行确认。一个潜在的问题是 proposer 在此过程中出现故障，可以通过超时机制来解决。极为凑巧的情况下，每次新的一轮提案的 proposer 都恰好故障，系统则永远无法达成一致（概率很小）。 Paxos 能保证在超过 1/21/21/2 的正常节点存在时，系统能达成共识。 单个提案者+多接收者 如果系统中限定只有某个特定节点是提案者，那么一致性肯定能达成（只有一个方案，要么达成，要么失败）。提案者只要收到了来自多数接收者的投票，即可认为通过，因为系统中不存在其他的提案。 但一旦提案者故障，则系统无法工作。 多个提案者+单个接收者 限定某个节点作为接收者。这种情况下，共识也很容易达成，接收者收到多个提案，选第一个提案作为决议，拒绝掉后续的提案即可。 缺陷也是容易发生单点故障，包括接收者故障或首个提案者节点故障。 以上两种情形其实类似主从模式，虽然不那么可靠，但因为原理简单而被广泛采用。 当提案者和接收者都推广到多个的情形，会出现一些挑战。 多个提案者+多个接收者 既然限定单提案者或单接收者都会出现故障，那么就得允许出现多个提案者和多个接收者。问题一下子变得复杂了。 一种情况是同一时间片段（如一个提案周期）内只有一个提案者，这时可以退化到单提案者的情形。需要设计一种机制来保障提案者的正确产生，例如按照时间、序列、或者大家猜拳（出一个数字来比较）之类。考虑到分布式系统要处理的工作量很大，这个过程要尽量高效，满足这一条件的机制非常难设计。 另一种情况是允许同一时间片段内可以出现多个提案者。那同一个节点可能收到多份提案，怎么对他们进行区分呢？这个时候采用只接受第一个提案而拒绝后续提案的方法也不适用。很自然的，提案需要带上不同的序号。节点需要根据提案序号来判断接受哪个。比如接受其中序号较大（往往意味着是接受新提出的，因为旧提案者故障概率更大）的提案。 如何为提案分配序号呢？一种可能方案是每个节点的提案数字区间彼此隔离开，互相不冲突。为了满足递增的需求可以配合用时间戳作为前缀字段。 此外，提案者即便收到了多数接收者的投票，也不敢说就一定通过。因为在此过程中系统可能还有其它的提案。 5.2. Raft Raft 算法是 Paxos 算法的一种简化实现。 包括三种角色：leader、candidate 和 follower，其基本过程为： Leader 选举 - 每个 candidate 随机经过一定时间都会提出选举方案，最近阶段中得票最多者被选为 leader； 同步 log - leader 会找到系统中 log 最新的记录，并强制所有的 follower 来刷新到这个记录； 注：此处 log 并非是指日志消息，而是各种事件的发生记录。 单个 Candidate 的竞选 有三种节点：Follower、Candidate 和 Leader。Leader 会周期性的发送心跳包给 Follower。每个 Follower 都设置了一个随机的竞选超时时间，一般为 150ms~300ms，如果在这个时间内没有收到 Leader 的心跳包，就会变成 Candidate，进入竞选阶段。 下图表示一个分布式系统的最初阶段，此时只有 Follower，没有 Leader。Follower A 等待一个随机的竞选超时时间之后，没收到 Leader 发来的心跳包，因此进入竞选阶段。 此时 A 发送投票请求给其它所有节点。 其它节点会对请求进行回复，如果超过一半的节点回复了，那么该 Candidate 就会变成 Leader。 之后 Leader 会周期性地发送心跳包给 Follower，Follower 接收到心跳包，会重新开始计时。 多个 Candidate 竞选 如果有多个 Follower 成为 Candidate，并且所获得票数相同，那么就需要重新开始投票，例如下图中 Candidate B 和 Candidate D 都获得两票，因此需要重新开始投票。 当重新开始投票时，由于每个节点设置的随机竞选超时时间不同，因此能下一次再次出现多个 Candidate 并获得同样票数的概率很低。 同步日志 来自客户端的修改都会被传入 Leader。注意该修改还未被提交，只是写入日志中。 Leader 会把修改复制到所有 Follower。 Leader 会等待大多数的 Follower 也进行了修改，然后才将修改提交。 此时 Leader 会通知的所有 Follower 让它们也提交修改，此时所有节点的值达成一致。 6. 分布式缓存问题 6.1. 缓存雪崩 缓存雪崩是指：在高并发场景下，由于原有缓存失效，新缓存未到期间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库 CPU 和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。 解决方案： 用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。 还有一个简单的方案，就是将缓存失效时间分散开，不要所有缓存时间长度都设置成 5 分钟或者 10 分钟；比如我们可以在原有的失效时间基础上增加一个随机值，比如 1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 缓存失效时产生的雪崩效应，将所有请求全部放在数据库上，这样很容易就达到数据库的瓶颈，导致服务无法正常提供。尽量避免这种场景的发生。 6.2. 缓存穿透 缓存穿透是指：用户查询的数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。 当在流量较大时，出现这样的情况，一直请求 DB，很容易导致服务挂掉。 解决方案： 在封装的缓存 SET 和 GET 部分增加个步骤，如果查询一个 KEY 不存在，就以这个 KEY 为前缀设定一个标识 KEY；以后再查询该 KEY 的时候，先查询标识 KEY，如果标识 KEY 存在，就返回一个协定好的非 false 或者 NULL 值，然后 APP 做相应的处理，这样缓存层就不会被穿透。当然这个验证 KEY 的失效时间不能太长。 如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，一般只有几分钟。 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。 6.3. 缓存预热 缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！ 解决方案： 直接写个缓存刷新页面，上线时手工操作下； 数据量不大，可以在项目启动的时候自动进行加载； 定时刷新缓存； 6.4. 缓存更新 除了缓存服务器自带的缓存失效策略之外（Redis 默认的有 6 中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种： 定时去清理过期的缓存； 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。 两者各有优劣，第一种的缺点是维护大量缓存的 key 是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。 6.5. 缓存降级 当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。 降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。 7. 参考资料 杨传辉. 大规模分布式存储系统: 原理解析与架构实战[M]. 机械工业出版社, 2013. 区块链技术指南 NEAT ALGORITHMS - PAXOS Raft: Understandable Distributed Consensus Paxos By Example 聊聊分布式事务，再说说解决方案]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码坏味道之耦合]]></title>
    <url>%2Fblog%2F2018%2F10%2F13%2Fdesign%2Frefactor%2F%E4%BB%A3%E7%A0%81%E5%9D%8F%E5%91%B3%E9%81%93%E4%B9%8B%E8%80%A6%E5%90%88%2F</url>
    <content type="text"><![CDATA[代码坏味道之耦合 📓 本文已归档到：「blog」 翻译自：https://sourcemaking.com/refactoring/smells/couplers 耦合(Couplers)这组坏味道意味着：不同类之间过度耦合。 不完美的库类 中间人 依恋情结 狎昵关系 过度耦合的消息链 扩展阅读 参考资料 不完美的库类 不完美的库类(Incomplete Library Class) 当一个类库已经不能满足实际需要时，你就不得不改变这个库（如果这个库是只读的，那就没辙了）。 问题原因 许多编程技术都建立在库类的基础上。库类的作者没用未卜先知的能力，不能因此责怪他们。麻烦的是库往往构造的不够好，而且往往不可能让我们修改其中的类以满足我们的需要。 解决方法 如果你只想修改类库的一两个函数，可以运用 引入外加函数(Introduce Foreign Method)； 如果想要添加一大堆额外行为，就得运用 引入本地扩展(Introduce Local Extension) 。 收益 减少代码重复（你不用一言不合就自己动手实现一个库的全部功能，代价太高） 何时忽略 如果扩展库会带来额外的工作量。 重构方法说明 引入外加函数(Introduce Foreign Method) 问题 你需要为提供服务的类增加一个函数，但你无法修改这个类。 class Report &#123; //... void sendReport() &#123; Date nextDay = new Date(previousEnd.getYear(), previousEnd.getMonth(), previousEnd.getDate() + 1); //... &#125;&#125; 解决 在客户类中建立一个函数，并一个第一个参数形式传入一个服务类实例。 class Report &#123; //... void sendReport() &#123; Date newStart = nextDay(previousEnd); //... &#125; private static Date nextDay(Date arg) &#123; return new Date(arg.getYear(), arg.getMonth(), arg.getDate() + 1); &#125;&#125; 引入本地扩展(Introduce Local Extension) 问题 你需要为服务类提供一些额外函数，但你无法修改这个类。 解决 建立一个新类，使它包含这些额外函数，让这个扩展品成为源类的子类或包装类。 中间人 中间人(Middle Man) 如果一个类的作用仅仅是指向另一个类的委托，为什么要存在呢？ 问题原因 对象的基本特征之一就是封装：对外部世界隐藏其内部细节。封装往往伴随委托。但是人们可能过度运用委托。比如，你也许会看到一个类的大部分有用工作都委托给了其他类，类本身成了一个空壳，除了委托之外不做任何事情。 解决方法 应该运用 移除中间人(Remove Middle Man)，直接和真正负责的对象打交道。 收益 减少笨重的代码。 何时忽略 如果是以下情况，不要删除已创建的中间人： 添加中间人是为了避免类之间依赖关系。 一些设计模式有目的地创建中间人（例如代理模式和装饰器模式）。 重构方法说明 移除中间人(Remove Middle Man) 问题 某个类做了过多的简单委托动作。 解决 让客户直接调用委托类。 依恋情结 依恋情结(Feature Envy) 一个函数访问其它对象的数据比访问自己的数据更多。 问题原因 这种气味可能发生在字段移动到数据类之后。如果是这种情况，你可能想将数据类的操作移动到这个类中。 解决方法 As a basic rule, if things change at the same time, you should keep them in the same place. Usually data and functions that use this data are changed together (although exceptions are possible). 有一个基本原则：同时会发生改变的事情应该被放在同一个地方。通常，数据和使用这些数据的函数是一起改变的。 如果一个函数明显应该被移到另一个地方，可运用 搬移函数(Move Method) 。 如果仅仅是函数的部分代码访问另一个对象的数据，运用 提炼函数(Extract Method) 将这部分代码移到独立的函数中。 如果一个方法使用来自其他几个类的函数，首先确定哪个类包含大多数使用的数据。然后，将该方法与其他数据一起放在此类中。或者，使用 提炼函数(Extract Method) 将方法拆分为几个部分，可以放置在不同类中的不同位置。 收益 减少重复代码（如果数据处理的代码放在中心位置）。 更好的代码组织性（处理数据的函数靠近实际数据）。 何时忽略 有时，行为被有意地与保存数据的类分开。这通常的优点是能够动态地改变行为（见策略设计模式，访问者设计模式和其他模式）。 重构方法说明 搬移函数(Move Method) 问题 你的程序中，有个函数与其所驻类之外的另一个类进行更多交流：调用后者，或被后者调用。 解决 在该函数最常引用的类中建立一个有着类似行为的新函数。将旧函数变成一个单纯的委托函数，或是旧函数完全移除。 提炼函数(Extract Method) 问题 你有一段代码可以组织在一起。 void printOwing() &#123; printBanner(); //print details System.out.println("name: " + name); System.out.println("amount: " + getOutstanding());&#125; 解决 移动这段代码到一个新的函数中，使用函数的调用来替代老代码。 void printOwing() &#123; printBanner(); printDetails(getOutstanding());&#125;void printDetails(double outstanding) &#123; System.out.println("name: " + name); System.out.println("amount: " + outstanding);&#125; 狎昵关系 狎昵关系(Inappropriate Intimacy) 一个类大量使用另一个类的内部字段和方法。 问题原因 类和类之间应该尽量少的感知彼此（减少耦合）。这样的类更容易维护和复用。 解决方法 最简单的解决方法是运用 搬移函数(Move Method) 和 搬移字段(Move Field) 来让类之间斩断羁绊。 你也可以看看是否能运用 将双向关联改为单向关联(Change Bidirectional Association to Unidirectional) 让其中一个类对另一个说分手。 如果这两个类实在是情比金坚，难分难舍，可以运用 提炼类(Extract Class) 把二者共同点提炼到一个新类中，让它们产生爱的结晶。或者，可以尝试运用 隐藏委托关系(Hide Delegate) 让另一个类来为它们牵线搭桥。 继承往往造成类之间过分紧密，因为子类对超类的了解总是超过后者的主观愿望，如果你觉得该让这个子类自己闯荡，请运用 以委托取代继承(Replace Inheritance with Delegation) 来让超类和子类分家。 收益 提高代码组织性。 提高代码复用性。 重构方法说明 搬移函数(Move Method) 问题 你的程序中，有个函数与其所驻类之外的另一个类进行更多交流：调用后者，或被后者调用。 解决 在该函数最常引用的类中建立一个有着类似行为的新函数。将旧函数变成一个单纯的委托函数，或是旧函数完全移除。 搬移字段(Move Field) 问题 在你的程序中，某个字段被其所驻类之外的另一个类更多地用到。 解决 在目标类新建一个字段，修改源字段的所有用户，令他们改用新字段。 将双向关联改为单向关联(Change Bidirectional Association to Unidirectional) 问题 两个类之间有双向关联，但其中一个类如今不再需要另一个类的特性。 解决 去除不必要的关联。 提炼类(Extract Class) 问题 某个类做了不止一件事。 解决 建立一个新类，将相关的字段和函数从旧类搬移到新类。 隐藏委托关系(Hide Delegate) 问题 客户通过一个委托类来调用另一个对象。 解决 在服务类上建立客户所需的所有函数，用以隐藏委托关系。 以委托取代继承(Replace Inheritance with Delegation) 问题 某个子类只使用超类接口中的一部分，或是根本不需要继承而来的数据。 解决 在子类中新建一个字段用以保存超类；调整子类函数，令它改而委托超类；然后去掉两者之间的继承关系。 过度耦合的消息链 过度耦合的消息链(Message Chains) 消息链的形式类似于：obj.getA().getB().getC()。 问题原因 如果你看到用户向一个对象请求另一个对象，然后再向后者请求另一个对象，然后再请求另一个对象……这就是消息链。实际代码中你看到的可能是一长串 getThis()或一长串临时变量。采取这种方式，意味客户代码将与查找过程中的导航紧密耦合。一旦对象间关系发生任何变化，客户端就不得不做出相应的修改。 解决方法 可以运用 隐藏委托关系(Hide Delegate) 删除一个消息链。 有时更好的选择是：先观察消息链最终得到的对象是用来干什么的。看看能否以 提炼函数(Extract Method)把使用该对象的代码提炼到一个独立函数中，再运用 搬移函数(Move Method) 把这个函数推入消息链。 收益 能减少链中类之间的依赖。 能减少代码量。 何时忽略 过于侵略性的委托可能会使程序员难以理解功能是如何触发的。 重构方法说明 隐藏委托关系(Hide Delegate) 问题 客户通过一个委托类来调用另一个对象。 解决 在服务类上建立客户所需的所有函数，用以隐藏委托关系。 提炼函数(Extract Method) 问题 你有一段代码可以组织在一起。 void printOwing() &#123; printBanner(); //print details System.out.println("name: " + name); System.out.println("amount: " + getOutstanding());&#125; 解决 移动这段代码到一个新的函数中，使用函数的调用来替代老代码。 void printOwing() &#123; printBanner(); printDetails(getOutstanding());&#125;void printDetails(double outstanding) &#123; System.out.println("name: " + name); System.out.println("amount: " + outstanding);&#125; 搬移函数(Move Method) 问题 你的程序中，有个函数与其所驻类之外的另一个类进行更多交流：调用后者，或被后者调用。 解决 在该函数最常引用的类中建立一个有着类似行为的新函数。将旧函数变成一个单纯的委托函数，或是旧函数完全移除。 扩展阅读 代码的坏味道和重构 代码坏味道之代码臃肿 代码坏味道之滥用面向对象 代码坏味道之变革的障碍 代码坏味道之非必要的 代码坏味道之耦合 参考资料 重构——改善既有代码的设计 - by Martin Fowler https://sourcemaking.com/refactoring]]></content>
      <categories>
        <category>design</category>
        <category>refactor</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>refactor</tag>
        <tag>code-smell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码的坏味道和重构]]></title>
    <url>%2Fblog%2F2018%2F10%2F13%2Fdesign%2Frefactor%2F%E4%BB%A3%E7%A0%81%E7%9A%84%E5%9D%8F%E5%91%B3%E9%81%93%E5%92%8C%E9%87%8D%E6%9E%84%2F</url>
    <content type="text"><![CDATA[代码的坏味道和重构 📓 本文已归档到：「blog」 症与药 对代码的坏味道的思考 重构的原则 代码的坏味道 代码坏味道之代码臃肿 代码坏味道之滥用面向对象 代码坏味道之变革的障碍 代码坏味道之非必要的 代码坏味道之耦合 扩展阅读 参考资料 第一次读《重构:改善既有代码的设计》时，我曾整理过一个简单的笔记。最近，因为参与一个重构项目，再一次温习了《重构:改善既有代码的设计》。过程中，萌发了认真总结、整理重构方法的冲动，于是有了这系列文字。 代码的坏味道还有几篇没有完稿，后面我会陆续补充。。。 症与药 对代码的坏味道的思考 “有病要早治，不要放弃治疗”。多么朴素的道理 ，人人都懂。 病，就是不健康。 人有病，可以通过打针、吃药、做手术来进行治疗。 如果把代码的坏味道（代码质量问题）比作病症，那么重构就是治疗代码的坏味道的药。 个人认为，在重构这件事上，也可以应用治病的道理： 防病于未然。 —— 春秋战国时期的一代名医扁鹊，曾经有个很著名的医学主张：防病于未然。 我觉得这个道理应用于软件代码的重构亦然。编程前要有合理的设计、编程时要有良好的编程风格，尽量减少问题。从这个层面上说，了解代码的坏味道，不仅仅是为了发现问题、解决问题。更重要的作用是：指导我们在编程过程中有意识的去规避这些问题。 小病不医，易得大病。 —— 刘备说过：“勿以善小而不为，勿以恶小而为之”。发现问题就及时修改，代码质量自然容易进入良性循环；反之，亦然。要重视积累的力量，别总以为代码出现点小问题，那都不是事儿。 对症下药。 —— 程序出现了问题，要分析出问题的根本，有针对性的制定合理的重构方案。大家都知道吃错药的后果，同样的，瞎改还不如不改。 忌猛药 —— 医病用猛药容易产生副作用。换一句俗语：步子大了容易扯着蛋。重构如果大刀阔斧的干，那你就要有随时可能扑街的心理准备。推倒重来不是重构，而是重写。重构应该是循序渐进，步步为营的过程。当你发现重写代码比重构代码更简单，往往说明你早就该重构了。 重构的原则 前面把代码质量问题比作病症，而把重构比作药。这里，我们再进一步讨论一下重构的原则。 何谓重构(What) 重构（Refactoring） 的常见定义是：不改变软件系统外部行为的前提下，改善它的内部结构。 个人觉得这个定义有点生涩。不妨理解为：重构是给代码治病的行为。而代码有病是指代码的质量（可靠性、安全性、可复用性、可维护性）和性能有问题。 重构的目的是为了提高代码的质量和性能。 注：功能不全或者不正确，那是残疾代码。就像治病治不了残疾，重构也解决不了功能问题。 为何重构(Why) 翻翻书，上网搜一下，谈到重构的理由大体相同： 重构改进软件设计 重构使软件更容易理解 重构帮助找到 bug 重构提高编程速度 总之就是，重构可以提高代码质量。 何时重构(When) 关于何时重构，我先引用一下 重构并非难在如何做，而是难在何时开始做 一文的观点。 对于一个高速发展的公司来说，停止业务开发，专门来做重构项目，从来就不是一个可接受的选项，“边开飞机边换引擎”才是这种公司想要的。 我们不妨来衡量一下重构的成本和收益。 重构的成本 重构是有成本的，费时费力（时间、人力）不说，还有可能会使本来正常运行的程序出错。所以，很多人都抱着“不求有功，但求无过”的心理得过且过。 还有一种成本：重构使用较新且较为复杂的技术，学习曲线不平滑，团队成员技术切换困难，短期内开发效率可能不升反降。 但是，如果一直放任代码腐朽下去，技术债务会越来越沉重。当代码最终快要跑不动时，架构师们往往还是不得不使用激进的手段来治疗代码的顽疾。但是，这个过程通常都是非常痛苦的，而且有着很高的失败风险。 重构的收益 重构的收益是提高代码的质量和性能，并提高未来的开发效率。但是，应当看到，重构往往并不能在短期内带来实际的效益，或者很难直观看出效益。而对于一个企业来说，没有什么比效益更重要。换句话说，没有实际效益的事，通常也没有价值。很多领导，尤其是非技术方向的领导，并不关心你应用了什么新技术，让代码变得多么优雅等等。 重构的合适时机 从以上来看，重构实在是个吃力不讨好的事情。 于是，很多人屈服于万恶的 KPI 和要命的 deadline，一边吐槽着以前的代码是垃圾，一边自己也在造垃圾。 但是，**重构本应该是个渐进式的过程，不是只有伤筋动骨的改造才叫重构。**如果非要等到代码已经烂到病入膏肓，再使用激进方式来重构，那必然是困难重重，风险极高。 《重构》书中提到的重构时机应该在添加功能、修复功能、审查代码时，不建议专门抽出时间专门做重构项目。 我认为，其思想就是指：重构应该是在开发过程中实时的、渐进的演化过程。 重构的不恰当时机 但是，这里我也要强调一下：不是所有软件开发过程都一定要重构。 较能凸显重构价值的场景是：代码规模较大、生命周期还较长、承担了较多责任、有一个较大（且较不稳定，人员流动频繁）团队在其上工作的单一代码库。 与之相反，有一些场景的重构价值就很小： 代码库生命周期快要走到尾声，开发逐渐减少，以维护为主。 代码库当前版本马上要发布了，这时重构无疑是给自己找麻烦。 重构代价过于沉重：重构后功能的正确性、稳定性难以保障；技术过于超前，团队成员技术迁移难度太大。 如何重构(How) 重构行为在我看来，也是可以分层级的。由高到低，越高层级难度越大： 服务、数据库 现代软件往往业务复杂、庞大。使用微服务、数据迁移来拆分业务，降低业务复杂度成为了主流。但是，这些技术的测试、部署复杂，技术难度很高。 组件、模块、框架 组件、模块、框架的重构，主要是针对代码的设计问题。解决的是代码的整体结构问题。需要对框架、设计模式、分布式、并发等等有足够的了解。 类、接口、函数、字段 《重构》一书提到了**“代码的坏味道”**以及相关的重构方法。这些都是对类、接口、函数、字段级别代码的重构手段。由于这一级别的重构方法较为简单，所以可操作性较强。具体细节可以阅读《代码的坏味道》篇章。 前两种层级的重构已经涉及到架构层面，影响较大，难度较高，如果功力不够不要轻易变动。由于这两个层级涉及领域较广，这里不做论述。 此处为分割线。下面是代码的坏味道系列。。。 代码的坏味道 《重构:改善既有代码的设计》中介绍了 22 种代码的坏味道以及重构手法。这些坏味道可以进一步归类。我总觉得将事物分类有助于理解和记忆。所以本系列将坏味道按照特性分类，然后逐一讲解。 代码坏味道之代码臃肿 代码臃肿(Bloated)这组坏味道意味着：代码中的类、函数、字段没有经过合理的组织，只是简单的堆砌起来。这一类型的问题通常在代码的初期并不明显，但是随着代码规模的增长而逐渐积累（特别是当没有人努力去根除它们时）。 过长函数 过大的类 基本类型偏执 过长参数列 数据泥团 代码坏味道之滥用面向对象 滥用面向对象(Object-Orientation Abusers)这组坏味道意味着：代码部分或完全地违背了面向对象编程原则。 switch 声明 临时字段 被拒绝的馈赠 异曲同工的类 代码坏味道之变革的障碍 变革的障碍(Change Preventers)这组坏味道意味着：当你需要改变一处代码时，却发现不得不改变其他的地方。这使得程序开发变得复杂、代价高昂。 发散式变化 霰弹式修改 平行继承体系 代码坏味道之非必要的 非必要的(Dispensables)这组坏味道意味着：这样的代码可有可无，它的存在反而影响整体代码的整洁和可读性。 过多的注释 重复代码 冗余类 纯稚的数据类 夸夸其谈未来性 代码坏味道之耦合 耦合(Couplers)这组坏味道意味着：不同类之间过度耦合。 依恋情结 狎昵关系 过度耦合的消息链 中间人 不完美的库类 扩展阅读 代码的坏味道和重构 代码坏味道之代码臃肿 代码坏味道之滥用面向对象 代码坏味道之变革的障碍 代码坏味道之非必要的 代码坏味道之耦合 参考资料 重构——改善既有代码的设计 - by Martin Fowler https://sourcemaking.com/refactoring]]></content>
      <categories>
        <category>design</category>
        <category>refactor</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>refactor</tag>
        <tag>code-smell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sqoop]]></title>
    <url>%2Fblog%2F2018%2F09%2F04%2Fbigdata%2FSqoop%2F</url>
    <content type="text"><![CDATA[Sqoop Sqoop 是一个主要在 Hadoop 和关系数据库之间进行批量数据迁移的工具。 Sqoop 简介 提供多种 Sqoop 连接器 Sqoop 版本 Sqoop 原理 导入 导出 Sqoop 简介 Sqoop 是一个主要在 Hadoop 和关系数据库之间进行批量数据迁移的工具。 Hadoop：HDFS、Hive、HBase、Inceptor、Hyperbase 面向大数据集的批量导入导出 将输入数据集分为 N 个切片，然后启动 N 个 Map 任务并行传输 支持全量、增量两种传输方式 提供多种 Sqoop 连接器 内置连接器 经过优化的专用 RDBMS 连接器：MySQL、PostgreSQL、Oracle、DB2、SQL Server、Netzza 等 通用的 JDBC 连接器：支持 JDBC 协议的数据库 第三方连接器 数据仓库：Teradata NoSQL 数据库：Couchbase Sqoop 版本 Sqoop 1 优缺点 优点 架构简单 部署简单 功能全面 稳定性较高 速度较快 缺点 访问方式单一 命令行方式容易出错，格式紧耦合 安全机制不够完善，存在密码泄露风险 Sqoop 2 优缺点 优点 访问方式多样 集中管理连接器 安全机制较完善 支持多用户 缺点 架构较复杂 部署较繁琐 稳定性一般 速度一般 Sqoop 原理 导入 导出]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>bigdata</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flume]]></title>
    <url>%2Fblog%2F2018%2F09%2F04%2Fbigdata%2FFlume%2F</url>
    <content type="text"><![CDATA[Flume Sqoop 是一个主要在 Hadoop 和关系数据库之间进行批量数据迁移的工具。 Flume 简介 什么是 Flume ？ 应用场景 Flume 原理 Flume 基本概念 Flume 基本组件 Flume 数据流 资源 Flume 简介 什么是 Flume ？ Flume 是一个分布式海量数据采集、聚合和传输系统。 特点 基于事件的海量数据采集 数据流模型：Source -&gt; Channel -&gt; Sink 事务机制：支持重读重写，保证消息传递的可靠性 内置丰富插件：轻松与各种外部系统集成 高可用：Agent 主备切换 Java 实现：开源，优秀的系统设计 应用场景 Flume 原理 Flume 基本概念 Event：事件，最小数据传输单元，由 Header 和 Body 组成。 Agent：代理，JVM 进程，最小运行单元，由 Source、Channel、Sink 三个基本组件构成，负责将外部数据源产生的数据以 Event 的形式传输到目的地 Source：负责对接各种外部数据源，将采集到的数据封装成 Event，然后写入 Channel Channel：Event 暂存容器，负责保存 Source 发送的 Event，直至被 Sink 成功读取 Sink：负责从 Channel 读取 Event，然后将其写入外部存储，或传输给下一阶段的 Agent 映射关系：1 个 Source -&gt; 多个 Channel，1 个 Channel -&gt; 多个 Sink，1 个 Sink -&gt; 1 个 Channel Flume 基本组件 Source 组件 对接各种外部数据源，将采集到的数据封装成 Event，然后写入 Channel 一个 Source 可向多个 Channel 发送 Event Flume 内置类型丰富的 Source，同时用户可自定义 Source Channel 组件 Event 中转暂存区，存储 Source 采集但未被 Sink 读取的 Event 为了平衡 Source 采集、Sink 读取的速度，可视为 Flume 内部的消息队列 线程安全并具有事务性，支持 Source 写失败重写和 Sink 读失败重读 Sink 组件 从 Channel 读取 Event，将其写入外部存储，或传输到下一阶段的 Agent 一个 Sink 只能从一个 Channel 中读取 Event Sink 成功读取 Event 后，向 Channel 提交事务，Event 被删除，否则 Channel 会等待 Sink 重新读取 Flume 数据流 单层架构 优点：架构简单，使用方便，占用资源较少 缺点 如果采集的数据源或Agent较多，将Event写入到HDFS会产生很多小文件 外部存储升级维护或发生故障，需对采集层的所有Agent做处理，人力成本较高，系统稳定性较差 系统安全性较差 数据源管理较混乱 资源]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>bigdata</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDFS]]></title>
    <url>%2Fblog%2F2018%2F09%2F03%2Fbigdata%2FHDFS%2F</url>
    <content type="text"><![CDATA[HDFS HDFS 是 Hadoop 分布式文件系统。 关键词：分布式、文件系统 概述 HDFS 的特点 HDFS 的概念 NameNode DataNode Block 数据块 Client Block 副本策略 数据流 HDFS 读文件 HDFS 写文件 HDFS 安全模式 什么是安全模式？ 何时正常离开安全模式 触发安全模式的原因 故障排查 HDFS 高可用 NameNode 的 HA 机制 利用 QJM 实现元数据高可用 资源 概述 HDFS 是 Hadoop 的核心子项目。 HDFS 是 Hadoop Distributed File System 的缩写，即 Hadoop 分布式文件系统。 HDFS 是一种用于存储具有流数据访问模式的超大文件的文件系统，它运行在廉价的机器集群上。 HDFS 的特点 优点 高容错 - 数据冗余多副本，副本丢失后自动恢复 高可用 - NameNode HA、安全模式 高扩展 - 能够处理 10K 节点的规模；处理数据达到 GB、TB、甚至 PB 级别的数据；能够处理百万规模以上的文件数量，数量相当之大。 批处理 - 流式数据访问；数据位置暴露给计算框架 构建在廉价商用机器上 - 提供了容错和恢复机制 缺点 不适合低延迟数据访问 - 适合高吞吐率的场景，就是在某一时间内写入大量的数据。但是它在低延时的情况下是不行的，比如毫秒级以内读取数据，它是很难做到的。 不适合大量小文件存储 存储大量小文件(这里的小文件是指小于 HDFS 系统的 Block 大小的文件（默认 64M）)的话，它会占用 NameNode 大量的内存来存储文件、目录和块信息。这样是不可取的，因为 NameNode 的内存总是有限的。 磁盘寻道时间超过读取时间 不支持并发写入 - 一个文件同时只能有一个写入者 不支持文件随机修改 - 仅支持追加写入 HDFS 的概念 HDFS 采用 Master/Slave 架构。 一个 HDFS 集群是由一个 Namenode 和一定数目的 Datanodes 组成。Namenode 是一个中心服务器，负责管理文件系统的名字空间(namespace)以及客户端对文件的访问。集群中的 Datanode 一般是一个节点一个，负责管理它所在节点上的存储。HDFS 暴露了文件系统的名字空间，用户能够以文件的形式在上面存储数据。从内部看，一个文件其实被分成一个或多个数据块，这些块存储在一组 Datanode 上。Namenode 执行文件系统的名字空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体 Datanode 节点的映射。Datanode 负责处理文件系统客户端的读写请求。在 Namenode 的统一调度下进行数据块的创建、删除和复制。 NameNode NameNode 就是 master 工作节点。 管理命名空间 管理元数据：文件的位置、所有者、权限、数据块等 管理 Block 副本策略：默认 3 个副本 处理客户端读写请求，为 DataNode 分配任务 Active NameNode 和 Standby NameNode NameNode 通过 HA 机制来容错。 Active NameNode - 是正在工作的 NameNode； Standby NameNode - 是备份的 NameNode。 Active NameNode 宕机后，Standby NameNode 快速升级为新的 Active NameNode。 Standby NameNode 周期性同步 edits 编辑日志，定期合并 fsimage 与 edits 到本地磁盘。 Hadoop 3.0 允许配置多个 Standby NameNode。 元数据文件 edits（编辑日志文件） - 保存了自最新检查点（Checkpoint）之后的所有文件更新操作。 fsimage（元数据检查点镜像文件） - 保存了文件系统中所有的目录和文件信息，如：某个目录下有哪些子目录和文件，以及文件名、文件副本数、文件由哪些 Block 组成等。 Active NameNode 内存中有一份最新的元数据（= fsimage + edits）。 Standby NameNode 在检查点定期将内存中的元数据保存到 fsimage 文件中。 DataNode **DataNode 就是 slave 工作节点。**NameNode 下达命令，DataNode 执行实际的操作。 存储 Block 和数据校验和 执行客户端发送的读写操作 通过心跳机制定期（默认 3 秒）向 NameNode 汇报运行状态和 Block 列表信息 集群启动时，DataNode 向 NameNode 提供 Block 列表信息 Block 数据块 HDFS 最小存储单元 文件写入 HDFS 会被切分成若干个 Block Block 大小固定，默认为 128MB，可自定义 若一个 Block 的大小小于设定值，不会占用整个块空间 默认情况下每个 Block 有 3 个副本 Client 将文件切分为 Block 数据块 与 NameNode 交互，获取文件元数据 与 DataNode 交互，读取或写入数据 管理 HDFS Block 副本策略 HDFS 被设计成能够在一个大集群中跨机器可靠地存储超大文件。它将每个文件存储成一系列的数据块，除了最后一个，所有的数据块都是同样大小的。为了容错，文件的所有数据块都会有副本。每个文件的数据块大小和副本系数都是可配置的。应用程序可以指定某个文件的副本数目。副本系数可以在文件创建的时候指定，也可以在之后改变。HDFS 中的文件都是一次性写入的，并且严格要求在任何时候只能有一个写入者。 Namenode 全权管理数据块的复制，它周期性地从集群中的每个 Datanode 接收心跳信号和块状态报告(Blockreport)。接收到心跳信号意味着该 Datanode 节点工作正常。块状态报告包含了一个该 Datanode 上所有数据块的列表。 副本 1：放在 Client 所在节点 对于远程 Client，系统会随机选择节点 副本 2：放在不同的机架节点上 副本 3：放在与第二个副本同一机架的不同节点上 副本 N：随机选择 节点选择：同等条件下优先选择空闲节点 数据流 HDFS 读文件 客户端调用 FileSyste 对象的 open() 方法在分布式文件系统中打开要读取的文件。 分布式文件系统通过使用 RPC（远程过程调用）来调用 namenode，确定文件起始块的位置。 分布式文件系统的 DistributedFileSystem 类返回一个支持文件定位的输入流 FSDataInputStream 对象，FSDataInputStream 对象接着封装 DFSInputStream 对象（存储着文件起始几个块的 datanode 地址），客户端对这个输入流调用 read()方法。 DFSInputStream 连接距离最近的 datanode，通过反复调用 read 方法，将数据从 datanode 传输到客户端。 到达块的末端时，DFSInputStream 关闭与该 datanode 的连接，寻找下一个块的最佳 datanode。 客户端完成读取，对 FSDataInputStream 调用 close()方法关闭连接。 HDFS 写文件 客户端通过对 DistributedFileSystem 对象调用 create() 函数来新建文件。 分布式文件系统对 namenod 创建一个 RPC 调用，在文件系统的命名空间中新建一个文件。 Namenode 对新建文件进行检查无误后，分布式文件系统返回给客户端一个 FSDataOutputStream 对象，FSDataOutputStream 对象封装一个 DFSoutPutstream 对象，负责处理 namenode 和 datanode 之间的通信，客户端开始写入数据。 FSDataOutputStream 将数据分成一个一个的数据包，写入内部队列“数据队列”，DataStreamer 负责将数据包依次流式传输到由一组 namenode 构成的管线中。 DFSOutputStream 维护着确认队列来等待 datanode 收到确认回执，收到管道中所有 datanode 确认后，数据包从确认队列删除。 客户端完成数据的写入，对数据流调用 close() 方法。 namenode 确认完成。 HDFS 安全模式 什么是安全模式？ 安全模式是 HDFS 的一种特殊状态，在这种状态下，HDFS 只接收读数据请求，而不接收写入、删除、修改等变更请求。 安全模式是 HDFS 确保 Block 数据安全的一种保护机制。 Active NameNode 启动时，HDFS 会进入安全模式，DataNode 主动向 NameNode 汇报可用 Block 列表等信息，在系统达到安全标准前，HDFS 一直处于“只读”状态。 何时正常离开安全模式 Block 上报率：DataNode 上报的可用 Block 个数 / NameNode 元数据记录的 Block 个数 当 Block 上报率 &gt;= 阈值时，HDFS 才能离开安全模式，默认阈值为 0.999 不建议手动强制退出安全模式 触发安全模式的原因 NameNode 重启 NameNode 磁盘空间不足 Block 上报率低于阈值 DataNode 无法正常启动 日志中出现严重异常 用户操作不当，如：强制关机（特别注意！） 故障排查 找到 DataNode 不能正常启动的原因，重启 DataNode 清理 NameNode 磁盘 谨慎操作，有问题找星环，以免丢失数据 HDFS 高可用 NameNode 的 HA 机制 Active NameNode 和 Standby NameNode 实现主备。 利用 QJM 实现元数据高可用 基于 Paxos 算法 QJM 机制（Quorum Journal Manager） 只要保证 Quorum（法定人数）数量的操作成功，就认为这是一次最终成功的操作 QJM 共享存储系统 部署奇数（2N+1）个 JournalNode JournalNode 负责存储 edits 编辑日志 写 edits 的时候，只要超过半数（N+1）的 JournalNode 返回成功，就代表本次写入成功 最多可容忍 N 个 JournalNode 宕机 利用 ZooKeeper 实现 Active 节点选举。 资源 HDFS 官方文档 HDFS 知识点总结 《Hadoop: The Definitive Guide, Fourth Edition》 by Tom White http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_design.html]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>bigdata</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark]]></title>
    <url>%2Fblog%2F2018%2F09%2F03%2Fbigdata%2FSpark%2F</url>
    <content type="text"><![CDATA[Spark Spark 简介 Spark 概念 Spark 特点 Spark 原理 编程模型 Spark 简介 Spark 概念 大规模分布式通用计算引擎 Spark Core：核心计算框架 Spark SQL：结构化数据查询 Spark Streaming：实时流处理 Spark MLib：机器学习 Spark GraphX：图计算 具有高吞吐、低延时、通用易扩展、高容错等特点 采用 Scala 语言开发 提供多种运行模式 Spark 特点 计算高效 利用内存计算、Cache 缓存机制，支持迭代计算和数据共享，减少数据读取的 IO 开销 利用 DAG 引擎，减少中间计算结果写入 HDFS 的开销 利用多线程池模型，减少任务启动开销，避免 Shuffle 中不必要的排序和磁盘 IO 操作 通用易用 适用于批处理、流处理、交互式计算、机器学习算法等场景 提供了丰富的开发 API，支持 Scala、Java、Python、R 等 运行模式多样 Local 模式 Standalone 模式 YARN/Mesos 模式 计算高效 利用内存计算、Cache 缓存机制，支持迭代计算和数据共享，减少数据读取的 IO 开销 利用 DAG 引擎，减少中间计算结果写入 HDFS 的开销 利用多线程池模型，减少任务启动开销，避免 Shuffle 中不必要的排序和磁盘 IO 操作 通用易用 适用于批处理、流处理、交互式计算、机器学习等场景 提供了丰富的开发 API，支持 Scala、Java、Python、R 等 Spark 原理 编程模型 RDD 弹性分布式数据集（Resilient Distributed Datesets） 分布在集群中的只读对象集合 由多个 Partition 组成 通过转换操作构造 失效后自动重构（弹性） 存储在内存或磁盘中 Spark 基于 RDD 进行计算 RDD 操作（Operator） Transformation（转换） 将 Scala 集合或 Hadoop 输入数据构造成一个新 RDD 通过已有的 RDD 产生新 RDD 惰性执行：只记录转换关系，不触发计算 例如：map、filter、flatmap、union、distinct、sortbykey Action（动作） 通过 RDD 计算得到一个值或一组值 真正触发计算 例如：first、count、collect、foreach、saveAsTextFile RDD 依赖（Dependency） 窄依赖（Narrow Dependency） 父 RDD 中的分区最多只能被一个子 RDD 的一个分区使用 子 RDD 如果有部分分区数据丢失或损坏，只需从对应的父 RDD 重新计算恢复 例如：map、filter、union 宽依赖（Shuffle/Wide Dependency ） 子 RDD 分区依赖父 RDD 的所有分区 子 RDD 如果部分或全部分区数据丢失或损坏，必须从所有父 RDD 分区重新计算 相对于窄依赖，宽依赖付出的代价要高很多，尽量避免使用 例如：groupByKey、reduceByKey、sortByKey]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>bigdata</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MapReduce]]></title>
    <url>%2Fblog%2F2018%2F09%2F03%2Fbigdata%2FMapReduce%2F</url>
    <content type="text"><![CDATA[MapReduce MapReduce 简介 概念 思想 特点 适用场景 不适用场景 MapReduce 原理 Job &amp; Task（作业与任务） Split（切片） Map 阶段（映射） Reduce 阶段（化简） Shuffle 阶段（洗牌） Shuffle 详解 Map 端 Reduce 端 作业运行模式 JobTracker/TaskTracker 模式（Hadoop 1.X） YARN 模式（Hadoop 2.X） MapReduce 简介 概念 MapReduce 是一个面向批处理的分布式计算框架。 编程模型：MapReduce 程序被分为 Map（映射）阶段和 Reduce（化简）阶段。 思想 分而治之，并行计算 移动计算，而非移动数据 特点 计算跟着数据走 良好的扩展性：计算能力随着节点数增加，近似线性递增 高容错 状态监控 适合海量数据的离线批处理 降低了分布式编程的门槛 适用场景 数据统计，如：网站的 PV、UV 统计 搜索引擎构建索引 海量数据查询 不适用场景 OLAP 要求毫秒或秒级返回结果 流计算 流计算的输入数据集是动态的，而 MapReduce 是静态的 DAG 计算 多个作业存在依赖关系，后一个的输入是前一个的输出，构成有向无环图 DAG 每个 MapReduce 作业的输出结果都会落盘，造成大量磁盘 IO，导致性能非常低下 MapReduce 原理 Job &amp; Task（作业与任务） 作业是客户端请求执行的一个工作单元 包括输入数据、MapReduce 程序、配置信息 任务是将作业分解后得到的细分工作单元 分为 Map 任务和 Reduce 任务 Split（切片） 输入数据被划分成等长的小数据块，称为输入切片（Input Split），简称切片 Split 是逻辑概念，仅包含元数据信息，如：数据的起始位置、长度、所在节点等 每个 Split 交给一个 Map 任务处理，Split 的数量决定 Map 任务的数量 Split 的划分方式由程序设定，Split 与 HDFS Block 没有严格的对应关系 Split 的大小默认等于 Block 大小 Split 越小，负载越均衡，但集群的开销越大 Map 阶段（映射） 由若干 Map 任务组成，任务数量由 Split 数量决定 输入：Split 切片（key-value），输出：中间计算结果（key-value） Reduce 阶段（化简） 由若干 Reduce 任务组成，任务数量由程序指定 输入：Map 阶段输出的中间结果（key-value），输出：最终结果（key-value） Shuffle 阶段（洗牌） Map、Reduce 阶段的中间环节，负责执行 Partition（分区）、Sort（排序）、Spill（溢写）、Merge（合并）、抓取（Fetch）等工作 Partition 决定了 Map 任务输出的每条数据放入哪个分区，交给哪个 Reduce 任务处理 Reduce 任务的数量决定了 Partition 数量 Partition 编号 = Reduce 任务编号 =“key hashcode % reduce task number” 避免和减少 Shuffle 是 MapReduce 程序调优的重点 Shuffle 详解 Map 端 Map 任务将中间结果写入专用内存缓冲区 Buffer（默认 100M），同时进行 Partition 和 Sort（先按“key hashcode % reduce task number”对数据进行分区，分区内再按 key 排序） 当 Buffer 的数据量达到阈值（默认 80%）时，将数据溢写（Spill）到磁盘的一个临时文件中，文件内数据先分区后排序 Map 任务结束前，将多个临时文件合并（Merge）为一个 Map 输出文件，文件内数据先分区后排序 Reduce 端 Reduce 任务从多个 Map 输出文件中主动抓取（Fetch）属于自己的分区数据，先写入 Buffer，数据量达到阈值后，溢写到磁盘的一个临时文件中 数据抓取完成后，将多个临时文件合并为一个 Reduce 输入文件，文件内数据按 key 排序 作业运行模式 JobTracker/TaskTracker 模式（Hadoop 1.X） JobTracker 节点（Master） 调度任务在 TaskTracker 上运行 若任务失败，指定新 TaskTracker 重新运行 TaskTracker 节点（Slave） 执行任务，发送进度报告 存在的问题 JobTracker 存在单点故障 JobTracker 负载太重（上限 4000 节点） JobTracker 缺少对资源的全面管理 TaskTracker 对资源的描述过于简单 源码很难理解 YARN 模式（Hadoop 2.X） 提交作业 查看作业 终止作业]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>bigdata</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YARN]]></title>
    <url>%2Fblog%2F2018%2F09%2F03%2Fbigdata%2FYARN%2F</url>
    <content type="text"><![CDATA[YARN YARN 的目标是解决 MapReduce 的缺陷。 MapReduce 的缺陷（Hadoop 1.x） YARN 简介 YARN 系统架构 ResourceManager（RM） NodeManager（NM） ApplicationMaster（AM） Container YARN 高可用 YARN 资源调度策略 FIFO Scheduler（先进先出调度器） Capacity Scheduler（容量调度器） Fair Scheduler（公平调度器） 资源 MapReduce 的缺陷（Hadoop 1.x） 身兼两职：计算框架 + 资源管理框架 JobTracker 既做资源管理，又做任务调度 任务太重，开销过大 存在单点故障 资源描述模型过于简单，资源利用率较低 仅把 Task 数量看作资源，没有考虑 CPU 和内存 强制把资源分成 Map Task Slot 和 Reduce Task Slot 扩展性较差，集群规模上限 4K 源码难于理解，升级维护困难 YARN 简介 YARN(Yet Another Resource Negotiator，另一种资源管理器)是一个分布式通用资源管理系统。 设计目标：聚焦资源管理、通用（适用各种计算框架）、高可用、高扩展。 YARN 系统架构 主从结构（master/slave） 将 JobTracker 的资源管理、任务调度功能分离 三种角色： ResourceManager（Master） - 集群资源的统一管理和分配 NodeManager（Slave） - 管理节点资源，以及容器的生命周期 ApplicationMaster（新角色） - 管理应用程序实例，包括任务调度和资源申请 ResourceManager（RM） 主要功能 统一管理集群的所有资源 将资源按照一定策略分配给各个应用（ApplicationMaster） 接收 NodeManager 的资源上报信息 核心组件 用户交互服务（User Service） NodeManager 管理 ApplicationMaster 管理 Application 管理 安全管理 资源管理 NodeManager（NM） 主要功能 管理单个节点的资源 向 ResourceManager 汇报节点资源使用情况 管理 Container 的生命周期 核心组件 NodeStatusUpdater ContainerManager ContainerExecutor NodeHealthCheckerService Security WebServer ApplicationMaster（AM） 主要功能 管理应用程序实例 向 ResourceManager 申请任务执行所需的资源 任务调度和监管 实现方式 需要为每个应用开发一个 AM 组件 YARN 提供 MapReduce 的 ApplicationMaster 实现 采用基于事件驱动的异步编程模型，由中央事件调度器统一管理所有事件 每种组件都是一种事件处理器，在中央事件调度器中注册 Container 概念：Container 封装了节点上进程的相关资源，是 YARN 中资源的抽象 分类：运行 ApplicationMaster 的 Container 、运行应用任务的 Container YARN 高可用 ResourceManager 高可用 1 个 Active RM、多个 Standby RM 宕机后自动实现主备切换 ZooKeeper 的核心作用 Active 节点选举 恢复 Active RM 的原有状态信息 重启 AM，杀死所有运行中的 Container 切换方式：手动、自动 YARN 资源调度策略 FIFO Scheduler（先进先出调度器） 调度策略 将所有任务放入一个队列，先进队列的先获得资源，排在后面的任务只有等待 缺点 资源利用率低，无法交叉运行任务 灵活性差，如：紧急任务无法插队，耗时长的任务拖慢耗时短的任务 Capacity Scheduler（容量调度器） 核心思想 - 提前做预算，在预算指导下分享集群资源。 调度策略 集群资源由多个队列分享 每个队列都要预设资源分配的比例（提前做预算） 空闲资源优先分配给“实际资源/预算资源”比值最低的队列 队列内部采用 FIFO 调度策略 特点 层次化的队列设计：子队列可使用父队列资源 容量保证：每个队列都要预设资源占比，防止资源独占 弹性分配：空闲资源可以分配给任何队列，当多个队列争用时，会按比例进行平衡 支持动态管理：可以动态调整队列的容量、权限等参数，也可动态增加、暂停队列 访问控制：用户只能向自己的队列中提交任务，不能访问其他队列 多租户：多用户共享集群资源 Fair Scheduler（公平调度器） 调度策略 多队列公平共享集群资源 通过平分的方式，动态分配资源，无需预先设定资源分配比例 队列内部可配置调度策略：FIFO、Fair（默认） 资源抢占 终止其他队列的任务，使其让出所占资源，然后将资源分配给占用资源量少于最小资源量限制的队列 队列权重 当队列中有任务等待，并且集群中有空闲资源时，每个队列可以根据权重获得不同比例的空闲资源 资源]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>bigdata</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据简介]]></title>
    <url>%2Fblog%2F2018%2F09%2F03%2Fbigdata%2Foverview%2F</url>
    <content type="text"><![CDATA[大数据简介 简介 什么是大数据 应用场景 Hadoop 编年史 技术体系 HDFS MapReduce Spark YARN Hive HBase ElasticSearch 术语 资源 简介 什么是大数据 大数据是指超出传统数据库工具收集、存储、管理和分析能力的数据集。与此同时，及时采集、存储、聚合、管理数据，以及对数据深度分析的新技术和新能力，正在快速增长，就像预测计算芯片增长速度的摩尔定律一样。 Volume - 数据规模巨大 Velocity - 生成和处理速度极快 Variety - 数据规模巨大 Value - 生成和处理速度极快 应用场景 基于大数据的数据仓库 基于大数据的实时流处理 Hadoop 编年史 时间 事件 2003.01 Google发表了Google File System论文 2004.01 Google发表了MapReduce论文 2006.02 Apache Hadoop项目正式启动，并支持MapReduce和HDFS独立发展 2006.11 Google发表了Bigtable论文 2008.01 Hadoop成为Apache顶级项目 2009.03 Cloudera推出世界上首个Hadoop发行版——CDH，并完全开放源码 2012.03 HDFS NameNode HA加入Hadoop主版本 2014.02 Spark代替MapReduce成为Hadoop的缺省计算引擎，并成为Apache顶级项目 技术体系 HDFS 概念 Hadoop 分布式文件系统（Hadoop Distributed File System） 在开源大数据技术体系中，地位无可替代 特点 高容错：数据多副本，副本丢失后自动恢复 高可用：NameNode HA，安全模式 高扩展：10K 节点规模 简单一致性模型：一次写入多次读取，支持追加，不允许修改 流式数据访问：批量读而非随机读，关注吞吐量而非时间 大规模数据集：典型文件大小 GB~TB 级，百万以上文件数量， PB 以上数据规模 构建成本低且安全可靠：运行在大量的廉价商用机器上，硬件错误是常态，提供容错机制 MapReduce 概念 面向批处理的分布式计算框架 编程模型：将 MapReduce 程序分为 Map、Reduce 两个阶段 核心思想 分而治之，分布式计算 移动计算，而非移动数据 特点 高容错：任务失败，自动调度到其他节点重新执行 高扩展：计算能力随着节点数增加，近似线性递增 适用于海量数据的离线批处理 降低了分布式编程的门槛 Spark 高性能分布式通用计算引擎 Spark Core - 基础计算框架（批处理、交互式分析） Spark SQL - SQL 引擎（海量结构化数据的高性能查询） Spark Streaming - 实时流处理（微批） Spark MLlib - 机器学习 Spark GraphX - 图计算 采用 Scala 语言开发 特点 计算高效 - 内存计算、Cache 缓存机制、DAG 引擎、多线程池模型 通用易用 - 适用于批处理、交互式计算、流处理、机器学习、图计算等多种场景 运行模式多样 - Local、Standalone、YARN/Mesos YARN 概念 Yet Another Resource Negotiator，另一种资源管理器 为了解决 Hadoop 1.x 中 MapReduce 的先天缺陷 分布式通用资源管理系统 负责集群资源的统一管理 从 Hadoop 2.x 开始，YARN 成为 Hadoop 的核心组件 特点 专注于资源管理和作业调度 通用 - 适用各种计算框架，如 - MapReduce、Spark 高可用 - ResourceManager 高可用、HDFS 高可用 高扩展 Hive 概念 Hadoop 数据仓库 - 企业决策支持 SQL 引擎 - 对海量结构化数据进行高性能的 SQL 查询 采用 HDFS 或 HBase 为数据存储 采用 MapReduce 或 Spark 为计算框架 特点 提供类 SQL 查询语言 支持命令行或 JDBC/ODBC 提供灵活的扩展性 提供复杂数据类型、扩展函数、脚本等 HBase 概念 Hadoop Database Google BigTable 的开源实现 分布式 NoSQL 数据库 列式存储 - 主要用于半结构化、非结构化数据 采用 HDFS 为文件存储系统 特点 高性能 - 支持高并发写入和查询 高可用 - HDFS 高可用、Region 高可用 高扩展 - 数据自动切分和分布，可动态扩容，无需停机 海量存储 - 单表可容纳数十亿行，上百万列 ElasticSearch 开源的分布式全文检索引擎 基于 Lucene 实现全文数据的快速存储、搜索和分析 处理大规模数据 - PB 级以上 具有较强的扩展性，集群规模可达上百台 首选的分布式搜索引擎 术语 数据仓库（Data Warehouse） - 数据仓库，是为企业所有级别的决策制定过程，提供所有类型数据支持的战略集合。它是单个数据存储，出于分析性报告和决策支持目的而创建。 为需要业务智能的企业，提供指导业务流程改进、监视时间、成本、质量以及控制。 资源 awesome-bigdata Hadoop HBase Hive Impala Flume Kafka Spark Sqoop ElasticSearch]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>bigdata</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式技术面试题]]></title>
    <url>%2Fblog%2F2018%2F07%2F10%2Fdesign%2Fdistributed%2Fdistributed-interview%2F</url>
    <content type="text"><![CDATA[分布式技术面试题 1. 分布式缓存 1.1. Redis 有什么数据类型？分别用于什么场景？ 1.2. Redis 的主从复制是如何实现的？ 1.3. Redis 的 key 是如何寻址的？ 1.4. Redis 的集群模式是如何实现的？ 1.5. Redis 如何实现分布式锁？ZooKeeper 如何实现分布式锁？比较二者优劣？ 1.6. Redis 的持久化方式？有什么优缺点？持久化实现原理？ 1.7. Redis 过期策略有哪些？ 1.8. Redis 和 Memcached 有什么区别？ 1.9. 为什么单线程的 Redis 性能反而优于多线程的 Memcached？ 2. 分布式消息队列（MQ） 2.1. 为什么使用 MQ？ 2.2. 如何保证 MQ 的高可用？ 2.3. MQ 有哪些常见问题？如何解决这些问题？ 2.4. Kafka, ActiveMQ, RabbitMQ, RocketMQ 各有什么优缺点？ 3. 分布式服务（RPC） 3.1. Dubbo 的实现过程？ 3.2. Dubbo 负载均衡策略有哪些？ 3.3. Dubbo 集群容错策略 ？ 3.4. 动态代理策略？ 3.5. Dubbo 支持哪些序列化协议？Hessian？Hessian 的数据结构？ 3.6. Protoco Buffer 是什么？ 3.7. 注册中心挂了可以继续通信吗？ 3.8. ZooKeeper 原理是什么？ZooKeeper 有什么用？ 3.9. Netty 有什么用？NIO/BIO/AIO 有什么用？有什么区别？ 3.10. 为什么要进行系统拆分？拆分不用 Dubbo 可以吗？ 3.11. Dubbo 和 Thrift 有什么区别？ 1. 分布式缓存 1.1. Redis 有什么数据类型？分别用于什么场景？ 数据类型 可以存储的值 操作 STRING 字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作 LIST 列表 从两端压入或者弹出元素 读取单个或者多个元素 进行修剪，只保留一个范围内的元素 SET 无序集合 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 HASH 包含键值对的无序散列表 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 ZSET 有序集合 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 What Redis data structures look like 1.2. Redis 的主从复制是如何实现的？ 从服务器连接主服务器，发送 SYNC 命令； 主服务器接收到 SYNC 命名后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令； 主服务器 BGSAVE 执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； 1.3. Redis 的 key 是如何寻址的？ 背景 （1）redis 中的每一个数据库，都由一个 redisDb 的结构存储。其中： redisDb.id 存储着 redis 数据库以整数表示的号码。 redisDb.dict 存储着该库所有的键值对数据。 redisDb.expires 保存着每一个键的过期时间。 （2）当 redis 服务器初始化时，会预先分配 16 个数据库（该数量可以通过配置文件配置），所有数据库保存到结构 redisServer 的一个成员 redisServer.db 数组中。当我们选择数据库 select number 时，程序直接通过 redisServer.db[number] 来切换数据库。有时候当程序需要知道自己是在哪个数据库时，直接读取 redisDb.id 即可。 （3）redis 的字典使用哈希表作为其底层实现。dict 类型使用的两个指向哈希表的指针，其中 0 号哈希表（ht[0]）主要用于存储数据库的所有键值，而 1 号哈希表主要用于程序对 0 号哈希表进行 rehash 时使用，rehash 一般是在添加新值时会触发，这里不做过多的赘述。所以 redis 中查找一个 key，其实就是对进行该 dict 结构中的 ht[0] 进行查找操作。 （4）既然是哈希，那么我们知道就会有哈希碰撞，那么当多个键哈希之后为同一个值怎么办呢？redis 采取链表的方式来存储多个哈希碰撞的键。也就是说，当根据 key 的哈希值找到该列表后，如果列表的长度大于 1，那么我们需要遍历该链表来找到我们所查找的 key。当然，一般情况下链表长度都为是 1，所以时间复杂度可看作 o(1)。 寻址 key 的步骤 当拿到一个 key 后，redis 先判断当前库的 0 号哈希表是否为空，即：if (dict-&gt;ht[0].size == 0)。如果为 true 直接返回 NULL。 判断该 0 号哈希表是否需要 rehash，因为如果在进行 rehash，那么两个表中者有可能存储该 key。如果正在进行 rehash，将调用一次_dictRehashStep 方法，_dictRehashStep 用于对数据库字典、以及哈希键的字典进行被动 rehash，这里不作赘述。 计算哈希表，根据当前字典与 key 进行哈希值的计算。 根据哈希值与当前字典计算哈希表的索引值。 根据索引值在哈希表中取出链表，遍历该链表找到 key 的位置。一般情况，该链表长度为 1。 当 ht[0] 查找完了之后，再进行了次 rehash 判断，如果未在 rehashing，则直接结束，否则对 ht[1]重复 345 步骤。 1.4. Redis 的集群模式是如何实现的？ Redis Cluster 是 Redis 的分布式解决方案，在 Redis 3.0 版本正式推出的。 Redis Cluster 去中心化，每个节点保存数据和整个集群状态，每个节点都和其他所有节点连接。 Redis Cluster 节点分配 Redis Cluster 特点： 所有的 redis 节点彼此互联(PING-PONG 机制)，内部使用二进制协议优化传输速度和带宽。 节点的 fail 是通过集群中超过半数的节点检测失效时才生效。 客户端与 redis 节点直连,不需要中间 proxy 层。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。 redis-cluster 把所有的物理节点映射到[0-16383] 哈希槽 (hash slot)上（不一定是平均分配）,cluster 负责维护 node&lt;-&gt;slot&lt;-&gt;value。 Redis 集群预分好 16384 个桶，当需要在 Redis 集群中放置一个 key-value 时，根据 CRC16(key) mod 16384 的值，决定将一个 key 放到哪个桶中。 Redis Cluster 主从模式 Redis Cluster 为了保证数据的高可用性，加入了主从模式。 一个主节点对应一个或多个从节点，主节点提供数据存取，从节点则是从主节点拉取数据备份。当这个主节点挂掉后，就会有这个从节点选取一个来充当主节点，从而保证集群不会挂掉。所以，在集群建立的时候，一定要为每个主节点都添加了从节点。 Redis Sentinel Redis Sentinel 用于管理多个 Redis 服务器，它有三个功能： 监控（Monitoring） - Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。 提醒（Notification） - 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。 自动故障迁移（Automatic failover） - 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效主服务器的其中一个从服务器升级为新的主服务器， 并让失效主服务器的其他从服务器改为复制新的主服务器； 当客户端试图连接失效的主服务器时， 集群也会向客户端返回新主服务器的地址， 使得集群可以使用新主服务器代替失效服务器。 Redis 集群中应该有奇数个节点，所以至少有三个节点。 哨兵监控集群中的主服务器出现故障时，需要根据 quorum 选举出一个哨兵来执行故障转移。选举需要 majority，即大多数哨兵是运行的（2 个哨兵的 majority=2，3 个哨兵的 majority=2，5 个哨兵的 majority=3，4 个哨兵的 majority=2）。 假设集群仅仅部署 2 个节点 +----+ +----+| M1 |---------| R1 || S1 | | S2 |+----+ +----+ 如果 M1 和 S1 所在服务器宕机，则哨兵只有 1 个，无法满足 majority 来进行选举，就不能执行故障转移。 1.5. Redis 如何实现分布式锁？ZooKeeper 如何实现分布式锁？比较二者优劣？ 分布式锁的三种实现： 基于数据库实现分布式锁； 基于缓存（Redis 等）实现分布式锁； 基于 Zookeeper 实现分布式锁； 数据库实现 Redis 实现 获取锁的时候，使用 setnx 加锁，并使用 expire 命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的 value 值为一个随机生成的 UUID，通过此在释放锁的时候进行判断。 获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。 释放锁的时候，通过 UUID 判断是不是该锁，若是该锁，则执行 delete 进行锁释放。 ZooKeeper 实现 创建一个目录 mylock； 线程 A 想获取锁就在 mylock 目录下创建临时顺序节点； 获取 mylock 目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁； 线程 B 获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点； 线程 A 处理完，删除自己的节点，线程 B 监听到变更事件，判断自己是不是最小的节点，如果是则获得锁。 实现对比 ZooKeeper 具备高可用、可重入、阻塞锁特性，可解决失效死锁问题。 但 ZooKeeper 因为需要频繁的创建和删除节点，性能上不如 Redis 方式。 1.6. Redis 的持久化方式？有什么优缺点？持久化实现原理？ RDB 快照（snapshot） 将存在于某一时刻的所有数据都写入到硬盘中。 快照的原理 在默认情况下，Redis 将数据库快照保存在名字为 dump.rdb 的二进制文件中。你可以对 Redis 进行设置， 让它在“N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据集。你也可以通过调用 SAVE 或者 BGSAVE，手动让 Redis 进行数据集保存操作。这种持久化方式被称为快照。 当 Redis 需要保存 dump.rdb 文件时， 服务器执行以下操作: Redis 创建一个子进程。 子进程将数据集写入到一个临时快照文件中。 当子进程完成对新快照文件的写入时，Redis 用新快照文件替换原来的快照文件，并删除旧的快照文件。 这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益。 快照的优点 它保存了某个时间点的数据集，非常适用于数据集的备份。 很方便传送到另一个远端数据中心或者亚马逊的 S3（可能加密），非常适用于灾难恢复。 快照在保存 RDB 文件时父进程唯一需要做的就是 fork 出一个子进程，接下来的工作全部由子进程来做，父进程不需要再做其他 IO 操作，所以快照持久化方式可以最大化 redis 的性能。 与 AOF 相比，在恢复大的数据集的时候，DB 方式会更快一些。 快照的缺点 如果你希望在 redis 意外停止工作（例如电源中断）的情况下丢失的数据最少的话，那么快照不适合你。 快照需要经常 fork 子进程来保存数据集到硬盘上。当数据集比较大的时候，fork 的过程是非常耗时的，可能会导致 Redis 在一些毫秒级内不能响应客户端的请求。 AOF AOF 持久化方式记录每次对服务器执行的写操作。当服务器重启的时候会重新执行这些命令来恢复原始的数据。 AOF 的原理 Redis 创建一个子进程。 子进程开始将新 AOF 文件的内容写入到临时文件。 对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾，这样样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。 当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。 搞定！现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。 AOF 的优点 使用默认的每秒 fsync 策略，Redis 的性能依然很好(fsync 是由后台线程进行处理的,主线程会尽力处理客户端请求)，一旦出现故障，使用 AOF ，你最多丢失 1 秒的数据。 AOF 文件是一个只进行追加的日志文件，所以不需要写入 seek，即使由于某些原因(磁盘空间已满，写的过程中宕机等等)未执行完整的写入命令，你也也可使用 redis-check-aof 工具修复这些问题。 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写：重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。整个重写操作是绝对安全的。 AOF 文件有序地保存了对数据库执行的所有写入操作，这些写入操作以 Redis 协议的格式保存。因此 AOF 文件的内容非常容易被人读懂，对文件进行分析（parse）也很轻松。 AOF 的缺点 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。 根据所使用的 fsync 策略，AOF 的速度可能会慢于快照。在一般情况下，每秒 fsync 的性能依然非常高，而关闭 fsync 可以让 AOF 的速度和快照一样快，即使在高负荷之下也是如此。不过在处理巨大的写入载入时，快照可以提供更有保证的最大延迟时间（latency）。 1.7. Redis 过期策略有哪些？ noeviction - 当内存使用达到阈值的时候，所有引起申请内存的命令会报错。 allkeys-lru - 在主键空间中，优先移除最近未使用的 key。 allkeys-random - 在主键空间中，随机移除某个 key。 volatile-lru - 在设置了过期时间的键空间中，优先移除最近未使用的 key。 volatile-random - 在设置了过期时间的键空间中，随机移除某个 key。 volatile-ttl - 在设置了过期时间的键空间中，具有更早过期时间的 key 优先移除。 1.8. Redis 和 Memcached 有什么区别？ 两者都是非关系型内存键值数据库。有以下主要不同： 数据类型 Memcached 仅支持字符串类型； 而 Redis 支持五种不同种类的数据类型，使得它可以更灵活地解决问题。 数据持久化 Memcached 不支持持久化； Redis 支持两种持久化策略：RDB 快照和 AOF 日志。 分布式 Memcached 不支持分布式，只能通过在客户端使用像一致性哈希这样的分布式算法来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。 Redis Cluster 实现了分布式的支持。 内存管理机制 Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题，但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘。而 Memcached 的数据则会一直在内存中。 1.9. 为什么单线程的 Redis 性能反而优于多线程的 Memcached？ Redis 快速的原因： 绝大部分请求是纯粹的内存操作（非常快速） 采用单线程,避免了不必要的上下文切换和竞争条件 非阻塞 IO 内部实现采用 epoll，采用了 epoll+自己实现的简单的事件框架。epoll 中的读、写、关闭、连接都转化成了事件，然后利用 epoll 的多路复用特性，绝不在 io 上浪费一点时间。 2. 分布式消息队列（MQ） 2.1. 为什么使用 MQ？ 异步处理 - 相比于传统的串行、并行方式，提高了系统吞吐量。 应用解耦 - 系统间通过消息通信，不用关心其他系统的处理。 流量削锋 - 可以通过消息队列长度控制请求量；可以缓解短时间内的高并发请求。 日志处理 - 解决大量日志传输。 消息通讯 - 消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。 2.2. 如何保证 MQ 的高可用？ 数据复制 将所有 Broker 和待分配的 Partition 排序 将第 i 个 Partition 分配到第（i mod n）个 Broker 上 将第 i 个 Partition 的第 j 个 Replica 分配到第（(i + j) mode n）个 Broker 上 选举主服务器 2.3. MQ 有哪些常见问题？如何解决这些问题？ MQ 的常见问题有： 消息的顺序问题 消息的重复问题 消息的顺序问题 消息有序指的是可以按照消息的发送顺序来消费。 假如生产者产生了 2 条消息：M1、M2，假定 M1 发送到 S1，M2 发送到 S2，如果要保证 M1 先于 M2 被消费，怎么做？ 解决方案： （1）保证生产者 - MQServer - 消费者是一对一对一的关系 缺陷： 并行度就会成为消息系统的瓶颈（吞吐量不够） 更多的异常处理，比如：只要消费端出现问题，就会导致整个处理流程阻塞，我们不得不花费更多的精力来解决阻塞的问题。 （2）通过合理的设计或者将问题分解来规避。 不关注乱序的应用实际大量存在 队列无序并不意味着消息无序 所以从业务层面来保证消息的顺序而不仅仅是依赖于消息系统，是一种更合理的方式。 消息的重复问题 造成消息重复的根本原因是：网络不可达。 所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？ 消费端处理消息的业务逻辑保持幂等性。只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。 保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现。利用一张日志表来记录已经处理成功的消息的 ID，如果新到的消息 ID 已经在日志表中，那么就不再处理这条消息。 2.4. Kafka, ActiveMQ, RabbitMQ, RocketMQ 各有什么优缺点？ 3. 分布式服务（RPC） 3.1. Dubbo 的实现过程？ 节点角色： 节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 服务运行容器 调用关系： 务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 3.2. Dubbo 负载均衡策略有哪些？ Random 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin 轮循，按公约后的权重设置轮循比率。 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActive 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash 一致性 Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 算法参见：http://en.wikipedia.org/wiki/Consistent_hashing 缺省只对第一个参数 Hash，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.arguments&quot; value=&quot;0,1&quot; /&gt; 缺省用 160 份虚拟节点，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.nodes&quot; value=&quot;320&quot; /&gt; 3.3. Dubbo 集群容错策略 ？ Failover - 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=“2” 来设置重试次数(不含第一次)。 Failfast - 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe - 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback - 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking - 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=“2” 来设置最大并行数。 Broadcast - 播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。 3.4. 动态代理策略？ Dubbo 作为 RPC 框架，首先要完成的就是跨系统，跨网络的服务调用。消费方与提供方遵循统一的接口定义，消费方调用接口时，Dubbo 将其转换成统一格式的数据结构，通过网络传输，提供方根据规则找到接口实现，通过反射完成调用。也就是说，消费方获取的是对远程服务的一个代理(Proxy)，而提供方因为要支持不同的接口实现，需要一个包装层(Wrapper)。调用的过程大概是这样： 消费方的 Proxy 和提供方的 Wrapper 得以让 Dubbo 构建出复杂、统一的体系。而这种动态代理与包装也是通过基于 SPI 的插件方式实现的，它的接口就是ProxyFactory。 @SPI("javassist")public interface ProxyFactory &#123; @Adaptive(&#123;Constants.PROXY_KEY&#125;) &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException; @Adaptive(&#123;Constants.PROXY_KEY&#125;) &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) throws RpcException;&#125; ProxyFactory 有两种实现方式，一种是基于 JDK 的代理实现，一种是基于 javassist 的实现。ProxyFactory 接口上定义了@SPI(“javassist”)，默认为 javassist 的实现。 3.5. Dubbo 支持哪些序列化协议？Hessian？Hessian 的数据结构？ dubbo 序列化，阿里尚不成熟的 java 序列化实现。 hessian2 序列化：hessian 是一种跨语言的高效二进制的序列化方式，但这里实际不是原生的 hessian2 序列化，而是阿里修改过的 hessian lite，它是 dubbo RPC 默认启用的序列化方式。 json 序列化：目前有两种实现，一种是采用的阿里的 fastjson 库，另一种是采用 dubbo 中自已实现的简单 json 库，一般情况下，json 这种文本序列化性能不如二进制序列化。 java 序列化：主要是采用 JDK 自带的 java 序列化实现，性能很不理想。 Kryo 和 FST：Kryo 和 FST 的性能依然普遍优于 hessian 和 dubbo 序列化。 Hessian 序列化与 Java 默认的序列化区别？ Hessian 是一个轻量级的 remoting on http 工具，采用的是 Binary RPC 协议，所以它很适合于发送二进制数据，同时又具有防火墙穿透能力。 Hessian 支持跨语言串行 比 java 序列化具有更好的性能和易用性 支持的语言比较多 3.6. Protoco Buffer 是什么？ Protocol Buffer 是 Google 出品的一种轻量 &amp; 高效的结构化数据存储格式，性能比 Json、XML 真的强！太！多！ Protocol Buffer 的序列化 &amp; 反序列化简单 &amp; 速度快的原因是： 编码 / 解码 方式简单（只需要简单的数学运算 = 位移等等） 采用 Protocol Buffer 自身的框架代码 和 编译器 共同完成 Protocol Buffer 的数据压缩效果好（即序列化后的数据量体积小）的原因是： 采用了独特的编码方式，如 Varint、Zigzag 编码方式等等 采用 T - L - V 的数据存储方式：减少了分隔符的使用 &amp; 数据存储得紧凑 3.7. 注册中心挂了可以继续通信吗？ 可以。Dubbo 消费者在应用启动时会从注册中心拉取已注册的生产者的地址接口，并缓存在本地。每次调用时，按照本地存储的地址进行调用。 3.8. ZooKeeper 原理是什么？ZooKeeper 有什么用？ ZooKeeper 是一个分布式应用协调系统，已经用到了许多分布式项目中，用来完成统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等工作。 每个 Server 在内存中存储了一份数据； Zookeeper 启动时，将从实例中选举一个 leader（Paxos 协议）； Leader 负责处理数据更新等操作（Zab 协议）； 一个更新操作成功，当且仅当大多数 Server 在内存中成功修改数据。 3.9. Netty 有什么用？NIO/BIO/AIO 有什么用？有什么区别？ Netty 是一个“网络通讯框架”。 Netty 进行事件处理的流程。Channel是连接的通道，是 ChannelEvent 的产生者，而ChannelPipeline可以理解为 ChannelHandler 的集合。 参考：https://github.com/code4craft/netty-learning/blob/master/posts/ch1-overview.md IO 的方式通常分为几种： 同步阻塞的 BIO 同步非阻塞的 NIO 异步非阻塞的 AIO 在使用同步 I/O 的网络应用中，如果要同时处理多个客户端请求，或是在客户端要同时和多个服务器进行通讯，就必须使用多线程来处理。 NIO 基于 Reactor，当 socket 有流可读或可写入 socket 时，操作系统会相应的通知引用程序进行处理，应用再将流读取到缓冲区或写入操作系统。也就是说，这个时候，已经不是一个连接就要对应一个处理线程了，而是有效的请求，对应一个线程，当连接没有数据时，是没有工作线程来处理的。 与 NIO 不同，当进行读写操作时，只须直接调用 API 的 read 或 write 方法即可。这两种方法均为异步的，对于读操作而言，当有流可读取时，操作系统会将可读的流传入 read 方法的缓冲区，并通知应用程序；对于写操作而言，当操作系统将 write 方法传递的流写入完毕时，操作系统主动通知应用程序。 即可以理解为，read/write 方法都是异步的，完成后会主动调用回调函数。 参考：https://blog.csdn.net/skiof007/article/details/52873421 3.10. 为什么要进行系统拆分？拆分不用 Dubbo 可以吗？ 系统拆分从资源角度分为：应用拆分和数据库拆分。 从采用的先后顺序可分为：水平扩展、垂直拆分、业务拆分、水平拆分。 是否使用服务依据实际业务场景来决定。 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。 当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键。 3.11. Dubbo 和 Thrift 有什么区别？ Thrift 是跨语言的 RPC 框架。 Dubbo 支持服务治理，而 Thrift 不支持。]]></content>
      <categories>
        <category>design</category>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式基本原理]]></title>
    <url>%2Fblog%2F2018%2F07%2F09%2Fdesign%2Fdistributed%2Fdistributed-base%2F</url>
    <content type="text"><![CDATA[分布式基本原理 简介 性能 常见的性能指标： 吞吐量(Throughput) - 是指系统在单位时间内处理请求的数量。 响应时间(Response Time, RT) - 是指系统对请求作出响应的时间。 并发用户数 - 是指系统可以同时承载的正常工作的在线用户数。 每秒查询率（QPS） - 是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。对应 fetches/sec，即每秒的响应请求数，也即是最大吞吐能力。 每秒事务数（Transaction Per Second, TPS） - 衡量系统处理事务或交易的能力，即服务器对客户请求的能力，每秒处理的事务数，一般在 LoadRunner 上使用，设置事务，然后统计单位时间内系统可以成功完成多少个定义的事务。 点击量（Hits Per Second） - 服务器每秒收到的 HTTP 请求数。 QPS = 并发量 / 平均响应时间 吞吐量和响应时间这两个指标往往是矛盾的，追求高吞吐的系统，往往很难做到低响应时间，解释如下： 在无并发的系统中，吞吐量为响应时间的倒数，例如响应时间为 10 ms，那么吞吐量为 100 req/s，因此高吞吐也就意味着低响应时间。 但是在并发的系统中，由于一个请求在调用 I/O 资源的时候，需要进行等待。服务器端一般使用的是异步等待方式，即等待的请求被阻塞之后不需要一直占用 CPU 资源。这种方式能大大提高 CPU 资源的利用率，例如上面的例子中，单个请求在无并发的系统中响应时间为 10 ms，如果在并发的系统中，那么吞吐量将大于 100 req/s。因此为了追求高吞吐量，通常会提高并发程度。但是并发程度的增加，会导致请求的平均响应时间也增加，因为请求不能马上被处理，需要和其它请求一起进行并发处理，响应时间自然就会增高。 可用性 可用性指系统在面对各种异常时可以提供正常服务的能力。可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。 重要术语： 异常 服务器宕机 - 内存错误、服务器停电等都会导致服务器宕机，此时节点无法正常工作，称为不可用。服务器宕机会导致节点失去所有内存信息，因此需要将内存信息保存到持久化介质上。 网络异常 - 有一种特殊的网络异常称为——网络分区 ，即集群的所有节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。 磁盘故障 - 磁盘故障是一种发生概率很高的异常。使用冗余机制，将数据存储到多台服务器。 超时 - 在分布式系统中，一个请求除了成功和失败两种状态，还存在着超时状态。可以将服务器的操作设计为具有 幂等性 ，即执行多次的结果与执行一次的结果相同。如果使用这种方式，当出现超时的时候，可以不断地重新请求直到成功。 一致性 可以从两个角度理解一致性：从客户端的角度，读写操作是否满足某种特性；从服务器的角度，多个数据副本之间是否一致。 可扩展性 指系统通过扩展集群服务器规模来提高性能的能力。理想的分布式系统需要实现“线性可扩展”，即随着集群规模的增加，系统的整体性能也会线性增加。 数据分布 分布式存储系统的数据分布在多个节点中，常用的数据分布方式有哈希分布和顺序分布。 数据库的水平切分（Sharding）也是一种分布式存储方法，下面的数据分布方法同样适用于 Sharding。 哈希分布 哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。例如有 N 个节点，数据的主键为 key，则将该数据分配的节点序号为：hash(key)%N。 传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。 一致性哈希 Distributed Hash Table（DHT）：对于哈希空间 [0, 2n-1]，将该哈希空间看成一个哈希环，将每个节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。 一致性哈希的优点是在增加或者删除节点时只会影响到哈希环中相邻的节点，例如下图中新增节点 X，只需要将数据对象 C 重新存放到节点 X 上即可，对于节点 A、B、D 都没有影响。 顺序分布 哈希分布式破坏了数据的有序性，顺序分布则不会。 顺序分布的数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。例如下图中，User 表的 ID 范围为 1 ~ 7000，使用顺序分布可以将其划分成多个子表，对应的主键范围为 1 ~ 1000，1001 ~ 2000，…，6001 ~ 7000。 顺序分布的优点是可以充分利用每个节点的空间，而哈希分布很难控制一个节点存储多少数据。 但是顺序分布需要使用一个映射表来存储数据到节点的映射，这个映射表通常使用单独的节点来存储。当数据量非常大时，映射表也随着变大，那么一个节点就可能无法存放下整个映射表。并且单个节点维护着整个映射表的开销很大，查找速度也会变慢。为了解决以上问题，引入了一个中间层，也就是 Meta 表，从而分担映射表的维护工作。 负载均衡 衡量负载的因素很多，如 CPU、内存、磁盘等资源使用情况、读写请求数等。 分布式系统存储应当能够自动负载均衡，当某个节点的负载较高，将它的部分数据迁移到其它节点。 每个集群都有一个总控节点，其它节点为工作节点，由总控节点根据全局负载信息进行整体调度，工作节点定时发送心跳包（Heartbeat）将节点负载相关的信息发送给总控节点。 一个新上线的工作节点，由于其负载较低，如果不加控制，总控节点会将大量数据同时迁移到该节点上，造成该节点一段时间内无法工作。因此负载均衡操作需要平滑进行，新加入的节点需要较长的一段时间来达到比较均衡的状态。 分布式系统理论 CAP 分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容忍性（P：Partition Tolerance），最多只能同时满足其中两项。 （一）一致性 一致性指的是多个数据副本是否能保持一致的特性。 在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。 对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。 （二）可用性 可用性指分布式系统在面对各种异常时可以提供正常服务的能力，可以用系统可用时间占总时间的比值来衡量，如：4 个 9 的可用性表示系统 99.99% 的时间是可用的。 在可用性条件下，系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。 （三）分区容忍性 网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。 在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。 （四）权衡 在分布式系统中，分区容忍性必不可少，因为需要总是假设网络是不可靠的。因此，CAP 理论实际在是要在可用性和一致性之间做权衡。 可用性和一致性往往是冲突的，很难都使它们同时满足。在多个节点之间进行数据同步时， 为了保证一致性（CP），就需要让所有节点下线成为不可用的状态，等待同步完成； 为了保证可用性（AP），在同步过程中允许读取所有节点的数据，但是数据可能不一致。 BASE BASE 是基本可用（Basically Available）、软状态（Soft State）和最终一致性（Eventually Consistent）三个短语的缩写。 BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 基本可用 - 指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。例如，电商在做促销时，为了保证购物系统的稳定性，部分消费者可能会被引导到一个降级的页面。 软状态 - 指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性。即允许系统不同节点的数据副本之间进行同步的过程存在延时。 最终一致性 - 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。 ACID 要求强一致性，通常运用在传统的数据库系统上。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在大型分布式系统中。 在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。 共识性问题 Paxos 用于达成共识性问题，即对多个节点产生的值，该算法能保证只选出唯一一个值。 主要有三类节点： 提议者（Proposer）：提议一个值； 接受者（Acceptor）：对每个提议进行投票； 告知者（Learner）：被告知投票的结果，不参与投票过程。 算法需要满足 safety 和 liveness 两方面的约束要求（实际上这两个基础属性是大部分分布式算法都该考虑的）： safety：保证决议结果是对的，无歧义的，不会出现错误情况。 决议（value）只有在被 proposers 提出的 proposal 才能被最终批准； 在一次执行实例中，只批准（chosen）一个最终决议，意味着多数接受（accept）的结果能成为决议； liveness：保证决议过程能在有限时间内完成。 决议总会产生，并且 learners 能获得被批准（chosen）的决议。 基本过程包括 proposer 提出提案，先争取大多数 acceptor 的支持，超过一半支持时，则发送结案结果给所有人进行确认。一个潜在的问题是 proposer 在此过程中出现故障，可以通过超时机制来解决。极为凑巧的情况下，每次新的一轮提案的 proposer 都恰好故障，系统则永远无法达成一致（概率很小）。 Paxos 能保证在超过 1/21/21/2 的正常节点存在时，系统能达成共识。 单个提案者+多接收者 如果系统中限定只有某个特定节点是提案者，那么一致性肯定能达成（只有一个方案，要么达成，要么失败）。提案者只要收到了来自多数接收者的投票，即可认为通过，因为系统中不存在其他的提案。 但一旦提案者故障，则系统无法工作。 多个提案者+单个接收者 限定某个节点作为接收者。这种情况下，共识也很容易达成，接收者收到多个提案，选第一个提案作为决议，拒绝掉后续的提案即可。 缺陷也是容易发生单点故障，包括接收者故障或首个提案者节点故障。 以上两种情形其实类似主从模式，虽然不那么可靠，但因为原理简单而被广泛采用。 当提案者和接收者都推广到多个的情形，会出现一些挑战。 多个提案者+多个接收者 既然限定单提案者或单接收者都会出现故障，那么就得允许出现多个提案者和多个接收者。问题一下子变得复杂了。 一种情况是同一时间片段（如一个提案周期）内只有一个提案者，这时可以退化到单提案者的情形。需要设计一种机制来保障提案者的正确产生，例如按照时间、序列、或者大家猜拳（出一个数字来比较）之类。考虑到分布式系统要处理的工作量很大，这个过程要尽量高效，满足这一条件的机制非常难设计。 另一种情况是允许同一时间片段内可以出现多个提案者。那同一个节点可能收到多份提案，怎么对他们进行区分呢？这个时候采用只接受第一个提案而拒绝后续提案的方法也不适用。很自然的，提案需要带上不同的序号。节点需要根据提案序号来判断接受哪个。比如接受其中序号较大（往往意味着是接受新提出的，因为旧提案者故障概率更大）的提案。 如何为提案分配序号呢？一种可能方案是每个节点的提案数字区间彼此隔离开，互相不冲突。为了满足递增的需求可以配合用时间戳作为前缀字段。 此外，提案者即便收到了多数接收者的投票，也不敢说就一定通过。因为在此过程中系统可能还有其它的提案。 Raft Raft 算法是 Paxos 算法的一种简化实现。 包括三种角色：leader、candidate 和 follower，其基本过程为： Leader 选举 - 每个 candidate 随机经过一定时间都会提出选举方案，最近阶段中得票最多者被选为 leader； 同步 log - leader 会找到系统中 log 最新的记录，并强制所有的 follower 来刷新到这个记录； 注：此处 log 并非是指日志消息，而是各种事件的发生记录。 单个 Candidate 的竞选 有三种节点：Follower、Candidate 和 Leader。Leader 会周期性的发送心跳包给 Follower。每个 Follower 都设置了一个随机的竞选超时时间，一般为 150ms~300ms，如果在这个时间内没有收到 Leader 的心跳包，就会变成 Candidate，进入竞选阶段。 下图表示一个分布式系统的最初阶段，此时只有 Follower，没有 Leader。Follower A 等待一个随机的竞选超时时间之后，没收到 Leader 发来的心跳包，因此进入竞选阶段。 此时 A 发送投票请求给其它所有节点。 其它节点会对请求进行回复，如果超过一半的节点回复了，那么该 Candidate 就会变成 Leader。 之后 Leader 会周期性地发送心跳包给 Follower，Follower 接收到心跳包，会重新开始计时。 多个 Candidate 竞选 如果有多个 Follower 成为 Candidate，并且所获得票数相同，那么就需要重新开始投票，例如下图中 Candidate B 和 Candidate D 都获得两票，因此需要重新开始投票。 当重新开始投票时，由于每个节点设置的随机竞选超时时间不同，因此能下一次再次出现多个 Candidate 并获得同样票数的概率很低。 同步日志 来自客户端的修改都会被传入 Leader。注意该修改还未被提交，只是写入日志中。 Leader 会把修改复制到所有 Follower。 Leader 会等待大多数的 Follower 也进行了修改，然后才将修改提交。 此时 Leader 会通知的所有 Follower 让它们也提交修改，此时所有节点的值达成一致。 参考资料 杨传辉. 大规模分布式存储系统: 原理解析与架构实战[M]. 机械工业出版社, 2013. 区块链技术指南 NEAT ALGORITHMS - PAXOS Raft: Understandable Distributed Consensus Paxos By Example]]></content>
      <categories>
        <category>design</category>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式技术实现]]></title>
    <url>%2Fblog%2F2018%2F07%2F09%2Fdesign%2Farchitecture%2F%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[分布式技术实现 1. 分布式事务 2. 分布式锁 2.1. 基于数据库实现分布式锁 2.2. 基于 Redis 实现分布式锁 2.3. 基于 ZooKeeper 实现分布式锁 3. 分布式 Session 3.1. Sticky Sessions 3.2. Session Replication 3.3. Session Server 4. 分布式存储 5. 分布式缓存 6. 分布式计算 7. 负载均衡 7.1. 算法 7.2. 实现 8. 资料 1. 分布式事务 参考：分布式原理#4-分布式事务问题 2. 分布式锁 Java 原生 API 虽然有并发锁，但并没有提供分布式锁的能力，所以针对分布式场景中的锁需要解决的方案。 分布式锁的解决方案大致有以下几种： 基于数据库实现 基于缓存（redis，memcached 等）实现 基于 Zookeeper 实现 2.1. 基于数据库实现分布式锁 实现 1. 创建表 CREATE TABLE `methodLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键', `method_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的方法名', `desc` varchar(1024) NOT NULL DEFAULT '备注信息', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成', PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁定中的方法'; 2. 获取锁 想要锁住某个方法时，执行以下 SQL： insert into methodLock(method_name,desc) values (‘method_name’,‘desc’) 因为我们对 method_name 做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。 成功插入则获取锁。 3. 释放锁 当方法执行完毕之后，想要释放锁的话，需要执行以下 Sql: delete from methodLock where method_name ='method_name' 问题 这把锁强依赖数据库的可用性。如果数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。 这把锁只能是非阻塞的，因为数据的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。 解决办法 单点问题可以用多数据库实例，同时塞 N 个表，N/2+1 个成功就任务锁定成功 写一个定时任务，隔一段时间清除一次过期的数据。 写一个 while 循环，不断的重试插入，直到成功。 在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。 小结 优点: 直接借助数据库，容易理解。 缺点: 会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。操作数据库需要一定的开销，性能问题需要考虑。 2.2. 基于 Redis 实现分布式锁 相比于用数据库来实现分布式锁，基于缓存实现的分布式锁的性能会更好一些。目前有很多成熟的分布式产品，包括 Redis、memcache、Tair 等。这里以 Redis 举例。 Redis 命令 setnx - setnx key val：当且仅当 key 不存在时，set 一个 key 为 val 的字符串，返回 1；若 key 存在，则什么都不做，返回 0。 expire - expire key timeout：为 key 设置一个超时时间，单位为 second，超过这个时间锁会自动释放，避免死锁。 delete - delete key：删除 key 实现 单点实现步骤： 获取锁的使用，使用 setnx 加锁，锁的 value 值为一个随机生成的 UUID，再使用 expire 设置一个过期值。 获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。 释放锁的时候，通过 UUID 判断是不是该锁，若是该锁，则执行 delete 进行锁释放。 问题 单点问题。如果单机 redis 挂掉了，那么程序会跟着出错。 如果转移使用 slave 节点，复制不是同步复制，会出现多个程序获取锁的情况 小结 可以考虑使用 redisson 的解决方案。 2.3. 基于 ZooKeeper 实现分布式锁 实现 这也是 ZooKeeper 客户端 curator 的分布式锁实现。 创建一个目录 mylock； 线程 A 想获取锁就在 mylock 目录下创建临时顺序节点； 获取 mylock 目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁； 线程 B 获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点； 线程 A 处理完，删除自己的节点，线程 B 监听到变更事件，判断自己是不是最小的节点，如果是则获得锁。 小结 ZooKeeper 版本的分布式锁问题相对比较来说少。 锁的占用时间限制：redis 就有占用时间限制，而 ZooKeeper 则没有，最主要的原因是 redis 目前没有办法知道已经获取锁的客户端的状态，是已经挂了呢还是正在执行耗时较长的业务逻辑。而 ZooKeeper 通过临时节点就能清晰知道，如果临时节点存在说明还在执行业务逻辑，如果临时节点不存在说明已经执行完毕释放锁或者是挂了。由此看来 redis 如果能像 ZooKeeper 一样添加一些与客户端绑定的临时键，也是一大好事。 是否单点故障：redis 本身有很多中玩法，如客户端一致性 hash，服务器端 sentinel 方案或者 cluster 方案，很难做到一种分布式锁方式能应对所有这些方案。而 ZooKeeper 只有一种玩法，多台机器的节点数据是一致的，没有 redis 的那么多的麻烦因素要考虑。 总体上来说 ZooKeeper 实现分布式锁更加的简单，可靠性更高。但 ZooKeeper 因为需要频繁的创建和删除节点，性能上不如 Redis 方式。 3. 分布式 Session 在分布式场景下，一个用户的 Session 如果只存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器上，该服务器没有用户的 Session，就可能导致用户需要重新进行登录等操作。 分布式 Session 的几种实现策略： 粘性 session 应用服务器间的 session 复制共享 基于 cache DB 缓存的 session 共享 3.1. Sticky Sessions 需要配置负载均衡器，使得一个用户的所有请求都路由到一个服务器节点上，这样就可以把用户的 Session 存放在该服务器节点中。 缺点：当服务器节点宕机时，将丢失该服务器节点上的所有 Session。 3.2. Session Replication 在服务器节点之间进行 Session 同步操作，这样的话用户可以访问任何一个服务器节点。 缺点：占用过多内存；同步过程占用网络带宽以及服务器处理器时间。 3.3. Session Server 使用一个单独的服务器存储 Session 数据，可以存在 MySQL 数据库上，也可以存在 Redis 或者 Memcached 这种内存型数据库。 缺点：需要去实现存取 Session 的代码。 4. 分布式存储 通常有两种解决方案： 数据分布：就是把数据分块存在不同的服务器上（分库分表）。 数据复制：让所有的服务器都有相同的数据，提供相当的服务。 参考：分布式原理.md#2-数据分布 5. 分布式缓存 使用缓存的好处： 提升数据读取速度 提升系统扩展能力，通过扩展缓存，提升系统承载能力 降低存储成本，Cache+DB 的方式可以承担原有需要多台 DB 才能承担的请求量，节省机器成本 根据业务场景，通常缓存有以下几种使用方式 懒汉式(读时触发)：写入 DB 后, 然后把相关的数据也写入 Cache 饥饿式(写时触发)：先查询 DB 里的数据, 然后把相关的数据写入 Cache 定期刷新：适合周期性的跑数据的任务，或者列表型的数据，而且不要求绝对实时性 缓存分类： 应用内缓存：如：EHCache 分布式缓存：如：Memached、Redis 参考：分布式原理.md#6-分布式缓存问题 6. 分布式计算 7. 负载均衡 7.1. 算法 轮询（Round Robin） 轮询算法把每个请求轮流发送到每个服务器上。下图中，一共有 6 个客户端产生了 6 个请求，这 6 个请求按 (1, 2, 3, 4, 5, 6) 的顺序发送。最后，(1, 3, 5) 的请求会被发送到服务器 1，(2, 4, 6) 的请求会被发送到服务器 2。 该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载（下图的 Server 2）。 加权轮询（Weighted Round Robbin） 加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值。例如下图中，服务器 1 被赋予的权值为 5，服务器 2 被赋予的权值为 1，那么 (1, 2, 3, 4, 5) 请求会被发送到服务器 1，(6) 请求会被发送到服务器 2。 最少连接（least Connections） 由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。例如下图中，(1, 3, 5) 请求会被发送到服务器 1，但是 (1, 3) 很快就断开连接，此时只有 (5) 请求连接服务器 1；(2, 4, 6) 请求被发送到服务器 2，只有 (2) 的连接断开。该系统继续运行时，服务器 2 会承担过大的负载。 最少连接算法就是将请求发送给当前最少连接数的服务器上。例如下图中，服务器 1 当前连接数最小，那么新到来的请求 6 就会被发送到服务器 1 上。 加权最少连接（Weighted Least Connection） 在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。 随机算法（Random） 把请求随机发送到服务器上。和轮询算法类似，该算法比较适合服务器性能差不多的场景。 源地址哈希法 (IP Hash) 源地址哈希通过对客户端 IP 哈希计算得到的一个数值，用该数值对服务器数量进行取模运算，取模结果便是目标服务器的序号。 优点：保证同一 IP 的客户端都会被 hash 到同一台服务器上。 缺点：不利于集群扩展，后台服务器数量变更都会影响 hash 结果。可以采用一致性 Hash 改进。 7.2. 实现 HTTP 重定向 HTTP 重定向负载均衡服务器收到 HTTP 请求之后会返回服务器的地址，并将该地址写入 HTTP 重定向响应中返回给浏览器，浏览器收到后需要再次发送请求。 缺点： 用户访问的延迟会增加； 如果负载均衡器宕机，就无法访问该站点。 DNS 重定向 使用 DNS 作为负载均衡器，根据负载情况返回不同服务器的 IP 地址。大型网站基本使用了这种方式做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。 缺点： DNS 查找表可能会被客户端缓存起来，那么之后的所有请求都会被重定向到同一个服务器。 修改 MAC 地址 使用 LVS（Linux Virtual Server）这种链路层负载均衡器，根据负载情况修改请求的 MAC 地址。 修改 IP 地址 在网络层修改请求的目的 IP 地址。 代理自动配置 正向代理与反向代理的区别： 正向代理：发生在客户端，是由用户主动发起的。比如翻墙，客户端通过主动访问代理服务器，让代理服务器获得需要的外网数据，然后转发回客户端。 反向代理：发生在服务器端，用户不知道代理的存在。 PAC 服务器是用来判断一个请求是否要经过代理。 8. 资料 https://www.cnblogs.com/savorboard/p/distributed-system-transaction-consistency.html https://github.com/CyC2018/Interview-Notebook/blob/master/notes/分布式问题分析.md https://www.jianshu.com/p/453c6e7ff81c https://juejin.im/post/5a20cd8bf265da43163cdd9a https://github.com/redisson/redisson/wiki/8.-分布式锁和同步器 https://github.com/L316476844/distributed-session 分布式缓存架构基础 阿里 P8 技术专家细究分布式缓存问题]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负载均衡]]></title>
    <url>%2Fblog%2F2018%2F07%2F05%2Fdesign%2Fdistributed%2Fdistributed-load-balance%2F</url>
    <content type="text"><![CDATA[负载均衡 负载均衡原理 系统的扩展可分为垂直扩展和水平扩展。 垂直扩展，是从单机的角度通过增加硬件处理能力，比如 CPU 处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升。这种方式不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。 水平扩展，是通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。 应用集群：将同一应用部署到多台机器上，组成处理集群，接收负载均衡设备分发的请求，进行处理，并返回相应数据。 负载均衡设备：将用户访问的请求，根据负载均衡算法，分发到集群中的一台处理服务器。（一种把网络请求分散到一个服务器集群中的可用服务器上去的设备） 负载均衡的作用（解决的问题）： 解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）； 提供故障转移，实现高可用； 通过添加或减少服务器数量，提供网站伸缩性（扩展性）； 安全防护；（负载均衡设备上做一些过滤，黑白名单等处理） 负载均衡分类 根据实现技术不同，可分为反向代理、HTTP 重定向、DNS 重定向、修改 IP 地址、修改 MAC 地址等。 反向代理 正向代理与反向代理的区别： 正向代理：发生在客户端，是由用户主动发起的。比如翻墙，客户端通过主动访问代理服务器，让代理服务器获得需要的外网数据，然后转发回客户端。 反向代理：发生在服务器端，用户不知道代理的存在。 反向代理的作用是保护网站安全，所有互联网的请求都必须经过代理服务器，相当于在 web 服务器和可能的网络攻击之间建立了一个屏障。 优点：部署简单 缺点：可能成为系统瓶颈 HTTP 重定向 HTTP 重定向服务器收到 HTTP 请求之后会返回服务器的地址，并将该地址写入 HTTP 重定向响应中返回给浏览器，浏览器收到后需要再次发送请求。 缺点： 用户访问的延迟会增加； 如果负载均衡器宕机，就无法访问该站点。 DNS 重定向 使用 DNS 作为负载均衡器，根据负载情况返回不同服务器的 IP 地址。 大型网站基本使用了这种方式做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。 优点： 使用简单：负载均衡工作，交给 DNS 服务器处理，省掉了负载均衡服务器维护的麻烦 提高性能：可以支持基于地址的域名解析，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能； 缺点： 可用性差：DNS 解析是多级解析，新增/修改 DNS 后，解析时间较长；解析过程中，用户访问网站将失败； 扩展性低：DNS 负载均衡的控制权在域名商那里，无法对其做更多的改善和扩展； 维护性差：也不能反映服务器的当前运行状态；支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载） 建议： 将 DNS 作为第一级负载均衡，A 记录对应着内部负载均衡的 IP 地址，通过内部负载均衡将请求分发到真实的 Web 服务器上。一般用于互联网公司，复杂的业务系统不合适使用。 修改 IP 地址 在网络层修改请求的目的 IP 地址来进行负载均衡。 用户请求数据包，到达负载均衡服务器后，负载均衡服务器在操作系统内核进程获取网络数据包，根据负载均衡算法得到一台真实服务器地址，然后将请求目的地址修改为，获得的真实 ip 地址，不需要经过用户进程处理。真实服务器处理完成后，响应数据包回到负载均衡服务器，负载均衡服务器，再将数据包源地址修改为自身的 ip 地址，发送给用户浏览器。 IP 负载均衡，真实物理服务器返回给负载均衡服务器，存在两种方式： 负载均衡服务器在修改目的 ip 地址的同时修改源地址。将数据包源地址设为自身盘，即网络地址转换（NAT）。 将负载均衡服务器同时作为真实物理服务器集群的网关服务器。 优点：在内核进程完成数据分发，比在应用层分发性能更好； 缺点：所有请求响应都需要经过负载均衡服务器，集群最大吞吐量受限于负载均衡服务器网卡带宽； 修改 MAC 地址 使用 LVS（Linux Virtual Server）这种链路层负载均衡器，根据负载情况修改请求的 MAC 地址。 实际处理服务器 ip 和数据请求目的 ip 一致，不需要经过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。也称为直接路由模式（DR 模式）。 优点：性能好； 缺点：配置复杂； 建议：DR 模式是目前使用最广泛的一种负载均衡方式。 混合负载均衡 由于多个服务器群内硬件设备、各自的规模、提供的服务等的差异，可以考虑给每个服务器群采用最合适的负载均衡方式，然后又在这多个服务器群间再一次负载均衡或群集起来以一个整体向外界提供服务（即把这多个服务器群当做一个新的服务器群），从而达到最佳的性能。将这种方式称之为混合型负载均衡。 此种方式有时也用于单台均衡设备的性能不能满足大量连接请求的情况下。是目前大型互联网公司，普遍使用的方式。 方式一，如下图： 以上模式适合有动静分离的场景，反向代理服务器（集群）可以起到缓存和动态请求分发的作用，当时静态资源缓存在代理服务器时，则直接返回到浏览器。如果动态页面则请求后面的应用负载均衡（应用集群）。 方式二，如下图： 以上模式，适合动态请求场景。 因混合模式，可以根据具体场景，灵活搭配各种方式，以上两种方式仅供参考。 负载均衡算法 常用的负载均衡算法有：轮询、随机、最少连接、源地址散列、加权等方式。 轮询 轮询（Round Robin）算法将所有请求，依次分发到每台服务器上，适合服务器硬件同相同的场景。 优点：服务器请求数目相同； 缺点：服务器压力不一样，不适合服务器配置不同的情况； 下图中，一共有 6 个客户端产生了 6 个请求，这 6 个请求按 (1, 2, 3, 4, 5, 6) 的顺序发送。最后，(1, 3, 5) 的请求会被发送到服务器 1，(2, 4, 6) 的请求会被发送到服务器 2。 该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载（下图的 Server 2）。 算法示例： private Integer pos = 0;public void roundRobin() &#123; List&lt;String&gt; keyList = new ArrayList&lt;String&gt;(serverMap.keySet()); String server = null; synchronized (pos) &#123; if (pos &gt; keyList.size()) &#123; pos = 0; &#125; server = keyList.get(pos); pos++; &#125; System.out.println(server);&#125; 加权轮询 加权轮询（Weighted Round Robbin）算法在轮询算法的基础上，通过加权的方式，进行负载服务器分配。 优点：根据权重，调节转发服务器的请求数目； 缺点：使用相对复杂； 加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值。例如下图中，服务器 1 被赋予的权值为 5，服务器 2 被赋予的权值为 1，那么 (1, 2, 3, 4, 5) 请求会被发送到服务器 1，(6) 请求会被发送到服务器 2。 算法示例： public void weightRoundRobin() &#123; Set&lt;String&gt; keySet = serverMap.keySet(); List&lt;String&gt; servers = new ArrayList&lt;String&gt;(); for (Iterator&lt;String&gt; it = keySet.iterator(); it.hasNext(); ) &#123; String server = it.next(); int weithgt = serverMap.get(server); for (int i = 0; i &lt; weithgt; i++) &#123; servers.add(server); &#125; &#125; String server = null; synchronized (pos) &#123; if (pos &gt; keySet.size()) &#123; pos = 0; &#125; server = servers.get(pos); pos++; &#125; System.out.println(server);&#125; 最少连接 最少连接（Least Busy）算法将请求分配到连接数最少的服务器（目前处理请求最少的服务器）。 优点：根据服务器当前的请求处理情况，动态分配； 缺点：算法实现相对复杂，需要监控服务器请求连接数； 由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。例如下图中，(1, 3, 5) 请求会被发送到服务器 1，但是 (1, 3) 很快就断开连接，此时只有 (5) 请求连接服务器 1；(2, 4, 6) 请求被发送到服务器 2，只有 (2) 的连接断开。该系统继续运行时，服务器 2 会承担过大的负载。 最少连接算法就是将请求发送给当前最少连接数的服务器上。例如下图中，服务器 1 当前连接数最小，那么新到来的请求 6 就会被发送到服务器 1 上。 加权最少连接 加权最少连接（Weighted Least Connection）在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。 ### 随机 随机（Random）算法将请求随机分配到各个服务器。 优点：使用简单； 缺点：不适合机器配置不同的场景； 和轮询算法类似，该算法比较适合服务器性能差不多的场景。 哈希（Hash） 普通 Hash 根据 IP 地址进行 Hash 计算，得到 IP 地址。 优点：将来自同一 IP 地址的请求，同一会话期内，转发到相同的服务器；实现会话粘滞。 缺点：目标服务器宕机后，会话会丢失； 算法示例： public void hash() &#123; List&lt;String&gt; keyList = new ArrayList&lt;String&gt;(serverMap.keySet()); String remoteIp = "192.168.2.215"; int hashCode = remoteIp.hashCode(); int idx = hashCode % keyList.size(); String server = keyList.get(Math.abs(idx)); System.out.println(server);&#125; 一致性哈希 一致性 Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 硬件负载均衡 采用硬件的方式实现负载均衡，一般是单独的负载均衡服务器，价格昂贵，一般土豪级公司可以考虑，业界领先的有两款，F5 和 A10。 使用硬件负载均衡，主要考虑一下几个方面： 功能考虑：功能全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡； 性能考虑：一般软件负载均衡支持到 5 万级并发已经很困难了，硬件负载均衡可以支持 稳定性：商用硬件负载均衡，经过了良好的严格的测试，从经过大规模使用，在稳定性方面高； 安全防护：硬件均衡设备除具备负载均衡功能外，还具备防火墙，防 DDOS 攻击等安全功能； 维护角度：提供良好的维护管理界面，售后服务和技术支持； 土豪公司：F5 Big Ip 价格：15w~55w 不等；A10 价格：55w-100w 不等； 缺点 价格昂贵； 扩展能力差； 小结 一般硬件的负载均衡也要做双机高可用，因此成本会比较高。 互联网公司一般使用开源软件，因此大部分应用采用软件负载均衡；部分采用硬件负载均衡。 比如某互联网公司，目前是使用几台 F5 做全局负载均衡，内部使用 Nginx 等软件负载均衡。 Ngnix 负载均衡 Ngnix 是一款轻量级的 Web 服务器/反向代理服务器，工作在七层 Http 协议的负载均衡系统。具有高性能、高并发、低内存使用等特点。是一个轻量级的 Http 和反向代理服务器。Nginx 使用 epoll and kqueue 作为开发模型。能够支持高达 50,000 个并发连接数的响应。 操作系统：Liunx，Windows（Linux、FreeBSD、Solaris、Mac OS X、AIX 以及 Microsoft Windows） 开发语言：C 并发性能：官方支持每秒 5 万并发，实际国内一般到每秒 2 万并发，有优化到每秒 10 万并发的。具体性能看应用场景。 Ngnix 特点 模块化设计：良好的扩展性，可以通过模块方式进行功能扩展。 高可靠性：主控进程和 worker 是同步实现的，一个 worker 出现问题，会立刻启动另一个 worker。 内存消耗低：一万个长连接（keep-alive）,仅消耗 2.5MB 内存。 支持热部署：不用停止服务器，实现更新配置文件，更换日志文件、更新服务器程序版本。 并发能力强：官方数据每秒支持 5 万并发； 功能丰富：优秀的反向代理功能和灵活的负载均衡策略 Ngnix 功能 基本功能 支持静态资源的 web 服务器。 http,smtp,pop3 协议的反向代理服务器、缓存、负载均衡； 支持 FASTCGI（fpm） 支持模块化，过滤器（让文本可以实现压缩，节约带宽）,ssl 及图像大小调整。 内置的健康检查功能 基于名称和 ip 的虚拟主机 定制访问日志 支持平滑升级 支持 KEEPALIVE 支持 url rewrite 支持路径别名 支持基于 IP 和用户名的访问控制。 支持传输速率限制，支持并发数限制。 扩展功能 性能 Nginx 的高并发，官方测试支持 5 万并发连接。实际生产环境能到 2-3 万并发连接数。10000 个非活跃的 HTTP keep-alive 连接仅占用约 2.5MB 内存。三万并发连接下，10 个 Nginx 进程，消耗内存 150M。淘宝 tengine 团队测试结果是“24G 内存机器上，处理并发请求可达 200 万”。 Ngnix 架构 Nginx 的基本工作模式 一个 master 进程，生成一个或者多个 worker 进程。但是这里 master 是使用 root 身份启动的，因为 nginx 要工作在 80 端口。而只有管理员才有权限启动小于低于 1023 的端口。master 主要是负责的作用只是启动 worker，加载配置文件，负责系统的平滑升级。其它的工作是交给 worker。那么当 worker 被启动之后，也只是负责一些 web 最简单的工作，而其他的工作都是有 worker 中调用的模块来实现的。 模块之间是以流水线的方式实现功能的。流水线，指的是一个用户请求，由多个模块组合各自的功能依次实现完成的。比如：第一个模块只负责分析请求首部，第二个模块只负责查找数据，第三个模块只负责压缩数据，依次完成各自工作。来实现整个工作的完成。 他们是如何实现热部署的呢？其实是这样的，我们前面说 master 不负责具体的工作，而是调用 worker 工作，他只是负责读取配置文件，因此当一个模块修改或者配置文件发生变化，是由 master 进行读取，因此此时不会影响到 worker 工作。在 master 进行读取配置文件之后，不会立即的把修改的配置文件告知 worker。而是让被修改的 worker 继续使用老的配置文件工作，当 worker 工作完毕之后，直接当掉这个子进程，更换新的子进程，使用新的规则。 Nginx 支持的 sendfile 机制 Sendfile 机制，用户将请求发给内核，内核根据用户的请求调用相应用户进程，进程在处理时需要资源。此时再把请求发给内核（进程没有直接 IO 的能力），由内核加载数据。内核查找到数据之后，会把数据复制给用户进程，由用户进程对数据进行封装，之后交给内核，内核在进行 tcp/ip 首部的封装，最后再发给客户端。这个功能用户进程只是发生了一个封装报文的过程，却要绕一大圈。因此 nginx 引入了 sendfile 机制，使得内核在接受到数据之后，不再依靠用户进程给予封装，而是自己查找自己封装，减少了一个很长一段时间的浪费，这是一个提升性能的核心点。 以上内容摘自网友发布的文章，简单一句话是资源的处理，直接通过内核层进行数据传递，避免了数据传递到应用层，应用层再传递到内核层的开销。 目前高并发的处理，一般都采用 sendfile 模式。通过直接操作内核层数据，减少应用与内核层数据传递。 Nginx 通信模型（I/O 复用机制） 开发模型：epoll 和 kqueue。 支持的事件机制：kqueue、epoll、rt signals、/dev/poll 、event ports、select 以及 poll。 支持的 kqueue 特性包括 EV_CLEAR、EV_DISABLE、NOTE_LOWAT、EV_EOF，可用数据的数量，错误代码. 支持 sendfile、sendfile64 和 sendfilev;文件 AIO；DIRECTIO;支持 Accept-filters 和 TCP_DEFER_ACCEP. 以上概念较多，大家自行百度或谷歌，知识领域是网络通信（BIO,NIO,AIO）和多线程方面的知识。 Ngnix 均衡策略 nginx 的负载均衡策略可以划分为两大类：内置策略和扩展策略。内置策略包含加权轮询和 ip hash，在默认情况下这两种策略会编译进 nginx 内核，只需在 nginx 配置中指明参数即可。扩展策略有很多，如 fair、通用 hash、consistent hash 等，默认不编译进 nginx 内核。由于在 nginx 版本升级中负载均衡的代码没有本质性的变化，因此下面将以 nginx1.0.15 稳定版为例，从源码角度分析各个策略。 加权轮询（weighted round robin） 轮询的原理很简单，首先我们介绍一下轮询的基本流程。如下是处理一次请求的流程图： 图中有两点需要注意，第一，如果可以把加权轮询算法分为先深搜索和先广搜索，那么 nginx 采用的是先深搜索算法，即将首先将请求都分给高权重的机器，直到该机器的权值降到了比其他机器低，才开始将请求分给下一个高权重的机器；第二，当所有后端机器都 down 掉时，nginx 会立即将所有机器的标志位清成初始状态，以避免造成所有的机器都处在 timeout 的状态，从而导致整个前端被夯住。 ip hash ip hash 是 nginx 内置的另一个负载均衡的策略，流程和轮询很类似，只是其中的算法和具体的策略有些变化，如下图所示： fair fair 策略是扩展策略，默认不被编译进 nginx 内核。其原理是根据后端服务器的响应时间判断负载情况，从中选出负载最轻的机器进行分流。这种策略具有很强的自适应性，但是实际的网络环境往往不是那么简单，因此要慎用。 通用 hash、一致性 hash 这两种也是扩展策略，在具体的实现上有些差别，通用 hash 比较简单，可以以 nginx 内置的变量为 key 进行 hash，一致性 hash 采用了 nginx 内置的一致性 hash 环，可以支持 memcache。 Ngnix 场景 Ngnix 一般作为入口负载均衡或内部负载均衡，结合反向代理服务器使用。以下架构示例，仅供参考，具体使用根据场景而定。 入口负载均衡架构 Ngnix 服务器在用户访问的最前端。根据用户请求再转发到具体的应用服务器或二级负载均衡服务器（LVS） 内部负载均衡架构 LVS 作为入口负载均衡，将请求转发到二级 Ngnix 服务器，Ngnix 再根据请求转发到具体的应用服务器。 Ngnix 高可用 分布式系统中，应用只部署一台服务器会存在单点故障，负载均衡同样有类似的问题。一般可采用主备或负载均衡设备集群的方式节约单点故障或高并发请求分流。 Ngnix 高可用，至少包含两个 Ngnix 服务器，一台主服务器，一台备服务器，之间使用 Keepalived 做健康监控和故障检测。开放 VIP 端口，通过防火墙进行外部映射。 DNS 解析公网的 IP 实际为 VIP。 LVS 负载均衡 LVS 是一个开源的软件，由毕业于国防科技大学的章文嵩博士于 1998 年 5 月创立，用来实现 Linux 平台下的简单负载均衡。LVS 是 Linux Virtual Server 的缩写，意思是 Linux 虚拟服务器。 基于 IP 层的负载均衡调度技术，它在操作系统核心层上，将来自 IP 层的 TCP/UDP 请求均衡地转移到不同的 服务器，从而将一组服务器构成一个高性能、高可用的虚拟服务器。 操作系统：Liunx 开发语言：C 并发性能：默认 4096，可以修改但需要重新编译。 LVS 功能 LVS 的主要功能是实现 IP 层（网络层）负载均衡，有 NAT,TUN,DR 三种请求转发模式。 LVS/NAT 方式的负载均衡集群 NAT 是指 Network Address Translation，它的转发流程是：Director 机器收到外界请求，改写数据包的目标地址，按相应的调度算法将其发送到相应 Real Server 上，Real Server 处理完该请求后，将结果数据包返回到其默认网关，即 Director 机器上，Director 机器再改写数据包的源地址，最后将其返回给外界。这样就完成一次负载调度。 构架一个最简单的 LVS/NAT 方式的负载均衡集群 Real Server 可以是任何的操作系统，而且无需做任何特殊的设定，惟一要做的就是将其默认网关指向 Director 机器。Real Server 可以使用局域网的内部 IP(192.168.0.0/24)。Director 要有两块网卡，一块网卡绑定一个外部 IP 地址 (10.0.0.1)，另一块网卡绑定局域网的内部 IP(192.168.0.254)，作为 Real Server 的默认网关。 LVS/NAT 方式实现起来最为简单，而且 Real Server 使用的是内部 IP，可以节省 Real IP 的开销。但因为执行 NAT 需要重写流经 Director 的数据包，在速度上有一定延迟； 当用户的请求非常短，而服务器的回应非常大的情况下，会对 Director 形成很大压力，成为新的瓶颈，从而使整个系统的性能受到限制。 LVS/TUN 方式的负载均衡集群 TUN 是指 IP Tunneling，它的转发流程是：Director 机器收到外界请求，按相应的调度算法,通过 IP 隧道发送到相应 Real Server，Real Server 处理完该请求后，将结果数据包直接返回给客户。至此完成一次负载调度。 最简单的 LVS/TUN 方式的负载均衡集群架构使用 IP Tunneling 技术，在 Director 机器和 Real Server 机器之间架设一个 IP Tunnel，通过 IP Tunnel 将负载分配到 Real Server 机器上。Director 和 Real Server 之间的关系比较松散，可以是在同一个网络中，也可以是在不同的网络中，只要两者能够通过 IP Tunnel 相连就行。收到负载分配的 Real Server 机器处理完后会直接将反馈数据送回给客户，而不必通过 Director 机器。实际应用中，服务器必须拥有正式的 IP 地址用于与客户机直接通信，并且所有服务器必须支持 IP 隧道协议。 该方式中 Director 将客户请求分配到不同的 Real Server，Real Server 处理请求后直接回应给用户，这样 Director 就只处理客户机与服务器的一半连接，极大地提高了 Director 的调度处理能力，使集群系统能容纳更多的节点数。另外 TUN 方式中的 Real Server 可以在任何 LAN 或 WAN 上运行，这样可以构筑跨地域的集群，其应对灾难的能力也更强，但是服务器需要为 IP 封装付出一定的资源开销，而且后端的 Real Server 必须是支持 IP Tunneling 的操作系统。 LVS/TUN 方式的负载均衡集群 DR 是指 Direct Routing，它的转发流程是：Director 机器收到外界请求，按相应的调度算法将其直接发送到相应 Real Server，Real Server 处理完该请求后，将结果数据包直接返回给客户，完成一次负载调度。 构架一个最简单的 LVS/DR 方式的负载均衡集群 Real Server 和 Director 都在同一个物理网段中，Director 的网卡 IP 是 192.168.0.253，再绑定另一个 IP： 192.168.0.254 作为对外界的 virtual IP，外界客户通过该 IP 来访问整个集群系统。Real Server 在 lo 上绑定 IP：192.168.0.254，同时加入相应的路由。 LVS/DR 方式与前面的 LVS/TUN 方式有些类似，前台的 Director 机器也是只需要接收和调度外界的请求，而不需要负责返回这些请求的反馈结果，所以能够负载更多的 Real Server，提高 Director 的调度处理能力，使集群系统容纳更多的 Real Server。但 LVS/DR 需要改写请求报文的 MAC 地址，所以所有服务器必须在同一物理网段内。 LVS 架构 LVS 架设的服务器集群系统有三个部分组成：最前端的负载均衡层（Loader Balancer），中间的服务器群组层，用 Server Array 表示，最底层的数据共享存储层，用 Shared Storage 表示。在用户看来所有的应用都是透明的，用户只是在使用一个虚拟服务器提供的高性能服务。 LVS 的体系架构如图： LVS 的各个层次的详细介绍： Load Balancer 层：位于整个集群系统的最前端，有一台或者多台负载调度器（Director Server）组成，LVS 模块就安装在 Director Server 上，而 Director 的主要作用类似于一个路由器，它含有完成 LVS 功能所设定的路由表，通过这些路由表把用户的请求分发给 Server Array 层的应用服务器（Real Server）上。同时，在 Director Server 上还要安装对 Real Server 服务的监控模块 Ldirectord，此模块用于监测各个 Real Server 服务的健康状况。在 Real Server 不可用时把它从 LVS 路由表中剔除，恢复时重新加入。 Server Array 层：由一组实际运行应用服务的机器组成，Real Server 可以是 WEB 服务器、MAIL 服务器、FTP 服务器、DNS 服务器、视频服务器中的一个或者多个，每个 Real Server 之间通过高速的 LAN 或分布在各地的 WAN 相连接。在实际的应用中，Director Server 也可以同时兼任 Real Server 的角色。 Shared Storage 层：是为所有 Real Server 提供共享存储空间和内容一致性的存储区域，在物理上，一般有磁盘阵列设备组成，为了提供内容的一致性，一般可以通过 NFS 网络文件系统共享数 据，但是 NFS 在繁忙的业务系统中，性能并不是很好，此时可以采用集群文件系统，例如 Red hat 的 GFS 文件系统，oracle 提供的 OCFS2 文件系统等。 从整个 LVS 结构可以看出，Director Server 是整个 LVS 的核心，目前，用于 Director Server 的操作系统只能是 Linux 和 FreeBSD，linux2.6 内核不用任何设置就可以支持 LVS 功能，而 FreeBSD 作为 Director Server 的应用还不是很多，性能也不是很好。对于 Real Server，几乎可以是所有的系统平台，Linux、windows、Solaris、AIX、BSD 系列都能很好的支持。 LVS 均衡策略 LVS 默认支持八种负载均衡策略，简述如下： 轮询调度（Round Robin） 调度器通过“轮询”调度算法将外部请求按顺序轮流分配到集群中的真实服务器上，它均等地对待每一台服务器，而不管服务器上实际的连接数和系统负载。 加权轮询（Weighted Round Robin） 调度器通过“加权轮询”调度算法根据真实服务器的不同处理能力来调度访问请求。这样可以保证处理能力强的服务器能处理更多的访问流量。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 最少链接（Least Connections） 调度器通过“最少连接”调度算法动态地将网络请求调度到已建立的链接数最少的服务器上。如果集群系统的真实服务器具有相近的系统性能，采用“最小连接”调度算法可以较好地均衡负载。 加权最少链接（Weighted Least Connections） 在集群系统中的服务器性能差异较大的情况下，调度器采用“加权最少链接”调度算法优化负载均衡性能，具有较高权值的服务器将承受较大比例的活动连接负载。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 基于局部性的最少链接（Locality-Based Least Connections） “基于局部性的最少链接”调度算法是针对目标 IP 地址的负载均衡，目前主要用于 Cache 集群系统。该算法根据请求的目标 IP 地址找出该目标 IP 地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则用“最少链接” 的原则选出一个可用的服务器，将请求发送到该服务器。 带复制的基于局部性最少链接（Locality-Based Least Connections with Replication） “带复制的基于局部性最少链接”调度算法也是针对目标 IP 地址的负载均衡，目前主要用于 Cache 集群系统。它与 LBLC 算法的不同之处是它要维护从一个目标 IP 地址到一组服务器的映射，而 LBLC 算法维护从一个目标 IP 地址到一台服务器的映射。该算法根据请求的目标 IP 地址找出该目标 IP 地址对应的服务器组，按“最小连接”原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接”原则从这个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。 目标地址散列（Destination Hashing） “目标地址散列”调度算法根据请求的目标 IP 地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。 源地址散列（Source Hashing） “源地址散列”调度算法根据请求的源 IP 地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。 除具备以上负载均衡算法外，还可以自定义均衡策略。 LVS 场景 一般作为入口负载均衡或内部负载均衡，结合反向代理服务器使用。相关架构可参考 Ngnix 场景架构。 HaProxy 负载均衡 HAProxy 也是使用较多的一款负载均衡软件。HAProxy 提供高可用性、负载均衡以及基于 TCP 和 HTTP 应用的代理，支持虚拟主机，是免费、快速并且可靠的一种解决方案。特别适用于那些负载特大的 web 站点。运行模式使得它可以很简单安全的整合到当前的架构中，同时可以保护你的 web 服务器不被暴露到网络上。 HaProxy 特点 支持两种代理模式：TCP（四层）和 HTTP（七层），支持虚拟主机； 配置简单，支持 url 检测后端服务器状态； 做负载均衡软件使用，在高并发情况下，处理速度高于 nginx； TCP 层多用于 Mysql 从（读）服务器负载均衡。 （对 Mysql 进行负载均衡，对后端的 DB 节点进行检测和负载均衡） 能够补充 Nginx 的一些缺点比如 Session 的保持，Cookie 引导等工作 HaProxy 均衡策略 支持四种常用算法： roundrobin：轮询，轮流分配到后端服务器； static-rr：根据后端服务器性能分配； leastconn：最小连接者优先处理； source：根据请求源 IP，与 Nginx 的 IP_Hash 类似。 资料 大型网站架构系列：负载均衡详解（1） 大型网站架构系列：负载均衡详解（2） 大型网站架构系列：负载均衡详解（3） 大型网站架构系列：负载均衡详解（4） https://segmentfault.com/a/1190000004492447]]></content>
      <categories>
        <category>design</category>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站的高性能架构]]></title>
    <url>%2Fblog%2F2018%2F07%2F05%2Fdesign%2Farchitecture%2F%E7%BD%91%E7%AB%99%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[网站的高性能架构 📓 本文已归档到：「blog」 1. 性能测试 1.1. 性能指标 1.2. 性能测试方法 1.3. 性能测试报告 1.4. 性能优化策略 2. 前端性能优化 2.1. 浏览器访问优化 2.2. CDN 2.3. 反向代理 3. 应用服务性能优化 3.1. 分布式缓存 3.2. 异步操作 3.3. 使用集群 3.4. 代码优化 4. 存储性能优化 4.1. 机械键盘和固态硬盘 4.2. B+数和 LSM 树 4.3. RAID 和 HDFS 5. 资料 1. 性能测试 1.1. 性能指标 网站性能测试的主要指标有： 响应时间 - 响应时间(RT)是指从客户端发一个请求开始计时，到客户端接收到从服务器端返回的响应结果结束所经历的时间，响应时间由请求发送时间、网络传输时间和服务器处理时间三部分组成。 并发数 - 系统同时处理的请求、事务数。 吞吐量 - TPS(每秒事务数)、HPS(每秒 HTTP 请求数)、QPS(每秒查询数)。 性能计数器 - 系统负载、对象与线程数、内存使用、CPU 使用、磁盘与网络 IO 等。这些指标也是系统监控的重要参数。 1.2. 性能测试方法 性能测试 负载测试 压力测试 稳定性测试 1.3. 性能测试报告 性能测试报告示例： 1.4. 性能优化策略 性能分析 - 如果请求响应慢，存在性能问题。需要对请求经历的各个环节逐一分析，排查可能出现性能瓶颈的地方，定位问题。检查监控数据，分析影响性能的主要因素：内存、磁盘、网络、CPU，可能是代码或架构设计不合理，又或者是系统资源确实不足。 性能优化 - 性能优化根据网站分层架构，大致可分为前端性能优化、应用服务性能优化、存储服务性能优化。 2. 前端性能优化 2.1. 浏览器访问优化 减少 HTTP 请求 - HTTP 请求需要建立通信链路，进行数据传输，开销高昂，所以减少 HTTP 请求数可以有效提高访问性能。减少 HTTP 的主要手段是合并 Css、JavaScript、图片。 使用浏览器缓存 - 因为静态资源文件更新频率低，可以缓存浏览器中以提高性能。设置 HTTP 头中的 Cache-Control 和 Expires 属性，可以设定浏览器缓存。 启用压缩 - 在服务器端压缩静态资源文件，在浏览器端解压缩，可以有效减少传输的数据量。由于文本文件压缩率可达 80% 以上，所以可以对静态资源，如 Html、Css、JavaScrip 进行压缩。 CSS 放在页面最上面，JavaScript 放在页面最下面 - 浏览器会在下载完全部的 Css 后才对整个页面进行渲染，所以最好的做法是将 Css 放在页面最上面，让浏览器尽快下载 Css；JavaScript 则相反，浏览器加载 JavaScript 后立即执行，可能会阻塞整个页面，造成页面显示缓慢，因此 JavaScript 最好放在页面最下面。 减少 Cookie 传输 - Cookie 包含在 HTTP 每次的请求和响应中，太大的 Cookie 会严重影响数据传输。 2.2. CDN CDN 一般缓存的是静态资源。 CDN 的本质仍然是一个缓存，而且将数据缓存在离用户最近的地方，使用户已最快速度获取数据，即所谓网络访问第一跳。 2.3. 反向代理 传统代理服务器位于浏览器一侧，代理浏览器将 HTTP 请求发送到互联网上，而反向代理服务器位于网站机房一侧，代理网站服务器接收 HTTP 请求。 反向代理服务器可以配置缓存功能加速 Web 请求，当用户第一次访问静态内容时，静态内容就会被缓存在反向代理服务器上。 反向代理还可以实现负载均衡，通过负载均衡构建的集群可以提高系统总体处理能力。 因为所有请求都必须先经过反向代理服务器，所以可以屏蔽一些攻击 IP，达到保护网站安全的作用。 3. 应用服务性能优化 3.1. 分布式缓存 网站性能优化第一定律：优先考虑使用缓存优化性能。 缓存原理 缓存指将数据存储在相对较高访问速度的存储介质中，以供系统处理。一方面缓存访问速度快，可以减少数据访问的时间，另一方面如果缓存的数据是经过计算处理得到的，那么被缓存的数据无需重复计算即可直接使用，因此缓存还起到减少计算时间的作用。 缓存的本质是一个内存 HASH 表。 缓存主要用来存放那些读写比很高、很少变化的数据，如商品的类目信息，热门词的搜索列表信息、热门商品信息等。 合理使用缓存 缓存数据的选择： 不要存储频繁修改的数据 不要存储非热点数据 数据不一致和脏读： 缓存有有效期，所以存在一定时间的数据不一致和脏读问题。如果不能接受，可以考虑使用数据更新立即更新缓存策略 需要考虑缓存问题：缓存雪崩、缓存穿透、缓存预热 3.2. 异步操作 异步处理一般是通过分布式消息队列的方式。 异步处理可以解决一下问题： 异步处理 应用解耦 流量削锋 日志处理 消息通讯 3.3. 使用集群 在高并发场景下，使用负载均衡技术为一个应用构建一个由多台服务器组成的服务器集群，将并发访问请求分发到多台服务器上处理，避免单一服务器因负载压力过大而响应缓慢，使用户请求具有更好的响应延迟特性。 3.4. 代码优化 多线程 从资源利用的角度看，使用多线程的原因主要有两个：IO 阻塞和多 CPU。 线程数并非越多越好，那么启动多少线程合适呢？ 有个参考公式： 启动线程数 = (任务执行时间 / (任务执行时间 - IO 等待时间)) * CPU 内核数 最佳启动线程数和 CPU 内核数成正比，和 IO 阻塞时间成反比。如果任务都是 CPU 计算型任务，那么线程数最多不要超过 CPU 内核数，因为启动再多线程，CPU 也来不及调度；相反如果是任务需要等待磁盘操作，网络响应，那么多启动线程有助于任务并罚赌，提高系统吞吐量。 线程安全问题 将对象设计为无状态对象 使用局部对象 并发访问资源时使用锁 资源复用 应该尽量减少那些开销很大的系统资源的创建和销毁，如数据库连接、网络通信连接、线程、复杂对象等。从编程角度，资源复用主要有两种模式：单例模式和对象池。 数据结构 根据具体场景，选择合适的数据结构。 垃圾回收 如果 Web 应用运行在 JVM 等具有垃圾回收功能的环境中，那么垃圾回收可能会对系统的性能特性产生巨大影响。立即垃圾回收机制有助于程序优化和参数调优，以及编写内存安全的代码。 4. 存储性能优化 4.1. 机械键盘和固态硬盘 考虑使用固态硬盘替代机械键盘，因为它的读写速度更快。 4.2. B+数和 LSM 树 传统关系数据库的数据库索引一般都使用两级索引的 B+ 树结构，树的层次最多三层。因此可能需要 5 次磁盘访问才能更新一条记录（三次磁盘访问获得数据索引及行 ID，然后再进行一次数据文件读操作及一次数据文件写操作）。 由于磁盘访问是随机的，传统机械键盘在数据随机访问时性能较差，每次数据访问都需要多次访问磁盘影响数据访问性能。 许多 Nosql 数据库中的索引采用 LSM 树作为主要数据结构。LSM 树可视为一个 N 阶合并树。数据写操作都在内存中进行。在 LSM 树上进行一次数据更新不需要磁盘访问，速度远快于 B+ 树。 4.3. RAID 和 HDFS HDFS(分布式文件系统) 更被大型网站所青睐。它可以配合 MapReduce 并发计算任务框架进行大数据处理，可以在整个集群上并发访问所有磁盘，无需 RAID 支持。 5. 资料 大型网站技术架构]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大型分布式网站架构]]></title>
    <url>%2Fblog%2F2018%2F07%2F05%2Fdesign%2Farchitecture%2F%E5%A4%A7%E5%9E%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%AB%99%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[大型分布式网站架构 📓 本文已归档到：「blog」 1. 大型分布式网站架构概述 1.1. 大型网站的特点 1.2. 大型网站架构目标 1.3. 大型网站架构模式 1.4. 高性能架构 1.5. 高可用架构 1.6. 可伸缩架构 1.7. 可扩展架构 1.8. 安全架构 1.9. 敏捷性 1.10. 大型架构举例 2. 电商网站架构案例 2.1. 网站初级架构 2.2. 系统容量预估 2.3. 网站架构分析 2.4. 网站架构优化 2.5. 架构总结 3. 资料 1. 大型分布式网站架构概述 1.1. 大型网站的特点 用户多，分布广泛 大流量，高并发 海量数据，服务高可用 安全环境恶劣，易受网络攻击 功能多，变更快，频繁发布 从小到大，渐进发展 以用户为中心 免费服务，付费体验 1.2. 大型网站架构目标 高性能：提供快速的访问体验。 高可用：网站服务一直可以正常访问。 可伸缩：通过硬件增加/减少，提高/降低处理能力。 安全性：提供网站安全访问和数据加密，安全存储等策略。 扩展性：方便的通过新增/移除方式，增加/减少新的功能/模块。 敏捷性：随需应变，快速响应； 1.3. 大型网站架构模式 分层：一般可分为，应用层，服务层，数据层，管理层，分析层； 分割：一般按照业务/模块/功能特点进行划分，比如应用层分为首页，用户中心。 分布式：将应用分开部署（比如多台物理机），通过远程调用协同工作。 集群：一个应用/模块/功能部署多份（如：多台物理机），通过负载均衡共同提供对外访问。 缓存：将数据放在距离应用或用户最近的位置，加快访问速度。 异步：将同步的操作异步化。客户端发出请求，不等待服务端响应，等服务端处理完毕后，使用通知或轮询的方式告知请求方。一般指：请求——响应——通知 模式。 冗余：增加副本，提高可用性，安全性，性能。 安全：对已知问题有有效的解决方案，对未知/潜在问题建立发现和防御机制。 自动化：将重复的，不需要人工参与的事情，通过工具的方式，使用机器完成。 敏捷性：积极接受需求变更，快速响应业务发展需求。 1.4. 高性能架构 以用户为中心，提供快速的网页访问体验。主要参数有较短的响应时间，较大的并发处理能力，较高的吞吐量，稳定的性能参数。 可分为前端优化，应用层优化，代码层优化，存储层优化。 前端优化：网站业务逻辑之前的部分； 浏览器优化：减少 Http 请求数，使用浏览器缓存，启用压缩，Css Js 位置，Js 异步，减少 Cookie 传输； CDN 加速，反向代理； 应用层优化：处理网站业务的服务器。使用缓存，异步，集群 代码优化：合理的架构，多线程，资源复用（对象池，线程池等），良好的数据结构，JVM 调优，单例，Cache 等； 存储优化：缓存，固态硬盘，光纤传输，优化读写，磁盘冗余，分布式存储（HDFS），NOSQL 等； 1.5. 高可用架构 大型网站应该在任何时候都可以正常访问。正常提供对外服务。因为大型网站的复杂性，分布式，廉价服务器，开源数据库，操作系统等特点。要保证高可用是很困难的，也就是说网站的故障是不可避免的。 如何提高可用性，就是需要迫切解决的问题。首先，需要从架构级别，在规划的时候，就考虑可用性。行业内一般用几个 9 表示可用性指标。比如四个 9（99.99），一年内允许的不可用时间是 53 分钟。 不同层级使用的策略不同，一般采用冗余备份和失效转移解决高可用问题。 应用层：一般设计为无状态的，对于每次请求，使用哪一台服务器处理是没有影响的。一般使用负载均衡技术（需要解决 Session 同步问题），实现高可用。 服务层：负载均衡，分级管理，快速失败（超时设置），异步调用，服务降级，幂等设计等。 数据层：冗余备份（冷，热备[同步，异步]，温备），失效转移（确认，转移，恢复）。数据高可用方面著名的理论基础是 CAP 理论（持久性，可用性，数据一致性[强一致，用户一致，最终一致]） 1.6. 可伸缩架构 伸缩性是指在不改变原有架构设计的基础上，通过添加/减少硬件（服务器）的方式，提高/降低系统的处理能力。 应用层：对应用进行垂直或水平切分。然后针对单一功能进行负载均衡（DNS,HTTP[反向代理],IP,链路层）。 服务层：与应用层类似； 数据层：分库，分表，NOSQL 等；常用算法 Hash，一致性 Hash。 1.7. 可扩展架构 可以方便的进行功能模块的新增/移除，提供代码/模块级别良好的可扩展性。 模块化，组件化：高内聚，内耦合，提高复用性，扩展性。 稳定接口：定义稳定的接口，在接口不变的情况下，内部结构可以“随意”变化。 设计模式：应用面向对象思想，原则，使用设计模式，进行代码层面的设计。 消息队列：模块化的系统，通过消息队列进行交互，使模块之间的依赖解耦。 分布式服务：公用模块服务化，提供其他系统使用，提高可重用性，扩展性。 1.8. 安全架构 对已知问题有有效的解决方案，对未知/潜在问题建立发现和防御机制。对于安全问题，首先要提高安全意识，建立一个安全的有效机制，从政策层面，组织层面进行保障。比如服务器密码不能泄露，密码每月更新，并且三次内不能重复；每周安全扫描等。以制度化的方式，加强安全体系的建设。同时，需要注意与安全有关的各个环节。安全问题不容忽视。包括基础设施安全，应用系统安全，数据保密安全等。 基础设施安全：硬件采购，操作系统，网络环境方面的安全。一般采用，正规渠道购买高质量的产品，选择安全的操作系统，及时修补漏洞，安装杀毒软件防火墙。防范病毒，后门。设置防火墙策略，建立 DDOS 防御系统，使用攻击检测系统，进行 子网隔离等手段。 ​ 应用系统安全：在程序开发时，对已知常用问题，使用正确的方式，在代码层面解决掉。防止跨站脚本攻击（XSS），注入攻击，跨站请求伪造（CSRF），错误信息，HTML 注释，文件上传，路径遍历等。还可以使用 Web 应用防火墙（比如：ModSecurity），进行安全漏洞扫描等措施，加强应用级别的安全。 ​ 数据保密安全：存储安全（存在在可靠的设备，实时，定时备份），保存安全（重要的信息加密保存，选择合适的人员复杂保存和检测等），传输安全（防止数据窃取和数据篡改）； ​ 常用的加解密算法（单项散列加密[MD5,SHA]，对称加密[DES,3DES,RC]），非对称加密[RSA]等。 1.9. 敏捷性 网站的架构设计，运维管理要适应变化，提供高伸缩性，高扩展性。方便的应对快速的业务发展，突增高流量访问等要求。 除上面介绍的架构要素外，还需要引入敏捷管理，敏捷开发的思想。使业务，产品，技术，运维统一起来，随需应变，快速响应。 1.10. 大型架构举例 以上采用七层逻辑架构，第一层客户层，第二层前端优化层，第三层应用层，第四层服务层，第五层数据存储层，第六层大数据存储层，第七层大数据处理层。 客户层：支持 PC 浏览器和手机 APP。差别是手机 APP 可以直接访问通过 IP 访问，反向代理服务器。 前端层：使用 DNS 负载均衡，CDN 本地加速以及反向代理服务； 应用层：网站应用集群；按照业务进行垂直拆分，比如商品应用，会员中心等； 服务层：提供公用服务，比如用户服务，订单服务，支付服务等； 数据层：支持关系型数据库集群（支持读写分离），NOSQL 集群，分布式文件系统集群；以及分布式 Cache； 大数据存储层：支持应用层和服务层的日志数据收集，关系数据库和 NOSQL 数据库的结构化和半结构化数据收集； 大数据处理层：通过 Mapreduce 进行离线数据分析或 Storm 实时数据分析，并将处理后的数据存入关系型数据库。（实际使用中，离线数据和实时数据会按照业务要求进行分类处理，并存入不同的数据库中，供应用层或服务层使用）。 2. 电商网站架构案例 2.1. 网站初级架构 一般网站，刚开始的做法，是三台服务器，一台部署应用，一台部署数据库，一台部署 NFS 文件系统。 这是前几年比较传统的做法，之前见到一个网站 10 万多会员，垂直服装设计门户，N 多图片。使用了一台服务器部署了应用，数据库以及图片存储。出现了很多性能问题。 如下图： 但是，目前主流的网站架构已经发生了翻天覆地的变化。一般都会采用集群的方式，进行高可用设计。至少是下面这个样子。 （1） 使用集群对应用服务器进行冗余，实现高可用；（负载均衡设备可与应用一块部署） 使用数据库主备模式，实现数据备份和高可用； 2.2. 系统容量预估 预估步骤： （1） 注册用户数-日均 UV 量-每日的 PV 量-每天的并发量； （2） 峰值预估：平常量的 2~3 倍； （3） 根据并发量（并发，事务数），存储容量计算系统容量。 客户需求：3~5 年用户数达到 1000 万注册用户； 每秒并发数预估： （1） 每天的 UV 为 200 万（二八原则）； （2） 每日每天点击浏览 30 次； （3） PV 量：200*30=6000 万； （4） 集中访问量：240.2=4.8 小时会有 6000 万0.8=4800 万（二八原则）； （5） 每分并发量：4.8*60=288 分钟，每分钟访问 4800/288=16.7 万（约等于）； （6） 每秒并发量：16.7 万/60=2780（约等于）； （7） 假设：高峰期为平常值的三倍，则每秒的并发数可以达到 8340 次。 （8） 1 毫秒=1.3 次访问； 没好好学数学后悔了吧？！（不知道以上算是否有错误，呵呵~~） 服务器预估：（以 tomcat 服务器举例） （1） 按一台 web 服务器，支持每秒 300 个并发计算。平常需要 10 台服务器（约等于）；[tomcat 默认配置是 150] （2） 高峰期：需要 30 台服务器； 容量预估：70/90 原则 系统 CPU 一般维持在 70%左右的水平，高峰期达到 90%的水平，是不浪费资源，并比较稳定的。内存，IO 类似。 以上预估仅供参考，因为服务器配置，业务逻辑复杂度等都有影响。在此 CPU，硬盘，网络等不再进行评估。 2.3. 网站架构分析 根据以上预估，有几个问题： 需要部署大量的服务器，高峰期计算，可能要部署 30 台 Web 服务器。并且这三十台服务器，只有秒杀，活动时才会用到，存在大量的浪费。 所有的应用部署在同一台服务器，应用之间耦合严重。需要进行垂直切分和水平切分。 大量应用存在冗余代码 服务器 SESSION 同步耗费大量内存和网络带宽 数据需要频繁访问数据库，数据库访问压力巨大。 大型网站一般需要做以下架构优化（优化是架构设计时，就要考虑的，一般从架构/代码级别解决，调优主要是简单参数的调整，比如 JVM 调优；如果调优涉及大量代码改造，就不是调优了，属于重构）： 业务拆分 应用集群部署（分布式部署，集群部署和负载均衡） 多级缓存 单点登录（分布式 Session） 数据库集群（读写分离，分库分表） 服务化 消息队列 其他技术 2.4. 网站架构优化 业务拆分 根据业务属性进行垂直切分，划分为产品子系统，购物子系统，支付子系统，评论子系统，客服子系统，接口子系统（对接如进销存，短信等外部系统）。 根据业务子系统进行等级定义，可分为核心系统和非核心系统。核心系统：产品子系统，购物子系统，支付子系统；非核心：评论子系统，客服子系统，接口子系统。 业务拆分作用：提升为子系统可由专门的团队和部门负责，专业的人做专业的事，解决模块之间耦合以及扩展性问题；每个子系统单独部署，避免集中部署导致一个应用挂了，全部应用不可用的问题。 等级定义作用：用于流量突发时，对关键应用进行保护，实现优雅降级；保护关键应用不受到影响。 拆分后的架构图： 参考部署方案 2 （1） 如上图每个应用单独部署 （2） 核心系统和非核心系统组合部署 应用集群部署（分布式，集群，负载均衡） ​ 分布式部署：将业务拆分后的应用单独部署，应用直接通过 RPC 进行远程通信； ​ 集群部署：电商网站的高可用要求，每个应用至少部署两台服务器进行集群部署； ​ 负载均衡：是高可用系统必须的，一般应用通过负载均衡实现高可用，分布式服务通过内置的负载均衡实现高可用，关系型数据库通过主备方式实现高可用。 集群部署后架构图： 多级缓存 缓存按照存放的位置一般可分为两类：本地缓存和分布式缓存。本案例采用二级缓存的方式，进行缓存的设计。一级缓存为本地缓存，二级缓存为分布式缓存。（还有页面缓存，片段缓存等，那是更细粒度的划分） 一级缓存，缓存数据字典，和常用热点数据等基本不可变/有规则变化的信息，二级缓存缓存需要的所有缓存。当一级缓存过期或不可用时，访问二级缓存的数据。如果二级缓存也没有，则访问数据库。 缓存的比例，一般 1:4，即可考虑使用缓存。（理论上是 1:2 即可）。 ​ 根据业务特性可使用以下缓存过期策略： （1） 缓存自动过期； （2） 缓存触发过期； 单点登录（分布式 Session） 系统分割为多个子系统，独立部署后，不可避免的会遇到会话管理的问题。一般可采用 Session 同步，Cookies，分布式 Session 方式。电商网站一般采用分布式 Session 实现。 再进一步可以根据分布式 Session，建立完善的单点登录或账户管理系统。 ​ 流程说明 （1） 用户第一次登录时，将会话信息（用户 Id 和用户信息），比如以用户 Id 为 Key，写入分布式 Session； （2） 用户再次登录时，获取分布式 Session，是否有会话信息，如果没有则调到登录页； （3） 一般采用 Cache 中间件实现，建议使用 Redis，因为它有持久化功能，方便分布式 Session 宕机后，可以从持久化存储中加载会话信息； （4） 存入会话时，可以设置会话保持的时间，比如 15 分钟，超过后自动超时； 结合 Cache 中间件，实现的分布式 Session，可以很好的模拟 Session 会话。 数据库集群（读写分离，分库分表） 大型网站需要存储海量的数据，为达到海量数据存储，高可用，高性能一般采用冗余的方式进行系统设计。一般有两种方式读写分离和分库分表。 读写分离：一般解决读比例远大于写比例的场景，可采用一主一备，一主多备或多主多备方式。 本案例在业务拆分的基础上，结合分库分表和读写分离。如下图： （1） 业务拆分后：每个子系统需要单独的库； （2） 如果单独的库太大，可以根据业务特性，进行再次分库，比如商品分类库，产品库； （3） 分库后，如果表中有数据量很大的，则进行分表，一般可以按照 Id，时间等进行分表；（高级的用法是一致性 Hash） （4） 在分库，分表的基础上，进行读写分离； 相关中间件可参考 Cobar（阿里，目前已不在维护），TDDL（阿里），Atlas（奇虎 360），MyCat（在 Cobar 基础上，国内很多牛人，号称国内第一开源项目）。 分库分表后序列的问题，JOIN，事务的问题，会在分库分表主题分享中，介绍。 服务化 ​将多个子系统公用的功能/模块，进行抽取，作为公用服务使用。比如本案例的会员子系统就可以抽取为公用的服务。 消息队列 ​ 消息队列可以解决子系统/模块之间的耦合，实现异步，高可用，高性能的系统。是分布式系统的标准配置。本案例中，消息队列主要应用在购物，配送环节。 （1） 用户下单后，写入消息队列，后直接返回客户端； （2） 库存子系统：读取消息队列信息，完成减库存； （3） 配送子系统：读取消息队列信息，进行配送； 目前使用较多的 MQ 有 Active MQ,Rabbit MQ,Zero MQ，MS MQ 等，需要根据具体的业务场景进行选择。建议可以研究下 Rabbit MQ。 其他架构（技术） 除了以上介绍的业务拆分，应用集群，多级缓存，单点登录，数据库集群，服务化，消息队列外。还有 CDN，反向代理，分布式文件系统，大数据处理等系统。 此处不详细介绍，大家可以问度娘/Google，有机会的话也可以分享给大家。 2.5. 架构总结 以上是本次分享的架构总结，其中细节可参考前面分享的内容。其中还有很多可以优化和细化的地方，因为是案例分享，主要针对重要部分做了介绍，工作中需要大家根据具体的业务场景进行架构设计。 以上是电商网站架构案例的分享一共有三篇，从电商网站的需求，到单机架构，逐步演变为常用的，可供参考的分布式架构的原型。除具备功能需求外，还具备一定的高性能，高可用，可伸缩，可扩展等非功能质量需求（架构目标）。 3. 资料 大型分布式网站架构技术总结 大型网站架构系列：电商网站架构案例(1) 大型网站架构系列：电商网站架构案例(2) 大型网站架构系列：电商网站架构案例(3)]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大型网站架构概述]]></title>
    <url>%2Fblog%2F2018%2F07%2F05%2Fdesign%2Farchitecture%2F%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[大型网站架构概述 📓 本文已归档到：「blog」 1. 大型网站系统的特点 2. 大型网站架构演化历程 2.1. 初始阶段架构 2.2. 应用服务和数据服务分离 2.3. 使用缓存改善性能 2.4. 使用应用服务器集群 2.5. 数据库读写分离 2.6. 反向代理和 CDN 加速 2.7. 分布式文件系统和分布式数据库 2.8. 使用 NoSQL 和搜索引擎 2.9. 业务拆分 2.10. 分布式服务 3. 大型网站架构模式 3.1. 分层 3.2. 分割 3.3. 分布式 3.4. 集群 3.5. 缓存 3.6. 异步 3.7. 冗余 3.8. 自动化 3.9. 安全 4. 大型网站核心架构要素 4.1. 性能 4.2. 可用性 4.3. 伸缩性 4.4. 扩展性 4.5. 安全性 5. 资料 1. 大型网站系统的特点 高并发、大流量 高可用 海量数据 用户分布广泛，网络情况复杂 安全环境恶劣 需求快速变更，迭代频繁 渐进式发展 2. 大型网站架构演化历程 2.1. 初始阶段架构 问题：网站运营初期，访问用户少，一台服务器绰绰有余。 特征：应用程序、数据库、文件等所有的资源都在一台服务器上。 描述：通常服务器操作系统使用 linux，应用程序使用 PHP 开发，然后部署在 Apache 上，数据库使用 Mysql，通俗称为 LAMP。汇集各种免费开源软件以及一台廉价服务器就可以开始系统的发展之路了。 2.2. 应用服务和数据服务分离 问题：越来越多的用户访问导致性能越来越差，越来越多的数据导致存储空间不足，一台服务器已不足以支撑。 特征：应用服务器、数据库服务器、文件服务器分别独立部署。 描述：三台服务器对性能要求各不相同：应用服务器要处理大量业务逻辑，因此需要更快更强大的 CPU；数据库服务器需要快速磁盘检索和数据缓存，因此需要更快的硬盘和更大的内存；文件服务器需要存储大量文件，因此需要更大容量的硬盘。 2.3. 使用缓存改善性能 问题：随着用户逐渐增多，数据库压力太大导致访问延迟。 特征：由于网站访问和财富分配一样遵循二八定律：80% 的业务访问集中在 20% 的数据上。将数据库中访问较集中的少部分数据缓存在内存中，可以减少数据库的访问次数，降低数据库的访问压力。 描述：缓存分为两种：应用服务器上的本地缓存和分布式缓存服务器上的远程缓存，本地缓存访问速度更快，但缓存数据量有限，同时存在与应用程序争用内存的情况。分布式缓存可以采用集群方式，理论上可以做到不受内存容量限制的缓存服务。 2.4. 使用应用服务器集群 问题：使用缓存后，数据库访问压力得到有效缓解。但是单一应用服务器能够处理的请求连接有限，在访问高峰期，成为瓶颈。 特征：多台服务器通过负载均衡同时向外部提供服务，解决单一服务器处理能力和存储空间不足的问题。 描述：使用集群是系统解决高并发、海量数据问题的常用手段。通过向集群中追加资源，提升系统的并发处理能力，使得服务器的负载压力不再成为整个系统的瓶颈。 2.5. 数据库读写分离 问题：网站使用缓存后，使绝大部分数据读操作访问都可以不通过数据库就能完成，但是仍有一部分读操作和全部的写操作需要访问数据库，在网站的用户达到一定规模后，数据库因为负载压力过高而成为网站的瓶颈。 特征：目前大部分的主流数据库都提供主从热备功能，通过配置两台数据库主从关系，可以将一台数据库服务器的数据更新同步到一台服务器上。网站利用数据库的主从热备功能，实现数据库读写分离，从而改善数据库负载压力。 描述：应用服务器在写操作的时候，访问主数据库，主数据库通过主从复制机制将数据更新同步到从数据库。这样当应用服务器在读操作的时候，访问从数据库获得数据。为了便于应用程序访问读写分离后的数据库，通常在应用服务器端使用专门的数据访问模块，使数据库读写分离的对应用透明。 2.6. 反向代理和 CDN 加速 问题：中国网络环境复杂，不同地区的用户访问网站时，速度差别也极大。 特征：采用 CDN 和反向代理加快系统的静态资源访问速度。 描述：CDN 和反向代理的基本原理都是缓存，区别在于 CDN 部署在网络提供商的机房，使用户在请求网站服务时，可以从距离自己最近的网络提供商机房获取数据；而反向代理则部署在网站的中心机房，当用户请求到达中心机房后，首先访问的服务器时反向代理服务器，如果反向代理服务器中缓存着用户请求的资源，就将其直接返回给用户。 2.7. 分布式文件系统和分布式数据库 问题：随着大型网站业务持续增长，数据库经过读写分离，从一台服务器拆分为两台服务器，依然不能满足需求。 特征：数据库采用分布式数据库，文件系统采用分布式文件系统。 描述：分布式数据库是数据库拆分的最后方法，只有在单表数据规模非常庞大的时候才使用。不到不得已时，更常用的数据库拆分手段是业务分库，将不同的业务数据库部署在不同的物理服务器上。 2.8. 使用 NoSQL 和搜索引擎 问题：随着网站业务越来越复杂，对数据存储和检索的需求也越来越复杂。 特征：系统引入 NoSQL 数据库及搜索引擎。 描述：NoSQL 数据库及搜索引擎对可伸缩的分布式特性具有更好的支持。应用服务器通过统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。 2.9. 业务拆分 问题：大型网站的业务场景日益复杂，分为多个产品线。 特征：采用分而治之的手段将整个网站业务分成不同的产品线。系统上按照业务进行拆分改造，应用服务器按照业务区分进行分别部署。 描述：应用之间可以通过超链接建立关系，也可以通过消息队列进行数据分发，当然更多的还是通过访问同一个数据存储系统来构成一个关联的完整系统。 纵向拆分：将一个大应用拆分为多个小应用，如果新业务较为独立，那么就直接将其设计部署为一个独立的 Web 应用系统。纵向拆分相对较为简单，通过梳理业务，将较少相关的业务剥离即可。 横向拆分：将复用的业务拆分出来，独立部署为分布式服务，新增业务只需要调用这些分布式服务横向拆分需要识别可复用的业务，设计服务接口，规范服务依赖关系。 2.10. 分布式服务 问题：随着业务越拆越小，存储系统越来越庞大，应用系统整体复杂程度呈指数级上升，部署维护越来越困难。由于所有应用要和所有数据库系统连接，最终导致数据库连接资源不足，拒绝服务。 特征：公共业务提取出来，独立部署。由这些可复用的业务连接数据库，通过分布式服务提供共用业务服务。 3. 大型网站架构模式 3.1. 分层 大型网站架构中常采用分层结构，将软件系统分为应用层、服务层、数据层： 应用层 - 负责具体业务和视图展示。如网站首页及搜索输入和结果展示。 服务层 - 为应用层提供服务支持。如用户管理服务、购物车服务等。 应用层 - 提供数据存储访问服务。如数据库、缓存、文件、搜索引擎等。 分层架构的约束：禁止跨层次的调用（应用层直接调用数据层）及逆向调用（数据层调用服务层，或者服务层调用应用层）。 分层结构内部还可以继续分层，如应用可以再细分为视图层和业务逻辑层；服务层也可以细分为数据接口层和逻辑处理层。 3.2. 分割 将不同的功能和服务分割开来，包装成高内聚低耦合的模块单元。这有助于软件的开发和维护，便于不同模块的分布式部署，提高网站的并发处理能力和功能扩展能力。 3.3. 分布式 大于大型网站，分层和分割的一个主要目的是为了切分后的模块便于分布式部署，即将不同模块部署在不同的服务器上，通过远程调用协同工作。 分布式意味可以用更多的机器工作，那么 CPU、内存、存储资源也就更丰富，能够处理的并发访问和数据量就越大，进而能够为更多的用户提供服务。 分布式也引入了一些问题： 服务调用必须通过网络，网络延迟会影响性能 服务器越多，宕机概率也越大，是可用性降低 数据一致性非常困难，分布式事务也难以保证 网站依赖错综复杂，开发管理维护困难 常用的分布式方案： 分布式应用和服务 分布式静态资源 分布式数据和存储 分布式计算 3.4. 集群 集群即多台服务器部署相同应用构成一个集群，通过负载均衡设备共同对外提供服务。 集群需要具备伸缩性和故障转移机制：伸缩性是指可以根据用户访问量向集群添加或减少机器；故障转移是指，当某台机器出现故障时，负载均衡设备或失效转移机制将请求转发到集群中的其他机器上，从而不影响用户使用。 3.5. 缓存 缓存就是将数据存放在距离最近的位置以加快处理速度。缓存是改善软件性能的第一手段。 网站应用中，缓存除了可以加快数据访问速度以外，还可以减轻后端应用和数据存储的负载压力。 常见缓存手段： CDN 反向代理 本地缓存 分布式缓存 使用缓存有两个前提： 数据访问热点不均匀，频繁访问的数据应该放在缓存中 数据在某个时间段有效，不过很快过期，否则缓存数据会因已经失效而产生脏读 3.6. 异步 软件发展的一个重要目标和驱动力是降低软件耦合性。事物之间直接关系越少，彼此影响就越小，也就更容易独立发展。 大型网站架构中，系统解耦的手段除了分层、分割、分布式等，还有一个重要手段——异步。 业务间的消息传递不是同步调用，而是将一个业务操作拆分成多阶段，每个阶段间通过共享数据的方式异步执行进行协作。 在单一服务器内部可通过多线程共享内存队列的方式实现异步，处在业务操作前面的线程将操作输出到队列，后面的线程从队列中读取数据进行处理； 在分布式系统中，多个服务器集群通过分布式消息队列实现异步。 异步架构是典型的生产者消费模式，二者不存在直接调用。异步消息队列还有如下特性： 提高系统可用性 加快响应速度 消除并发访问高峰 3.7. 冗余 大型网站，出现服务器宕机是必然事件。要保证部分服务器宕机的情况下网站依然可以继续服务，不丢失数据，就需要一定程度的服务器冗余运行，数据冗余备份。这样当某台服务器宕机是，可以将其上的服务和数据访问转移到其他机器上。 访问和负载很小的服务也必须部署 至少两台服务器构成一个集群，目的就是通过冗余实现服务高可用。数据除了定期备份，存档保存，实现 冷备份 外；为了保证在线业务高可用，还需要对数据库进行主从分离，实时同步实现 热备份。 为了抵御地震、海啸等不可抗因素导致的网站完全瘫痪，某些大型网站会对整个数据中心进行备份，全球范围内部署 灾备数据中心。网站程序和数据实时同步到多个灾备数据中心。 3.8. 自动化 大型网站架构的自动化架构设计主要集中在发布运维方面： 发布过程自动化 自动化代码管理 自动化测试 自动化安全监测 自动化部署 运维自动化 自动化监控 自动化报警 自动化失效转移 自动化失效恢复 自动化降级 自动化分配资源 3.9. 安全 密码 和 手机校验码 进行身份认证 登录、交易等重要操作需要对网络通信进行 加密，存储的敏感数据如用户信息等也进行加密处理 防止机器人程序攻击网站，使用 验证码 进行识别 对常见用于 攻击 网站的 XSS 攻击、SQL 注入、进行编码转换等相应处理 对垃圾信息、敏感信息进行 过滤 对交易转账等重要操作根据交易模式和交易信息进行 风险控制 4. 大型网站核心架构要素 架构 的一种通俗说法是：最高层次的规划，难以改变的决定。 除了系统功能需求外，架构还需要关注以下架构要素： 4.1. 性能 性能问题无处不在，所以网站性能优化手段也十分繁多： 前端 浏览器缓存 静态资源压缩 合理布局页面 减少 cookie 传输 CDN 应用服务器 本地缓存 分布式缓存 异步消息队列 集群 代码层面：使用多线程、改善内存管理 数据库 索引 数据库缓存 SQL 优化 4.2. 可用性 可用性指部分服务器出现故障时，还能否对用户提供服务 冗余 通过负载均衡设备建立集群共同对外提供服务 数据存储在多台服务器，互相备份 自动化：通过预发布验证、自动化测试、自动化发布、灰度发布等手段，减少将故障引入线上环境的可能 4.3. 伸缩性 衡量伸缩的标准就是是否可以用多台服务器构建集群，是否容易向集群中增删服务器节点。增删服务器节点后是否可以提供和之前无差别的服务。集群中可容纳的总服务器数是否有限制。 应用服务器集群 - 只要服务器上保存数据，则所有服务器都是对等的，通过负载均衡设备向集群中不断加入服务器即可 缓存服务器集群 - 加入新的服务器可能会导致缓存路由失效，进而导致集群中的大部分缓存数据都无法访问。虽然缓存数据可以通过数据库重新加载，但是如果应用严重依赖缓存，可能会导致网站崩溃。需要改进缓存路由算法保证缓存数据的可访问性。 关系型数据库集群 - 关系型数据库虽然支持数据复制，主从热备等机制，但是很难做到大规模集群的可伸缩性，因此关系型数据库的集群伸缩性方案必须在数据库之外实现，通过路由分区等手段将部署有多个数据库的服务器组成一个集群。 NOSql 数据库集群 - 由于先天就是为了应对海量数据而产生，因此对伸缩性的支持通常都非常好。 4.4. 扩展性 衡量扩展性的标准就是增加新的业务产品时，是否可以实现对现有产品透明无影响，不需要任何改动或很少改动，既有功能就可以上线新产品。主要手段有：事件驱动架构和分布式服务。 4.5. 安全性 安全性保护网站不受恶意攻击，保护网站重要数据不被窃取。 5. 资料 大型网站技术架构]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站的可扩展架构]]></title>
    <url>%2Fblog%2F2018%2F07%2F05%2Fdesign%2Farchitecture%2F%E7%BD%91%E7%AB%99%E7%9A%84%E5%8F%AF%E6%89%A9%E5%B1%95%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[网站的可扩展架构 📓 本文已归档到：「blog」 1. 构建可扩展的网站架构 2. 利用分布式消息队列降低系统耦合性 2.1. 事件驱动架构 2.2. 分布式消息队列 3. 利用分布式服务打造可复用的业务平台 4. 可扩展的数据结构 5. 资料 扩展性（Extensibility） - 指对现有系统影响最小的情况下，系统功能可持续扩展或提升的能力。表现在系统基础设施稳定不需要经常变更，应用之间较少依赖和耦合，对需求变更可以敏捷响应。它是系统架构设计层面的开闭原则（对扩展开放、对修改关闭），架构设计考虑未来功能扩展，当系统增加新功能时，不需要对现有系统的结构和代码进行修改。 伸缩性（Scalability） - 指系统能够通过增加减少自身资源规模的方式增减自己计算处理事务的能力。如果这种增减是成比例的，就被称作线性伸缩性。在网站架构中 ，通常指利用集群的方式增加服务器数量、提高系统的整体事务吞吐能力。 1. 构建可扩展的网站架构 低耦合的系统更容易扩展、复用。 设计网站可扩展架构的核心思想是模块化，并在此基础上，降低模块间的耦合性，提高模块的复用性。 分层和分割不仅可以进行架构伸缩，也是模块化设计的重要手段，利用分层和分割的方式将软件分割为若干个低耦合的独立的组件模块，这些组件模块以消息传递及依赖调用的方式聚合成一个完整的系统。 在大型网站中，这些模块通过分布式部署的方式，独立的模块部署在独立的服务器上，从物理上分离模块间的耦合关系，进一步降低耦合性提高复用性。 2. 利用分布式消息队列降低系统耦合性 2.1. 事件驱动架构 事件驱动架构通过在低耦合的模块间传输事件消息，以保持模块的松散耦合，并借助事件消息的通信完成模块间合作。典型的事件驱动架构就是操作系统中常见的生产者消费者模式。在大型网站中，最常见的实现手段就是分布式消息队列。 2.2. 分布式消息队列 消息生产者应用程序通过远程访问接口将消息推送给消息队列服务器，消息队列服务器将消息写入本地内存队列后立即返回成功响应给消息生产者。消息队列服务器根据消息订阅列表查找订阅该消息的消息消费者应用程序，将消息队列中的消息按照先进先出（FIFO）的原则将消息通过远程通信接口发送给消息消费者程序。 在伸缩性方面，由于消息队列服务器上的数据可以看作是即时处理的，因此类似于无状态的服务器，伸缩性设计比较简单。将新服务器加入分布式消息队列集群中，通知生产者服务器更改消息队列服务器列表即可。 在可用性方面，为了避免消费者进程处理缓慢，分布式消息队列服务器内存空间不足造成的问题，如果内存队列已满，会将消息写入磁盘，消息推送模块在将内存队列消息处理完成以后，将磁盘内容加载到内存队列继续处理。 3. 利用分布式服务打造可复用的业务平台 分布式服务则通过接口分解系统耦合性，不同子系统通过相同的接口描述进行服务调用。 大型网站分布式服务的需求与特点： 负载均衡 失效转移 高效的远程通信 整合异构系统 对应用最少侵入 版本管理 实时监控 4. 可扩展的数据结构 传统的关系型数据库为了保证关系运算的正确性，在设计数据库表结构的时候，就需要指定表的 schema ——字段名称，数据类型等，并要遵循特定的设计范式。这些规范带来一个问题：难以面对需求变更带来的挑战，所以有人通过预先设计一些冗余字段来应对。 许多 NoSql 数据库使用 ColumnFamily 设计来设计可扩展的数据结构。 5. 资料 大型网站技术架构]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站典型故障]]></title>
    <url>%2Fblog%2F2018%2F07%2F05%2Fdesign%2Farchitecture%2F%E7%BD%91%E7%AB%99%E5%85%B8%E5%9E%8B%E6%95%85%E9%9A%9C%2F</url>
    <content type="text"><![CDATA[网站典型故障 📓 本文已归档到：「blog」 1. 海量日志耗尽磁盘空间引发的故障 2. 高并发访问数据库引发的故障 3. 高并发情况下锁引发的故障 4. 缓存引发的故障 5. 应用启动不同步引发的故障 6. 大文件读写独占磁盘引发的故障 7. 资料 1. 海量日志耗尽磁盘空间引发的故障 现象：应用发布后，硬盘空间低于警戒值，服务器宕机。 分析：应用部署在服务器上，不断打印日志，但不定期清理日志，导致磁盘空间最终被耗尽。 总结： 应用自身的日志和第三方组件日志应分别配置。 日志输出级别不要设置太低，导致打印很多无关痛痒的信息。 2. 高并发访问数据库引发的故障 现象：数据库负载居高不下。 分析：某条 sql 执行频率非常高，追查发现，被网站首页调用。 总结：首页不应该访问数据库。 3. 高并发情况下锁引发的故障 现象：应用不定时地因为响应超时而报警，但是很快又超时接触，恢复正常。 分析：某个单例对象中多处使用了 synchronized，由于 this 对象只有一个，所有的并发请求都要排队获得者唯一的一把锁。 总结：使用锁操作要谨慎。 4. 缓存引发的故障 现象：没有新应用发布，但是数据库突然负载飙升，并很快失去响应。 分析：缓存服务器管理失当。 总结：当网站架构对缓存依赖性很强时，应该重视对缓存服务的管理。 5. 应用启动不同步引发的故障 现象：某应用发布后，服务器立即崩溃。 分析：后台服务还没准备好，前台应用就开始接受请求，导致故障。 总结：发布脚本中不断用 curl 命令访问后台应用特定页面，直到收到 OK，再启动前台应用。 6. 大文件读写独占磁盘引发的故障 现象：上传图片非常慢。 分析：文件存储最有可能出错的地方是存储服务器。检查发现，大部分文件大小比较小，少数几个文件非常大，读写大文件比较耗时，在这个读写时间内，磁盘基本被大文件操作独占，导致其他用户的文件操作缓慢。 总结：文件存储下需要根据不同文件类型和用途进行管理。 7. 资料 大型网站技术架构]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式架构]]></title>
    <url>%2Fblog%2F2018%2F07%2F05%2Fdesign%2Farchitecture%2F%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[分布式架构 📓 本文已归档到：「blog」 分布式架构的演进 分布式架构的问题 分布式架构的关键技术 消息队列 服务化 服务总线 分布式架构的通信模式 request/response 模式（同步模式） Callback（异步模式） Future 模式 Oneway 模式 Reliable 模式 资料 分布式架构的演进 分布式架构的问题 当服务越来越多时，服务 URL 配置管理变得非常困难，F5 硬件负载均衡器的单点压力也越来越大。 当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。 接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？ 服务多了，沟通成本也开始上升，调某个服务失败该找谁？服务的参数都有什么约定？ 一个服务有多个业务消费者，如何确保服务质量？ 随着服务的不停升级，总有些意想不到的事发生，比如 cache 写错了导致内存溢出，故障不可避免，每次核心服务一挂，影响一大片，人心慌慌，如何控制故障的影响面？服务是否可以功能降级？或者资源劣化？ 分布式架构的关键技术 消息队列 消息队列通过消息对象分解系统耦合性，不同子系统处理同一个消息。 消息队列框架 消息队列原理 服务化 服务框架通过接口分解系统耦合性，不同子系统通过相同的接口描述进行服务启用。 服务框架是一个点对点模型。 服务框架面向同构系统。 适合：移动应用、互联网应用、外部系统。 服务化框架 服务化原理 服务治理 服务治理是服务框架/服务总线的核心功能。所谓服务治理，是指服务的提供方和消费方达成一致的约定，保证服务的高质量。服务治理功能可以解决将某些特定流量引入某一批机器，以及限制某些非法消费者的恶意访问，并在提供者处理量达到一定程度是，拒绝接受新的访问。 当前比较流行的服务治理框架：Dubbo。 服务总线 服务总线同服务框架一样，均是通过接口分解系统耦合性，不同子系统通过相同的接口描述进行服务启用。 服务总线是一个总线式的模型。 服务总线面向同构、异构系统。 适合：内部系统。 服务总线框架 服务总线原理 分布式架构的通信模式 request/response 模式（同步模式） 客户端发起请求一直阻塞到服务端返回请求为止。 Callback（异步模式） 客户端发送一个 RPC 请求给服务器，服务端处理后再发送一个消息给消息发送端提供的 callback 端点，此类情况非常合适以下场景：A 组件发送 RPC 请求给 B，B 处理完成后，需要通知 A 组件做后续处理。 Future 模式 客户端发送完请求后，继续做自己的事情，返回一个包含消息结果的 Future 对象。客户端需要使用返回结果时，使用 Future 对象的.get(),如果此时没有结果返回的话，会一直阻塞到有结果返回为止。 Oneway 模式 客户端调用完继续执行，不管接收端是否成功。 Reliable 模式 为保证通信可靠，将借助于消息中心来实现消息的可靠送达，请求将做持久化存储，在接收方在线时做送达，并由消息中心保证异常重试。 资料 https://www.zhihu.com/question/22764869/answer/31277656]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站的伸缩性架构]]></title>
    <url>%2Fblog%2F2018%2F07%2F05%2Fdesign%2Farchitecture%2F%E7%BD%91%E7%AB%99%E7%9A%84%E4%BC%B8%E7%BC%A9%E6%80%A7%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[网站的伸缩性架构 📓 本文已归档到：「blog」 1. 网站架构的伸缩性设计 1.1. 不同功能进行物理分离实现伸缩 1.2. 单一功能通过集群规模实现伸缩 2. 应用服务器集群的伸缩性设计 2.1. HTTP 重定向负载均衡 2.2. DNS 域名解析负载均衡 2.3. 反向代理负载均衡 2.4. IP 负载均衡 2.5. 数据链路层负载均衡 2.6. 负载均衡算法 3. 分布式缓存集群的伸缩性设计 4. 数据存储服务器集群的伸缩性设计 4.1. 关系型数据库的伸缩性设计 4.2. NoSql 数据库的伸缩性设计 5. 资料 1. 网站架构的伸缩性设计 1.1. 不同功能进行物理分离实现伸缩 纵向分离（分层后分离）：将业务处理流程上的不同部分分离部署，实现系统伸缩性。 横向分离（业务分割后分离）：将不同的业务模块分离部署，实现系统伸缩性。 1.2. 单一功能通过集群规模实现伸缩 将不同功能分离部署可以实现一定程度的伸缩性，但是随着网站的访问量逐步增加，即使分离到最小粒度的独立部署，单一的服务器也不能满足业务规模的要求。因此必须使用服务器集群，即将相同服务部署在多态服务器上构成一个集群整体对外提供服务。 2. 应用服务器集群的伸缩性设计 2.1. HTTP 重定向负载均衡 利用 HTTP 重定向协议实现负载均衡。 这种负载均衡方案的优点是比较简单。缺点是浏览器需要两次请求服务器才能完成一次访问，性能较差：重定向服务器自身的处理能力有可能成为瓶颈，整个集群的伸缩性规模有限；使用 HTTP 302 响应码重定向，可能使搜索引擎判断为 SEO 作弊，降低搜索排名。 2.2. DNS 域名解析负载均衡 利用 DNS 处理域名解析请求的同时进行负载均衡处理的一种方案。 在 DNS 服务器中配置多个 A 记录，如： 114.100.40.1 www.mysite.com114.100.40.2 www.mysite.com114.100.40.3 www.mysite.com 每次域名解析请求都会根据负载均衡算法计算一个不同的 IP 地址返回，这样 A 记录中配置的多个服务器就构成一个集群，并可以实现负载均衡。 DNS 域名解析负载均衡的优点： 将负载均衡的工作转交给了 DNS，省掉了网站管理维护的麻烦。 同时，许多 DNS 服务器还支持基于地理位置的域名解析，即将域名解析成距离用户地理最近的一个服务器地址，这样可以加快用户访问速度，改善性能。 DNS 域名解析负载均衡的缺点： DNS 是多级解析，每一级 DNS 都可能缓存 A 记录，当某台服务器下线后，即使修改了 DNS 的 A 记录，要使其生效也需要较长时间。这段时间，依然会域名解析到已经下线的服务器，导致用户访问失败。 DNS 的负载均衡的控制权在域名服务商那里，网站无法对其做更多改善和更强大的管理。 2.3. 反向代理负载均衡 大多数反向代理服务器同时提供反向代理和负载均衡的功能。 反向代理服务器的优点是部署简单。缺点是反向代理服务器时所有请求和响应的中转站，其性能可能会成为瓶颈。 2.4. IP 负载均衡 在网络层通过修改请求目标地址进行负载均衡。负载均衡服务器（网关服务器）在操作系统内核获取网络数据包，根据负载均衡算法计算得到一台真实 Web 服务器 10.0.0.1，然后将目的 IP 地址修改为 10.0.0.1，不需要通过用户进程。真实 Web 服务器处理完成后，响应数据包回到负载均衡服务器，负载均衡服务器再将数据包原地址修改为自身的 IP 地址（114.100.80.10）发送给浏览器。 IP 负载均衡在内核完成数据分发，所以处理性能优于反向代理负载均衡。但是因为所有请求响应都要经过负载均衡服务器，集群的最大响应数据吞吐量受制于负载均衡服务器网卡带宽。 2.5. 数据链路层负载均衡 数据链路层负载均衡是指在通信协议的数据链路层修改 mac 地址进行负载均衡。 这种方式又称作三角传输方式，负载均衡数据分发过程中不修改 IP 地址，只修改目的 mac 地址，通过配置真实物理服务器集群所有机器虚拟 IP 和负载均衡服务器 IP 地址一致，从而达到不修改数据包的源地址和目的地址就可以进行数据分发的目的，由于实际处理请求的真实物理服务器 IP 和数据请求目的 IP 一致，不需要通过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。这种负载方式又称作直接路由方式。 在 Linux 平台上最好的链路层负载均衡开源产品是 LVS(Linux Virtual Server)。 2.6. 负载均衡算法 负载均衡服务器的实现可以分为两个部分： 根据负载均衡算法和 Web 服务器列表计算得到集群中一台 Web 服务器的地址。 将请求数据发送到该地址对应的 Web 服务器上。 负载均衡算法通常有以下几种： 轮询（Round Robin） - 所有请求被依次分发到每台应用服务器上，即每台服务器需要处理的请求数据都相同，适合于所有服务器硬件都相同的场景。 加权轮询（Weighted Round Robin） - 根据服务器硬件性能情况，在轮询的基础上，按照配置权重将请求分发到每个服务器，高性能服务器能分配更多请求。 随机（Random） - 请求被随机分配到各个应用服务器，在许多场合下，这种方案都很简单实用，因为好的随机数本身就很平均，即使应用服务器硬件配置不同，也可以使用加权随机算法。 最少连接（Least Connection） - 记录每个应用服务器正在处理的连接数，将新到的请求分发到最少连接的服务器上，应该说，这是最符合负载均衡定义的算法。 源地址 Hash（Source Hash） - 根据请求来源的 IP 地址进行 Hash 计算，得到应用服务器，这样来自同一个 IP 地址的请求总在同一个服务器上处理，该请求的上下文信息可以存储在这台服务器上，在一个会话周期内重复使用，从而实现会话粘滞。 3. 分布式缓存集群的伸缩性设计 一致性 HASH 算法 4. 数据存储服务器集群的伸缩性设计 4.1. 关系型数据库的伸缩性设计 主从复制 - 主流关系型数据库一般都支持主从复制。 分库 - 根据业务对数据库进行分割。制约条件是跨库的表不能进行 Join 操作。 分表 - 使用数据库分片中间件，如 Cobar 等。 4.2. NoSql 数据库的伸缩性设计 一般而言，Nosql 不支持 SQL 和 ACID，但是强化了对于高可用和伸缩性的支持。 5. 资料 大型网站技术架构]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站的高可用架构]]></title>
    <url>%2Fblog%2F2018%2F07%2F05%2Fdesign%2Farchitecture%2F%E7%BD%91%E7%AB%99%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[网站的高可用架构 📓 本文已归档到：「blog」 1. 网站可用性的度量 2. 高可用的网站架构 3. 高可用的应用 3.1. 通过负载均衡进行无状态服务的失效转移 3.2. 应用服务器集群的 Session 管理 4. 高可用的服务 5. 高可用的数据 5.1. CAP 原理 5.2. 数据备份 5.3. 失效转移 6. 高可用网站的软件质量保证 7. 网站监控 8. 资料 1. 网站可用性的度量 网站不可用也被称作网站故障，业界通常用多个 9 来衡量网站的可用性。如 QQ 的可用性为 4 个 9，即 99.99% 可用。 网站不可用时间 = 故障修复时间点 - 故障发现时间点网站年度可用性指标 = (1 - 网站不可用时间/年度总时间) * 100% 2. 高可用的网站架构 大型网站的分层架构及服务器的分布式部署使得位于不同层次的服务器具有不同的可用性特点。关闭服务或服务器宕机时产生的影响也不相同，高可用的解决方案也差异甚大。 3. 高可用的应用 3.1. 通过负载均衡进行无状态服务的失效转移 应用层主要处理网站应用的业务逻辑，一个显著的特点是应用的 无状态 性。 所谓的 无状态 的应用是指应用服务器不保存业务的上下文信息，而仅根据每次请求提交的数据进行相应的业务逻辑处理，多个服务实例之间完全对等，请求提交到任意服务器，处理结果都是完全一样的。 负载均衡，顾名思义，主要使用在业务量和数据量较高的情况下，当单台服务器不足以承担所有的负载压力时，通过负载均衡手段，将流量和数据分摊到一个集群组成的多台服务器上，以提高整体的负载处理能力。 3.2. 应用服务器集群的 Session 管理 应用服务器的高可用架构设计主要基于服务无状态这一特性。事实上，业务总是有状态的，如购物车记录用户的购买信息；用户的登录状态；最新发布的消息等等。 Web 应用中将这些多次请求修改使用的上下文对象称作会话。单机情况下，Session 可由部署在服务器上的 Web 容器管理。 而在集群环境下，Session 管理有以下手段： Session 复制 Session 复制是指应用服务器开发 Web 容器的 Session 复制功能，在集群中的几台服务器之间同步 Session 对象。 这种方案很简单，但当集群规模较大时，集群服务间需要大量的通信来进行 Session 复制。 Session 绑定 可以利用负载均衡的源地址 Hash 算法实现，总是将来源于同一 IP 的请求分发到同一台服务器上。这样在整个会话期间，用户所有的请求都在同一台服务器上处理，即 Session 绑定到某台特定服务器上。这种方法又被称作会话粘滞。 但是这种策略不符合高可用的需求，因为一旦某台服务器宕机，那么该机器上的 Session 也就不复存在了。 利用 Cookie 记录 Session 可以将 Session 记录在客户端（浏览器 Cookie），每次请求服务器时，将 Session 放在请求中发送给服务器，服务器处理完请求后再将修改过的 Session 响应给客户端。 这种策略的缺点是：Cookie 有大小限制，能记录的信息有限；每次请求响应都需要传输 Cookie，影响性能；如果用户关闭 Cookie，访问就不能工作。 Session 服务器 利用独立部署的 Session 服务器（集群）统一管理 Session，应用服务器每次读写 Session 时，都访问 Session 服务器。 实现 Session 服务器的一种简单方法时：利用分布式缓存、数据库等，在此基础上进行包装，使其符合 Session 的存储和访问要求。 4. 高可用的服务 高可用的服务策略： 分级管理 - 将服务根据业务重要性进行分级管理，并在服务部署上进行隔离。 超时设置 - 由于服务器宕机、线程死锁等原因，可能导致应用程序对服务端的调用失去响应。所以有必要引入超时机制，一旦调用超时，服务化框架抛出异常，应用程序根据服务调度策略，选择重试或请求转移到其他机器上。 异步调用 - 对于需要即时响应的业务，应用在调用服务时可以通过消息队列等异步方式完成，避免长时间等待服务响应结果。 服务降级 - 网站访问高峰期，服务可能因为大量并发调用而性能下降，严重时可能会导致宕机。为了保证核心功能的正常运行，需要对服务进行降级。降级有两种手段：拒绝服务和关闭服务。 幂等性设计 - 为了避免服务重复调用，可以通过设置编号的方式进行服务调用有效性校验，有效的操作才能继续执行。 5. 高可用的数据 5.1. CAP 原理 分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容忍性（P：Partition Tolerance），最多只能同时满足其中两项。 可用性 可用性指分布式系统在面对各种异常时可以提供正常服务的能力，可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。 在可用性条件下，系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。 分区容忍性 网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。 在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。 一致性 一致性指的是多个数据副本是否能保持一致的特性。 在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。 数据一致性又可以分为以下几点： 强一致性 - 数据更新操作结果和操作响应总是一致的，即操作响应通知更新失败，那么数据一定没有被更新，而不是处于不确定状态。 最终一致性 - 即物理存储的数据可能是不一致的，终端用户访问到的数据可能也是不一致的，但系统经过一段时间的自我修复和修正，数据最终会达到一致。 权衡 在分布式系统中，分区容忍性必不可少，因为需要总是假设网络是不可靠的。因此，CAP 理论实际在是要在可用性和一致性之间做权衡。 可用性和一致性往往是冲突的，很难都使它们同时满足。在多个节点之间进行数据同步时， 为了保证一致性（CP），就需要让所有节点下线成为不可用的状态，等待同步完成； 为了保证可用性（AP），在同步过程中允许读取所有节点的数据，但是数据可能不一致。 5.2. 数据备份 冷备份：定期将数据复制到某种存储介质。 热备份 异步热备方式 - 异步方式是指多份数据副本的写入操作异步完成，应用程序收到数据服务系统的写操作成功响应时，只写成功了一份，存储系统将会异步地写其他副本。 同步热备方式 - 同步方式是指多份数据副本的写入操作同步完成，即应用程序收到数据服务系统的写成功响应时，多份数据都已经写操作成功。但是当应用程序收到数据写操作失败的响应式，可能有部分副本或者全部副本都已经写入成功了（因为网络或者系统故障，无法返回操作成功的响应）。 5.3. 失效转移 失效确认 判断服务器宕机的手段有两种：心跳检测和访问失败报告。 对于应用程序的访问失败报告，控制中心还需要再一次发送心跳检测进行确认，以免错误判断服务器宕机。因为一旦进行数据访问的失效转移，意味着数据存储多份副本不一致，需要进行后续一系列的复杂动作。 访问转移 确认某台数据服务器宕机后，就需要将数据读写访问重新路由到其他服务器上。对于完全对等存储的服务器，当其中一台宕机后，应用程序根据配置直接切换到对等服务器上。如果存储不对等，就需要重新计算路由，选择存储服务器。 数据恢复 因为某台服务器宕机，所以数据存储的副本数目会减少，必须将副本的数目恢复到系统设定的值，否则，再有服务器宕机时，就可能出现无法访问转移，数据永久丢失的情况。因此系统需要从健康的服务器复制数据，将数据副本数目恢复到设定值。 6. 高可用网站的软件质量保证 高可用网站的软件质量保证的手段： 自动化发布 自动化测试 预发布验证 代码控制 灰度发布 7. 网站监控 监控数据采集 用户行为日志收集 服务器性能监控 运行数据报告 监控管理 系统报警 失效转移 自动优雅降级 8. 资料 大型网站技术架构]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站的安全架构]]></title>
    <url>%2Fblog%2F2018%2F07%2F05%2Fdesign%2Farchitecture%2F%E7%BD%91%E7%AB%99%E7%9A%84%E5%AE%89%E5%85%A8%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[网站的安全架构 📓 本文已归档到：「blog」 关键词：XSS、CSRF、SQL 注入、DoS、消息摘要、加密算法、证书 1. 网站安全的攻与防 1.1. 跨站脚本攻击（XSS） 1.2. 跨站请求伪造（CSRF） 1.3. SQL 注入攻击 1.4. 拒绝服务攻击（DoS） 2. 加密技术及密钥安全管理 2.1. 消息摘要 2.2. 加密算法 2.3. 证书 3. 资料 1. 网站安全的攻与防 互联网环境鱼龙混杂，网站被攻击是常见现象，所以了解一些常见的网站攻击手段十分必要。下面列举比较常见的 4 种攻击手段： 1.1. 跨站脚本攻击（XSS） 概念 跨站脚本攻击（Cross-Site Scripting, XSS），是一种网站应用程序的安全漏洞攻击，是代码注入的一种。它允许恶意用户将代码注入到网页上，其他用户在观看网页时就会受到影响。这类攻击通常包含了 HTML 以及用户端脚本语言。 XSS 攻击示例： 假如有下面一个 textbox &lt;input type="text" name="address1" value="value1from"&gt; value1from 是来自用户的输入，如果用户不是输入 value1from,而是输入 &quot;/&gt;&lt;script&gt;alert(document.cookie)&lt;/script&gt;&lt;!- 那么就会变成： &lt;input type="text" name="address1" value=""/&gt;&lt;script&gt;alert(document.cookie)&lt;/script&gt;&lt;!- "&gt; 嵌入的 JavaScript 代码将会被执行。攻击的威力，取决于用户输入了什么样的脚本。 攻击手段和目的 常用的 XSS 攻击手段和目的有： 盗用 cookie，获取敏感信息。 利用植入 Flash，通过 crossdomain 权限设置进一步获取更高权限；或者利用 Java 等得到类似的操作。 利用 iframe、frame、XMLHttpRequest 或上述 Flash 等方式，以（被攻击）用户的身份执行一些管理动作，或执行一些一般的如发微博、加好友、发私信等操作。 利用可被攻击的域受到其他域信任的特点，以受信任来源的身份请求一些平时不允许的操作，如进行不当的投票活动。 在访问量极大的一些页面上的 XSS 可以攻击一些小型网站，实现 DDoS 攻击的效果。 应对手段 过滤特殊字符 - 将用户所提供的内容进行过滤，从而避免 HTML 和 Jascript 代码的运行。如 &gt; 转义为 &amp;gt、&lt; 转义为 &amp;lt 等，就可以防止大部分攻击。为了避免对不必要的内容错误转移，如 3&lt;5 中的 &lt; 需要进行文本匹配后再转移，如：&lt;img src= 这样的上下文中的 &lt; 才转义。 设置 Cookie 为 HttpOnly - 设置了 HttpOnly 的 Cookie 可以防止 JavaScript 脚本调用，就无法通过 document.cookie 获取用户 Cookie 信息。 👉 参考阅读： Wiki 词条 - 跨站脚本 Web 安全测试之 XSS 1.2. 跨站请求伪造（CSRF） 概念 跨站请求伪造（Cross-site request forgery，CSRF），也被称为 one-click attack 或者 session riding，通常缩写为 CSRF 或者 XSRF。它 是一种挟制用户在当前已登录的 Web 应用程序上执行非本意的操作的攻击方法。和跨站脚本（XSS）相比，XSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户网页浏览器的信任。 攻击手段和目的 可以如此理解 CSRF：攻击者盗用了你的身份，以你的名义发送恶意请求。 CSRF 能做的事太多： 以你名义发送邮件，发消息 用你的账号购买商品 用你的名义完成虚拟货币转账 泄露个人隐私 … 应对手段 表单 Token - CSRF 是一个伪造用户请求的操作，所以需要构造用户请求的所有参数才可以。表单 Token 通过在请求参数中添加随机数的办法来阻止攻击者获得所有请求参数。 验证码 - 请求提交是，需要用户输入验证码，以避免用户在不知情的情况下被攻击者伪造请求。 Referer check - HTTP 请求头的 Referer 域中记录着请求资源，可通过检查请求来源，验证其是否合法。 👉 参考阅读： Wiki 词条 - 跨站请求伪造 浅谈 CSRF 攻击方式 「每日一题」CSRF 是什么？「每日一题」CSRF 是什么？ WEB 安全之-CSRF（跨站请求伪造） 1.3. SQL 注入攻击 概念 SQL 注入攻击（SQL injection），是发生于应用程序之数据层的安全漏洞。简而言之，是在输入的字符串之中注入 SQL 指令，在设计不良的程序当中忽略了检查，那么这些注入进去的指令就会被数据库服务器误认为是正常的 SQL 指令而运行，因此遭到破坏或是入侵。 攻击示例： 考虑以下简单的登录表单： &lt;form action="/login" method="POST"&gt;&lt;p&gt;Username: &lt;input type="text" name="username" /&gt;&lt;/p&gt;&lt;p&gt;Password: &lt;input type="password" name="password" /&gt;&lt;/p&gt;&lt;p&gt;&lt;input type="submit" value="登陆" /&gt;&lt;/p&gt;&lt;/form&gt; 我们的处理里面的 SQL 可能是这样的： username:=r.Form.Get("username")password:=r.Form.Get("password")sql:="SELECT * FROM user WHERE username='"+username+"' AND password='"+password+"'" 如果用户的输入的用户名如下，密码任意 myuser' or 'foo' = 'foo' -- 那么我们的 SQL 变成了如下所示： SELECT * FROM user WHERE username='myuser' or 'foo' = 'foo' --'' AND password='xxx' 在 SQL 里面 -- 是注释标记，所以查询语句会在此中断。这就让攻击者在不知道任何合法用户名和密码的情况下成功登录了。 对于 MSSQL 还有更加危险的一种 SQL 注入，就是控制系统，下面这个可怕的例子将演示如何在某些版本的 MSSQL 数据库上执行系统命令。 sql:="SELECT * FROM products WHERE name LIKE '%"+prod+"%'"Db.Exec(sql) 如果攻击提交 a%' exec master..xp_cmdshell 'net user test testpass /ADD' -- 作为变量 prod 的值，那么 sql 将会变成 sql:="SELECT * FROM products WHERE name LIKE '%a%' exec master..xp_cmdshell 'net user test testpass /ADD'--%'" MSSQL 服务器会执行这条 SQL 语句，包括它后面那个用于向系统添加新用户的命令。如果这个程序是以 sa 运行而 MSSQLSERVER 服务又有足够的权限的话，攻击者就可以获得一个系统帐号来访问主机了。 虽然以上的例子是针对某一特定的数据库系统的，但是这并不代表不能对其它数据库系统实施类似的攻击。针对这种安全漏洞，只要使用不同方法，各种数据库都有可能遭殃。 攻击手段和目的 数据表中的数据外泄，例如个人机密数据，账户数据，密码等。 数据结构被黑客探知，得以做进一步攻击（例如 SELECT * FROM sys.tables）。 数据库服务器被攻击，系统管理员账户被窜改（例如 ALTER LOGIN sa WITH PASSWORD='xxxxxx'）。 获取系统较高权限后，有可能得以在网页加入恶意链接、恶意代码以及 XSS 等。 经由数据库服务器提供的操作系统支持，让黑客得以修改或控制操作系统（例如 xp_cmdshell &quot;net stop iisadmin&quot;可停止服务器的 IIS 服务）。 破坏硬盘数据，瘫痪全系统（例如 xp_cmdshell “FORMAT C:”）。 应对手段 使用参数化查询 - 建议使用数据库提供的参数化查询接口，参数化的语句使用参数而不是将用户输入变量嵌入到 SQL 语句中，即不要直接拼接 SQL 语句。例如使用 database/sql 里面的查询函数 Prepare 和 Query ，或者 Exec(query string, args ...interface{})。 单引号转换 - 在组合 SQL 字符串时，先针对所传入的参数作字符取代（将单引号字符取代为连续 2 个单引号字符）。 👉 参考阅读： Wiki 词条 - SQL 注入攻击 避免 SQL 注入 实例讲解 SQL 注入攻击 1.4. 拒绝服务攻击（DoS） 拒绝服务攻击（denial-of-service attack, DoS）亦称洪水攻击，是一种网络攻击手法，其目的在于使目标电脑的网络或系统资源耗尽，使服务暂时中断或停止，导致其正常用户无法访问。 当黑客使用网络上两个或以上被攻陷的电脑作为“僵尸”向特定的目标发动“拒绝服务”式攻击时，称为分布式拒绝服务攻击（distributed denial-of-service attack，缩写：DDoS attack、DDoS）。 攻击方式 带宽消耗型攻击 资源消耗型攻击 应对手段 防火墙 - 允许或拒绝特定通讯协议，端口或 IP 地址。当攻击从少数不正常的 IP 地址发出时，可以简单的使用拒绝规则阻止一切从攻击源 IP 发出的通信。 路由器、交换机 - 具有速度限制和访问控制能力。 流量清洗 - 通过采用抗 DDoS 软件处理，将正常流量和恶意流量区分开。 👉 参考阅读： 拒绝服务攻击 2. 加密技术及密钥安全管理 对于网站来说，用户信息、账户等等敏感数据一旦泄漏，后果严重，所以为了保护数据，应对这些信息进行加密处理。 信息加密技术一般分为： 消息摘要 加密算法 对称加密 非对称加密 证书 2.1. 消息摘要 常用数字签名算法：MD5、SHA 等。 应用场景：将用户密码以消息摘要形式保存到数据库中。 👉 参考阅读： 消息摘要 2.2. 加密算法 对称加密 对称加密指加密和解密所使用的密钥是同一个密钥。 常用对称加密算法：DES 等。 应用场景：Cookie 加密、通信机密等。 非对称加密 非对称加密指加密和解密所使用的不是同一个密钥，而是一个公私钥对。用公钥加密的信息必须用私钥才能解开；反之，用私钥加密的信息只有用公钥才能解开。 常用非对称加密算法：RSA 等。 应用场景：HTTPS 传输中浏览器使用的数字证书实质上是经过权威机构认证的非对称加密公钥。 👉 参考阅读： 加密 2.3. 密钥安全管理 保证密钥安全的方法： 把密钥和算法放在一个独立的服务器上，对外提供加密和解密服务，应用系统通过调用这个服务，实现数据的加解密。 把加解密算法放在应用系统中，密钥则放在独立服务器中，为了提高密钥的安全性，实际存储时，密钥被切分成数片，加密后分别保存在不同存储介质中。 2.3. 证书 证书可以称为信息安全加密的终极手段。公开密钥认证（英语：Public key certificate），又称公开密钥证书、公钥证书、数字证书（digital certificate）、数字认证、身份证书（identity certificate）、电子证书或安全证书，是用于公开密钥基础建设的电子文件，用来证明公开密钥拥有者的身份。此文件包含了公钥信息、拥有者身份信息（主体）、以及数字证书认证机构（发行者）对这份文件的数字签名，以保证这个文件的整体内容正确无误。 透过信任权威数字证书认证机构的根证书、及其使用公开密钥加密作数字签名核发的公开密钥认证，形成信任链架构，已在 TLS 实现并在万维网的 HTTP 以 HTTPS、在电子邮件的 SMTP 以 STARTTLS 引入并广泛应用。 众所周知，常见的应用层协议 HTTP、FTP、Telnet 本身不保证信息安全。但是加入了 SSL/TLS 加密数据包机制的 HTTPS、FTPS、Telnets 是信息安全的。 概念 传输层安全性协议（Transport Layer Security, TLS），及其前身安全套接层（Secure Sockets Layer, SSL）是一种安全协议，目的是为互联网通信，提供安全及数据完整性保障。 证书原理 SSL/TLS 协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。 这里有两个问题： （1）如何保证公钥不被篡改？ 解决方法：将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。 （2）公钥加密计算量太大，如何减少耗用的时间？ 解决方法：每一次对话（session），客户端和服务器端都生成一个&quot;对话密钥&quot;（session key），用它来加密信息。由于&quot;对话密钥&quot;是对称加密，所以运算速度非常快，而服务器公钥只用于加密&quot;对话密钥&quot;本身，这样就减少了加密运算的消耗时间。 SSL/TLS 协议的基本过程是这样的： 客户端向服务器端索要并验证公钥。 双方协商生成&quot;对话密钥&quot;。 双方采用&quot;对话密钥&quot;进行加密通信。 👉 参考阅读： 传输层安全性协议 公开密钥认证 SSL/TLS 协议运行机制的概述 3. 资料 大型网站技术架构 Wiki 词条 - 跨站脚本 Web 安全测试之 XSS Wiki 词条 - 跨站请求伪造 浅谈 CSRF 攻击方式 「每日一题」CSRF 是什么？「每日一题」CSRF 是什么？ WEB 安全之-CSRF（跨站请求伪造） Wiki 词条 - SQL 注入攻击 避免 SQL 注入 实例讲解 SQL 注入攻击 拒绝服务攻击 传输层安全性协议 公开密钥认证 SSL/TLS 协议运行机制的概述]]></content>
      <categories>
        <category>design</category>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>design</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一篇文章让你彻底掌握 python 语言]]></title>
    <url>%2Fblog%2F2018%2F06%2F28%2Fprogramming%2Fpython%2F</url>
    <content type="text"><![CDATA[一篇文章让你彻底掌握 python 语言 📓 本文已归档到：「blog」 解释器 注释 数据类型 操作符 算术运算符 比较运算符 赋值运算符 位运算符 逻辑运算符 成员运算符 身份运算符 运算符优先级 控制语句 条件语句 循环语句 函数 函数变量作用域 关键字参数 可变参数列表 返回值 异常 异常处理 抛出异常 自定义异常 面向对象 面向对象技术简介 类定义 类对象 类的方法 继承 多继承 方法重写 类属性与方法 标准库概览 操作系统接口 文件通配符 命令行参数 错误输出重定向和程序终止 字符串正则匹配 数学 Python 编程 解释器 Linux/Unix 的系统上，Python 解释器通常被安装在 /usr/local/bin/python3.4 这样的有效路径（目录）里。 我们可以将路径 /usr/local/bin 添加到您的 Linux/Unix 操作系统的环境变量中，这样您就可以通过 shell 终端输入下面的命令来启动 Python 。 在 Linux/Unix 系统中，你可以在脚本顶部添加以下命令让 Python 脚本可以像 SHELL 脚本一样可直接执行： #! /usr/bin/env python3.4 注释 Python 中的注释有三种形式： 以 # 开头 以 ''' 开始，以 ''' 结尾 以 &quot;&quot;&quot; 开始，以 &quot;&quot;&quot; 结尾 # 单行注释'''这是多行注释，用三个单引号这是多行注释，用三个单引号这是多行注释，用三个单引号'''"""这是多行注释，用三个双引号这是多行注释，用三个双引号这是多行注释，用三个双引号""" 数据类型 Python3 中有六个标准的数据类型： Numbers（数字） String（字符串） List（列表） Tuple（元组） Sets（集合） Dictionaries（字典） 操作符 Python 语言支持以下类型的运算符: 算术运算符 比较（关系）运算符 赋值运算符 逻辑运算符 位运算符 成员运算符 身份运算符 运算符优先级 算术运算符 运算符 描述 实例 + 加 - 两个对象相加 a + b 输出结果 31 - 减 - 得到负数或是一个数减去另一个数 a - b 输出结果 -11 * 乘 - 两个数相乘或是返回一个被重复若干次的字符串 a * b 输出结果 210 / 除 - x 除以 y b / a 输出结果 2.1 % 取模 - 返回除法的余数 b % a 输出结果 1 ** 幂 - 返回 x 的 y 次幂 a**b 为 10 的 21 次方 // 取整除 - 返回商的整数部分 9//2 输出结果 4 , 9.0//2.0 输出结果 4.0 比较运算符 运算符 描述 实例 == 等于 - 比较对象是否相等 (a == b) 返回 False。 != 不等于 - 比较两个对象是否不相等 (a != b) 返回 True. &gt; 大于 - 返回 x 是否大于 y (a &gt; b) 返回 False。 &lt; 小于 - 返回 x 是否小于 y。所有比较运算符返回 1 表示真，返回 0 表示假。这分别与特殊的变量 True 和 False 等价。注意，这些变量名的大写。 (a &lt; b) 返回 True。 &gt;= 大于等于 - 返回 x 是否大于等于 y。 (a &gt;= b) 返回 False。 &lt;= 小于等于 - 返回 x 是否小于等于 y。 (a &lt;= b) 返回 True。 赋值运算符 运算符 描述 实例 = 简单的赋值运算符 c = a + b 将 a + b 的运算结果赋值为 c += 加法赋值运算符 c += a 等效于 c = c + a -= 减法赋值运算符 c -= a 等效于 c = c - a *= 乘法赋值运算符 c _= a 等效于 c = c _ a /= 除法赋值运算符 c /= a 等效于 c = c / a %= 取模赋值运算符 c %= a 等效于 c = c % a **= 幂赋值运算符 c **= a 等效于 c = c ** a //= 取整除赋值运算符 c //= a 等效于 c = c // a 位运算符 运算符 描述 实例 &amp; 按位与运算符：参与运算的两个值,如果两个相应位都为 1,则该位的结果为 1,否则为 0 (a &amp; b) 输出结果 12 ，二进制解释： 0000 1100 | 按位或运算符：只要对应的二个二进位有一个为 1 时，结果位就为 1。 (a | b) 输出结果 61 ，二进制解释： 0011 1101 ^ 按位异或运算符：当两对应的二进位相异时，结果为 1 (a ^ b) 输出结果 49 ，二进制解释： 0011 0001 ~ 按位取反运算符：对数据的每个二进制位取反,即把 1 变为 0,把 0 变为 1 (~a ) 输出结果 -61 ，二进制解释： 1100 0011， 在一个有符号二进制数的补码形式。 &lt;&lt; 左移动运算符：运算数的各二进位全部左移若干位，由&quot;&lt;&lt;&quot;右边的数指定移动的位数，高位丢弃，低位补 0。 a &lt;&lt; 2 输出结果 240 ，二进制解释： 1111 0000 &gt;&gt; 右移动运算符：把&quot;&gt;&gt;“左边的运算数的各二进位全部右移若干位，”&gt;&gt;&quot;右边的数指定移动的位数 a &gt;&gt; 2 输出结果 15 ，二进制解释： 0000 1111 逻辑运算符 运算符 逻辑表达式 描述 实例 and x and y 布尔&quot;与&quot; - 如果 x 为 False，x and y 返回 False，否则它返回 y 的计算值。 (a and b) 返回 20。 or x or y 布尔&quot;或&quot; - 如果 x 是 True，它返回 x 的值，否则它返回 y 的计算值。 (a or b) 返回 10。 not not x 布尔&quot;非&quot; - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 not(a and b) 返回 False 成员运算符 运算符 描述 实例 in 如果在指定的序列中找到值返回 True，否则返回 False。 x 在 y 序列中 , 如果 x 在 y 序列中返回 True。 not in 如果在指定的序列中没有找到值返回 True，否则返回 False。 x 不在 y 序列中 , 如果 x 不在 y 序列中返回 True。 身份运算符 运算符 描述 实例 is is 是判断两个标识符是不是引用自一个对象 x is y, 如果 id(x) 等于 id(y) , is 返回结果 1 is not is not 是判断两个标识符是不是引用自不同对象 x is not y, 如果 id(x) 不等于 id(y). is not 返回结果 1 运算符优先级 运算符 描述 ** 指数 (最高优先级) ~ + - 按位翻转, 一元加号和减号 (最后两个的方法名为 +@ 和 -@) * / % // 乘，除，取模和取整除 + - 加法减法 &gt;&gt; &lt;&lt; 右移，左移运算符 &amp; 位 ‘AND’ ^ | 位运算符 &lt;= &lt; &gt; &gt;= 比较运算符 &lt;&gt; == != 等于运算符 = %= /= //= -= += *= **= 赋值运算符 is is not 身份运算符 in not in 成员运算符 not or and 逻辑运算符 控制语句 条件语句 if condition_1: statement_block_1elif condition_2: statement_block_2else: statement_block_3 循环语句 while while 判断条件： statements for for &lt;variable&gt; in &lt;sequence&gt;: &lt;statements&gt; range() for i in range(0, 10, 3) : print(i) break 和 continue break 语句可以跳出 for 和 while 的循环体。 continue 语句被用来告诉 Python 跳过当前循环块中的剩余语句，然后继续进行下一轮循环。 pass pass 语句什么都不做。它只在语法上需要一条语句但程序不需要任何操作时使用.例如: while True: pass # 等待键盘中断 (Ctrl+C) 函数 Python 定义函数使用 def 关键字，一般格式如下： def 函数名（参数列表）： 函数体 函数变量作用域 #!/usr/bin/env python3a = 4 # 全局变量def print_func1(): a = 17 # 局部变量 print("in print_func a = ", a)def print_func2(): print("in print_func a = ", a)print_func1()print_func2()print("a = ", a) 以上实例运行结果如下： in print_func a = 17in print_func a = 4a = 4 关键字参数 函数也可以使用 kwarg=value 的关键字参数形式被调用.例如,以下函数: def parrot(voltage, state='a stiff', action='voom', type='Norwegian Blue'): print("-- This parrot wouldn't", action, end=' ') print("if you put", voltage, "volts through it.") print("-- Lovely plumage, the", type) print("-- It's", state, "!") 可以以下几种方式被调用: parrot(1000) # 1 positional argumentparrot(voltage=1000) # 1 keyword argumentparrot(voltage=1000000, action='VOOOOOM') # 2 keyword argumentsparrot(action='VOOOOOM', voltage=1000000) # 2 keyword argumentsparrot('a million', 'bereft of life', 'jump') # 3 positional argumentsparrot('a thousand', state='pushing up the daisies') # 1 positional, 1 keyword 以下为错误调用方法： parrot() # required argument missingparrot(voltage=5.0, 'dead') # non-keyword argument after a keyword argumentparrot(110, voltage=220) # duplicate value for the same argumentparrot(actor='John Cleese') # unknown keyword argument 可变参数列表 最后,一个最不常用的选择是可以让函数调用可变个数的参数.这些参数被包装进一个元组(查看元组和序列).在这些可变个数的参数之前,可以有零到多个普通的参数: def arithmetic_mean(*args): sum = 0 for x in args: sum += x return sum 返回值 Python 的函数的返回值使用 return 语句，可以将函数作为一个值赋值给指定变量： def return_sum(x,y): c = x + y return c 异常 异常处理 try 语句按照如下方式工作； 首先，执行 try 子句（在关键字 try 和关键字 except 之间的语句） 如果没有异常发生，忽略 except 子句，try 子句执行后结束。 如果在执行 try 子句的过程中发生了异常，那么 try 子句余下的部分将被忽略。如果异常的类型和 except 之后的名称相符，那么对应的 except 子句将被执行。最后执行 try 语句之后的代码。 如果一个异常没有与任何的 except 匹配，那么这个异常将会传递给上层的 try 中。 不管 try 子句里面有没有发生异常，finally 子句都会执行。 import systry: f = open('myfile.txt') s = f.readline() i = int(s.strip())except OSError as err: print("OS error: &#123;0&#125;".format(err))except ValueError: print("Could not convert data to an integer.")except: print("Unexpected error:", sys.exc_info()[0]) raisefinally: # 清理行为 抛出异常 Python 使用 raise 语句抛出一个指定的异常。例如: &gt;&gt;&gt; raise NameError('HiThere')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in ?NameError: HiThere 自定义异常 可以通过创建一个新的 exception 类来拥有自己的异常。异常应该继承自 Exception 类，或者直接继承，或者间接继承。 当创建一个模块有可能抛出多种不同的异常时，一种通常的做法是为这个包建立一个基础异常类，然后基于这个基础类为不同的错误情况创建不同的子类： class Error(Exception): """Base class for exceptions in this module.""" passclass InputError(Error): """Exception raised for errors in the input. Attributes: expression -- input expression in which the error occurred message -- explanation of the error """ def __init__(self, expression, message): self.expression = expression self.message = messageclass TransitionError(Error): """Raised when an operation attempts a state transition that's not allowed. Attributes: previous -- state at beginning of transition next -- attempted new state message -- explanation of why the specific transition is not allowed """ def __init__(self, previous, next, message): self.previous = previous self.next = next self.message = message 大多数的异常的名字都以&quot;Error&quot;结尾，就跟标准的异常命名一样。 面向对象 面向对象技术简介 类(Class): 用来描述具有相同的属性和方法的对象的集合。它定义了该集合中每个对象所共有的属性和方法。对象是类的实例。 **类变量：**类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。 **数据成员：**类变量或者实例变量用于处理类及其实例对象的相关的数据。 **方法重写：**如果从父类继承的方法不能满足子类的需求，可以对其进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。 **实例变量：**定义在方法中的变量，只作用于当前实例的类。 **继承：**即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个 Dog 类型的对象派生自 Animal 类，这是模拟&quot;是一个（is-a）&quot;关系（例图，Dog 是一个 Animal）。 **实例化：**创建一个类的实例，类的具体对象。 **方法：**类中定义的函数。 **对象：**通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。 类定义 语法格式如下： class ClassName: &lt;statement-1&gt; . . . &lt;statement-N&gt; 类实例化后，可以使用其属性，实际上，创建一个类之后，可以通过类名访问其属性。 类对象 类对象支持两种操作：属性引用和实例化。 属性引用使用和 Python 中所有的属性引用一样的标准语法：obj.name。 类对象创建后，类命名空间中所有的命名都是有效属性名。所以如果类定义是这样: #!/usr/bin/python3class MyClass: """一个简单的类实例""" i = 12345 def f(self): return 'hello world'# 实例化类x = MyClass()# 访问类的属性和方法print("MyClass 类的属性 i 为：", x.i)print("MyClass 类的方法 f 输出为：", x.f()) 实例化类： # 实例化类x = MyClass()# 访问类的属性和方法 以上创建了一个新的类实例并将该对象赋给局部变量 x，x 为空的对象。 执行以上程序输出结果为： MyClass 类的属性 i 为： 12345MyClass 类的方法 f 输出为： hello world 很多类都倾向于将对象创建为有初始状态的。因此类可能会定义一个名为 init() 的特殊方法（构造方法），像下面这样： def __init__(self): self.data = [] 类定义了 init() 方法的话，类的实例化操作会自动调用 init() 方法。所以在下例中，可以这样创建一个新的实例: x = MyClass() 当然， init() 方法可以有参数，参数通过 init() 传递到类的实例化操作上。例如: &gt;&gt;&gt; class Complex:... def __init__(self, realpart, imagpart):... self.r = realpart... self.i = imagpart...&gt;&gt;&gt; x = Complex(3.0, -4.5)&gt;&gt;&gt; x.r, x.i(3.0, -4.5) 类的方法 在类地内部，使用 def 关键字可以为类定义一个方法，与一般函数定义不同，类方法必须包含参数 self,且为第一个参数: #!/usr/bin/python3#类定义class people: #定义基本属性 name = '' age = 0 #定义私有属性,私有属性在类外部无法直接进行访问 __weight = 0 #定义构造方法 def __init__(self,n,a,w): self.name = n self.age = a self.__weight = w def speak(self): print("%s 说: 我 %d 岁。" %(self.name,self.age))# 实例化类p = people('W3Cschool',10,30)p.speak() 执行以上程序输出结果为： W3Cschool 说: 我 10 岁。 继承 Python 同样支持类的继承，如果一种语言不支持继承就，类就没有什么意义。派生类的定义如下所示: class DerivedClassName(BaseClassName1): &lt;statement-1&gt; . . . &lt;statement-N&gt; 需要注意圆括号中基类的顺序，若是基类中有相同的方法名，而在子类使用时未指定，python 从左至右搜索 即方法在子类中未找到时，从左到右查找基类中是否包含方法。 BaseClassName（示例中的基类名）必须与派生类定义在一个作用域内。除了类，还可以用表达式，基类定义在另一个模块中时这一点非常有用: class DerivedClassName(modname.BaseClassName): 实例 #!/usr/bin/python3#类定义class people: #定义基本属性 name = '' age = 0 #定义私有属性,私有属性在类外部无法直接进行访问 __weight = 0 #定义构造方法 def __init__(self,n,a,w): self.name = n self.age = a self.__weight = w def speak(self): print("%s 说: 我 %d 岁。" %(self.name,self.age))#单继承示例class student(people): grade = '' def __init__(self,n,a,w,g): #调用父类的构函 people.__init__(self,n,a,w) self.grade = g #覆写父类的方法 def speak(self): print("%s 说: 我 %d 岁了，我在读 %d 年级"%(self.name,self.age,self.grade))s = student('ken',10,60,3)s.speak() 执行以上程序输出结果为： ken 说: 我 10 岁了，我在读 3 年级 多继承 Python 同样有限的支持多继承形式。多继承的类定义形如下例: class DerivedClassName(Base1, Base2, Base3): &lt;statement-1&gt; . . . &lt;statement-N&gt; 需要注意圆括号中父类的顺序，若是父类中有相同的方法名，而在子类使用时未指定，python 从左至右搜索 即方法在子类中未找到时，从左到右查找父类中是否包含方法。 #!/usr/bin/python3#类定义class people: #定义基本属性 name = '' age = 0 #定义私有属性,私有属性在类外部无法直接进行访问 __weight = 0 #定义构造方法 def __init__(self,n,a,w): self.name = n self.age = a self.__weight = w def speak(self): print("%s 说: 我 %d 岁。" %(self.name,self.age))#单继承示例class student(people): grade = '' def __init__(self,n,a,w,g): #调用父类的构函 people.__init__(self,n,a,w) self.grade = g #覆写父类的方法 def speak(self): print("%s 说: 我 %d 岁了，我在读 %d 年级"%(self.name,self.age,self.grade))#另一个类，多重继承之前的准备class speaker(): topic = '' name = '' def __init__(self,n,t): self.name = n self.topic = t def speak(self): print("我叫 %s，我是一个演说家，我演讲的主题是 %s"%(self.name,self.topic))#多重继承class sample(speaker,student): a ='' def __init__(self,n,a,w,g,t): student.__init__(self,n,a,w,g) speaker.__init__(self,n,t)test = sample("Tim",25,80,4,"Python")test.speak() #方法名同，默认调用的是在括号中排前地父类的方法 执行以上程序输出结果为： 我叫 Tim，我是一个演说家，我演讲的主题是 Python 方法重写 如果你的父类方法的功能不能满足你的需求，你可以在子类重写你父类的方法，实例如下： #!/usr/bin/python3class Parent: # 定义父类 def myMethod(self): print ('调用父类方法')class Child(Parent): # 定义子类 def myMethod(self): print ('调用子类方法')c = Child() # 子类实例c.myMethod() # 子类调用重写方法 执行以上程序输出结果为： 调用子类方法 类属性与方法 类的私有属性 __private_attrs：两个下划线开头，声明该属性为私有，不能在类地外部被使用或直接访问。在类内部的方法中使用时self.__private_attrs。 类的方法 在类地内部，使用 def 关键字可以为类定义一个方法，与一般函数定义不同，类方法必须包含参数 self,且为第一个参数 类的私有方法 __private_method：两个下划线开头，声明该方法为私有方法，不能在类地外部调用。在类的内部调用 slef.__private_methods。 实例如下： #!/usr/bin/python3class JustCounter: __secretCount = 0 # 私有变量 publicCount = 0 # 公开变量 def count(self): self.__secretCount += 1 self.publicCount += 1 print (self.__secretCount)counter = JustCounter()counter.count()counter.count()print (counter.publicCount)print (counter.__secretCount) # 报错，实例不能访问私有变量 执行以上程序输出结果为： 122Traceback (most recent call last): File "test.py", line 16, in &lt;module&gt; print (counter.__secretCount) # 报错，实例不能访问私有变量AttributeError: 'JustCounter' object has no attribute '__secretCount' 类的专有方法： **init 😗* 构造函数，在生成对象时调用 **del 😗* 析构函数，释放对象时使用 **repr 😗* 打印，转换 **setitem 😗* 按照索引赋值 **getitem😗* 按照索引获取值 **len😗* 获得长度 **cmp😗* 比较运算 **call😗* 函数调用 **add😗* 加运算 **sub😗* 减运算 **mul😗* 乘运算 **div😗* 除运算 **mod😗* 求余运算 **pow😗* 乘方 运算符重载 Python 同样支持运算符重载，我么可以对类的专有方法进行重载，实例如下： #!/usr/bin/python3class Vector: def __init__(self, a, b): self.a = a self.b = b def __str__(self): return 'Vector (%d, %d)' % (self.a, self.b) def __add__(self,other): return Vector(self.a + other.a, self.b + other.b)v1 = Vector(2,10)v2 = Vector(5,-2)print (v1 + v2) 以上代码执行结果如下所示: Vector(7,8) 标准库概览 操作系统接口 os 模块提供了不少与操作系统相关联的函数。 &gt;&gt;&gt; import os&gt;&gt;&gt; os.getcwd() # 返回当前的工作目录'C:\\Python34'&gt;&gt;&gt; os.chdir('/server/accesslogs') # 修改当前的工作目录&gt;&gt;&gt; os.system('mkdir today') # 执行系统命令 mkdir0 文件通配符 glob 模块提供了一个函数用于从目录通配符搜索中生成文件列表: &gt;&gt;&gt; import glob&gt;&gt;&gt; glob.glob('*.py')['primes.py', 'random.py', 'quote.py'] 命令行参数 通用工具脚本经常调用命令行参数。这些命令行参数以链表形式存储于 sys 模块的 argv 变量。例如在命令行中执行 python demo.py one two three 后可以得到以下输出结果: &gt;&gt;&gt; import sys&gt;&gt;&gt; print(sys.argv)['demo.py', 'one', 'two', 'three'] 错误输出重定向和程序终止 sys 还有 stdin，stdout 和 stderr 属性，即使在 stdout 被重定向时，后者也可以用于显示警告和错误信息。 &gt;&gt;&gt; sys.stderr.write('Warning, log file not found starting a new one\n')Warning, log file not found starting a new one 字符串正则匹配 re 模块为高级字符串处理提供了正则表达式工具。对于复杂的匹配和处理，正则表达式提供了简洁、优化的解决方案: &gt;&gt;&gt; import re&gt;&gt;&gt; re.findall(r'\bf[a-z]*', 'which foot or hand fell fastest')['foot', 'fell', 'fastest']&gt;&gt;&gt; re.sub(r'(\b[a-z]+) \1', r'\1', 'cat in the the hat')'cat in the hat' 数学 math 模块为浮点运算提供了对底层 C 函数库的访问: &gt;&gt;&gt; import math&gt;&gt;&gt; math.cos(math.pi / 4)0.70710678118654757&gt;&gt;&gt; math.log(1024, 2)10.0 资料 https://github.com/vinta/awesome-python - 资源大全 https://github.com/jobbole/awesome-python-cn - 资源大全 https://github.com/scrapy/scrapy - python 爬虫框架 https://github.com/faif/python-patterns - python 设计模式 https://github.com/kennethreitz/python-guide - python 最佳实践]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>programming</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何学习一门编程语言]]></title>
    <url>%2Fblog%2F2018%2F01%2F05%2Fprogramming%2Fprogramming-guide%2F</url>
    <content type="text"><![CDATA[如何学习一门编程语言 📓 本文已归档到：「blog」 前言 学习编程语言的步骤 基本语法 数组、枚举、集合 常用类 语言特性 代码组织、模块加载、库管理 容错处理 输入输出和文件处理 回调机制 序列化和反序列化 进阶特性 库和框架 小结 前言 很多人喜欢争论什么什么编程语言好，我认为这个话题如果不限定应用范围，就毫无意义。 每种编程语言必然有其优点和缺点，这也决定了它有适合的应用场景和不适合的应用场景。现代软件行业，想一门编程语言包打天下是不现实的。这中现状也造成了一种现象，一个程序员往往要掌握多种编程语言。 学习任何一门编程语言，都会面临的第一个问题都是：如何学习 XX 语言？ 我不想说什么多看、多学、多写、多练之类的废话。世上事有难易乎？无他，唯手熟尔。谁不知道熟能生巧的道理？ 我觉得有必要谈谈的是：如何由浅入深的学习一门编程语言？学习所有编程语言有没有一个相对统一的学习方法？ 曾几何时，当我还是一名小菜鸟时，总是叹服那些大神掌握多门编程语言。后来，在多年编程工作和学习中，我陆陆续续也接触过不少编程语言：C、C++、Java、C#、Javascript、shell 等等。每次学习一门新的编程语言，掌握程度或深或浅，但是学习的曲线却大抵相似。 下面，我按照个人的学习经验总结一下，学习编程语言的基本步骤。 学习编程语言的步骤 基本语法 首先当然是了解语言的最基本语法。 控制台输出，如 C 的 printf，Java 的 System.out.println 等。 普通程序员的第一行代码一般都是输出 “Hello World” 吧。 基本数据类型 不同编程语言的基本数据类型不同。基本数据类型是的申请内存空间变得方便、规范化。 变量 不同编程语言的声明变量方式有很大不同。有的如 Java 、C++ 需要明确指定变量数据类型，这种叫强类型定义语言。有的语言（主要是脚本语言），如 Javascript、Shell 等，不需要明确指定数据类型，这种叫弱类型定义语言。 还需要注意的一点是变量的作用域范围和生命周期。不同语言变量的作用域范围和生命周期不一定一样，这个需要在代码中细细体会，有时会为此埋雷。 逻辑控制语句 编程语言都会有逻辑控制语句，哪怕是汇编语言。 掌握条件语句、循环语句、中断循环语句（break、continue）、选择语句。一般区别仅仅在于关键字、语法格式略有不同。 运算符 掌握基本运算符，如算术运算符、关系运算符、逻辑运算符、赋值运算符等。 有些语言还提供位运算符、特殊运算符，视情节掌握。 注释（没啥好说的） 函数 编程语言基本都有函数。注意语法格式：是否支持出参；支持哪些数据作为入参，有些语言允许将函数作为参数传入另一个参数（即回调）；返回值；如何退出函数（如 Java、C++的 return，）。 数组、枚举、集合 枚举只有部分编程语言有，如 Java、C++、C#。 但是数组和集合（有些语言叫容器）一般编程语言都有，只是有的编程语言提供的集合比较丰富。使用方法基本类似。 常用类 比较常用的类（当然有些语言中不叫类，叫对象或者其他什么，这个不重要，领会精神）请了解其 API 用法，如：字符串、日期、数学计算等等。 语言特性 语言特性这个特字反映的就是各个编程语言自身的&quot;独特个性&quot;，这涉及的点比较多，简单列举一些。 编程模式 比较流行的编程模式大概有： 面向对象编程，主要是封装、继承、多态；函数式编程，主要是应用 Lambda；过程式编程，可以理解为实现需求功能的特定步骤。 每种编程模式都有一定的道理，我从不认为只有面向对象编程才是王道。 Java 是面向对象语言，从 Java8 开始也支持函数编程（引入 Lambda 表达式）；C++ 可以算是半面向对象，半面向过程式语言。 语言自身特性 每个语言自身都有一些重要特性需要了解。例如，学习 C、C++，你必须了解内存的申请和释放，了解指针、引用。而学习 Java，你需要了解 JVM，垃圾回收机制。学习 Javascript，你需要了解 DOM 操作等。 代码组织、模块加载、库管理 一个程序一般都有很多个源代码文件。这就会引入这些问题：如何将代码文件组织起来？如何根据业务需要，选择将部分模块启动时进行加载，部分模块使用懒加载（或者热加载）？ 最基本的引用文件就不提了，如 C、C++的#include，Java 的 import 等。 针对代码组织、模块加载、库管理这些问题，不同语言会有不同的解决方案。 如 Java 可以用 maven、gradle 管理项目依赖、组织代码结构；Javascript （包括 Nodejs、jquery、react 等等库）可以用 npm、yarn 管理依赖，用 webpack 等工具管理模块加载。 容错处理 程序总难免会有 bug。 所以为了代码健壮性也好，为了方便定位问题也好，代码中需要有容错处理。常见的手段有： 异常 断言 日志 调试 单元测试 输入输出和文件处理 这块知识比较繁杂。建议提纲挈领的学习一下，理解基本概念，比如输入输出流、管道等等。至于 API，用到的时候再查一下即可。 回调机制 每种语言实现回调的方式有所不同，如 .Net 的 delegate （大量被用于 WinForm 程序）；Javascript 中函数天然支持回调：Javascript 函数允许传入另一个函数作为入参，然后在方法中调用它。其它语言的回调方式不一一列举。 序列化和反序列化 首先需要了解的是，序列化和反序列化的作用是为了在不同平台之间传输对象。 其次，要知道序列化存在多种方式，不同编程语言可能有多种方案。根据应用的序列化方式，选择性了解即可。 进阶特性 以下学习内容属于进阶性内容。可以根据开发需要去学习、掌握。需要注意的是，学习这些特性的态度应该是不学则已，学则死磕。因为半懂半不懂，特别容易引入问题。 对于半桶水的同学，我想说：放过自己，也放过别人，活着不好吗？ **并发编程：**好处多多，十分重要，但是并发代码容易出错，且出错难以定位。要学习还是要花很大力气的，需要了解大量知识，如：进程、线程、同步、异步、读写锁等等。 反射 - 让你可以动态编程（慎用）。 泛型 - 集合（或者叫容器）的基石。精通泛型，能大大提高你的代码效率。 元数据 - 描述数据的数据。Java 中叫做注解。 库和框架 学习一门编程语言，难免需要用到围绕它构建的技术生态圈——库和框架。这方面知识范围太庞大，根据实际应用领域去学习吧。比如搞 JavaWeb，你多多少少肯定要用到 Spring、Mybatis、Hibernate、Shiro 等大量开发框架；如果做 Javascript 前端，你可能会用到 React、Vue、Angular 、jQuery 等库或框架。 小结 总结以上，编程语言学习的道路是任重而道远的，未来是光明的。 最后一句话与君共勉：路漫漫兮其修远，吾将上下而求索。]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 从入门到精通]]></title>
    <url>%2Fblog%2F2017%2F12%2F09%2Ftools%2Fgit%2F</url>
    <content type="text"><![CDATA[Git 从入门到精通 📓 本文已归档到：「blog」 简介 Git 是什么？ 什么是版本控制？ 什么是分布式版本控制系统？ 为什么使用 Git？ 安装 配置 用户信息 .gitignore 原理 版本库 哈希值 文件状态 工作区域 命令 创建仓库 添加修改 撤销修改 更新与推送 查看信息 分支 标签 合并与重置 Github 最佳实践 Git Flow 常见问题 编辑提交(editting commits) 暂存(Staging) 未暂存(Unstaged)的内容 分支(Branches) Rebasing 和合并(Merging) 杂项(Miscellaneous Objects) 跟踪文件(Tracking Files) 配置(Configuration) 我不知道我做错了些什么 小结 参考资料 简介 Git 是什么？ Git 是一个开源的分布式版本控制系统。 什么是版本控制？ 版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。 什么是分布式版本控制系统？ 介绍分布式版本控制系统前，有必要先了解一下传统的集中式版本控制系统。 集中化的版本控制系统，诸如 CVS，Subversion 等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。 这么做最显而易见的缺点是中央服务器的单点故障。如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。要是中央服务器的磁盘发生故障，碰巧没做备份，或者备份不够及时，就会有丢失数据的风险。最坏的情况是彻底丢失整个项目的所有历史更改记录。 分布式版本控制系统的客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。 为什么使用 Git？ Git 是分布式的。这是 Git 和其它非分布式的版本控制系统，例如 svn，cvs 等，最核心的区别。分布式带来以下好处： 工作时不需要联网 首先，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件 A，你的同事也在他的电脑上改了文件 A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 更加安全 集中式版本控制系统，一旦中央服务器出了问题，所有人都无法工作。 分布式版本控制系统，每个人电脑中都有完整的版本库，所以某人的机器挂了，并不影响其它人。 安装 Debian/Ubuntu 环境安装 如果你使用的系统是 Debian/Ubuntu ， 安装命令为： $ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \&gt; libz-dev libssl-dev$ apt-get install git-core$ git --versiongit version 1.8.1.2 Centos/RedHat 环境安装 如果你使用的系统是 Centos/RedHat ，安装命令为： $ yum install curl-devel expat-devel gettext-devel \&gt; openssl-devel zlib-devel$ yum -y install git-core$ git --versiongit version 1.7.1 Windows 环境安装 在Git 官方下载地址下载 exe 安装包。按照安装向导安装即可。 建议安装 Git Bash 这个 git 的命令行工具。 Mac 环境安装 在Git 官方下载地址下载 mac 安装包。按照安装向导安装即可。 配置 Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置： /etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。 \~/.gitconfig 或 \~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。 当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。 每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。 在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\Users\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。 用户信息 当安装完 Git 应该做的第一件事就是设置你的用户名称与邮件地址。 这样做很重要，因为每一个 Git 的提交都会使用这些信息，并且它会写入到你的每一次提交中，不可更改： $ git config --global user.name "John Doe"$ git config --global user.email johndoe@example.com 再次强调，如果使用了 --global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 --global 选项的命令来配置。 很多 GUI 工具都会在第一次运行时帮助你配置这些信息。 .gitignore .gitignore 文件可能从字面含义也不难猜出：这个文件里配置的文件或目录，会自动被 git 所忽略，不纳入版本控制。 在日常开发中，我们的项目经常会产生一些临时文件，如编译 Java 产生的 *.class 文件，又或是 IDE 自动生成的隐藏目录（Intellij 的 .idea 目录、Eclipse 的 .settings 目录等）等等。这些文件或目录实在没必要纳入版本管理。在这种场景下，你就需要用到 .gitignore 配置来过滤这些文件或目录。 配置的规则很简单，也没什么可说的，看几个例子，自然就明白了。 这里推荐一下 Github 的开源项目：https://github.com/github/gitignore 在这里，你可以找到很多常用的模板，如：Java、Nodejs、C++ 的 .gitignore 模板等等。 原理 个人认为，对于 Git 这个版本工具，再不了解原理的情况下，直接去学习命令行，可能会一头雾水。所以，本文特意将原理放在命令使用章节之前讲解。 版本库 当你一个项目到本地或创建一个 git 项目，项目目录下会有一个隐藏的 .git 子目录。这个目录是 git 用来跟踪管理版本库的，千万不要手动修改。 哈希值 Git 中所有数据在存储前都计算校验和，然后以校验和来引用。 这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。 这个功能建构在 Git 底层，是构成 Git 哲学不可或缺的部分。 若你在传送过程中丢失信息或损坏文件，Git 就能发现。 Git 用以计算校验和的机制叫做 SHA-1 散列（hash，哈希）。 这是一个由 40 个十六进制字符（0-9 和 a-f）组成字符串，基于 Git 中文件的内容或目录结构计算出来。 SHA-1 哈希看起来是这样： 24b9da6552252987aa493b52f8696cd6d3b00373 Git 中使用这种哈希值的情况很多，你将经常看到这种哈希值。 实际上，Git 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。 文件状态 在 GIt 中，你的文件可能会处于三种状态之一： 已修改（modified） - 已修改表示修改了文件，但还没保存到数据库中。 已暂存（staged） - 已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。 已提交（committed） - 已提交表示数据已经安全的保存在本地数据库中。 工作区域 与文件状态对应的，不同状态的文件在 Git 中处于不同的工作区域。 工作区（working） - 当你 git clone 一个项目到本地，相当于在本地克隆了项目的一个副本。工作区是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。 暂存区（staging） - 暂存区是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作`‘索引’’，不过一般说法还是叫暂存区。 本地仓库（local） - 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 本地仓库。 远程仓库（remote） - 以上几个工作区都是在本地。为了让别人可以看到你的修改，你需要将你的更新推送到远程仓库。同理，如果你想同步别人的修改，你需要从远程仓库拉取更新。 命令 国外网友制作了一张 Git Cheat Sheet，总结很精炼，各位不妨收藏一下。 本节选择性介绍 git 中比较常用的命令行场景。 创建仓库 克隆一个已创建的仓库： # 通过 SSH$ git clone ssh://user@domain.com/repo.git#通过 HTTP$ git clone http://domain.com/user/repo.git 创建一个新的本地仓库： $ git init 添加修改 添加修改到暂存区： # 把指定文件添加到暂存区$ git add xxx# 把当前所有修改添加到暂存区$ git add .# 把所有修改添加到暂存区$ git add -A 提交修改到本地仓库： # 提交本地的所有修改$ git commit -a# 提交之前已标记的变化$ git commit# 附加消息提交$ git commit -m 'commit message' 储藏 有时，我们需要在同一个项目的不同分支上工作。当需要切换分支时，偏偏本地的工作还没有完成，此时，提交修改显得不严谨，但是不提交代码又无法切换分支。这时，你可以使用 git stash 将本地的修改内容作为草稿储藏起来。 官方称之为储藏，但我个人更喜欢称之为存草稿。 # 1. 将修改作为当前分支的草稿保存$ git stash# 2. 查看草稿列表$ git stash liststash@&#123;0&#125;: WIP on master: 6fae349 :memo: Writing docs.# 3.1 删除草稿$ git stash drop stash@&#123;0&#125;# 3.2 读取草稿$ git stash apply stash@&#123;0&#125; 撤销修改 撤销本地修改： # 移除缓存区的所有文件（i.e. 撤销上次git add）$ git reset HEAD# 将HEAD重置到上一次提交的版本，并将之后的修改标记为未添加到缓存区的修改$ git reset &lt;commit&gt;# 将HEAD重置到上一次提交的版本，并保留未提交的本地修改$ git reset --keep &lt;commit&gt;# 放弃工作目录下的所有修改$ git reset --hard HEAD# 将HEAD重置到指定的版本，并抛弃该版本之后的所有修改$ git reset --hard &lt;commit-hash&gt;# 用远端分支强制覆盖本地分支$ git reset --hard &lt;remote/branch&gt; e.g., upstream/master, origin/my-feature# 放弃某个文件的所有本地修改$ git checkout HEAD &lt;file&gt; 删除添加.gitignore文件前错误提交的文件： $ git rm -r --cached .$ git add .$ git commit -m "remove xyz file" 撤销远程修改（创建一个新的提交，并回滚到指定版本）： $ git revert &lt;commit-hash&gt; 彻底删除指定版本： # 执行下面命令后，commit-hash 提交后的记录都会被彻底删除，使用需谨慎$ git reset --hard &lt;commit-hash&gt;$ git push -f 更新与推送 更新： # 下载远程端版本，但不合并到HEAD中$ git fetch &lt;remote&gt;# 将远程端版本合并到本地版本中$ git pull origin master# 以rebase方式将远端分支与本地合并$ git pull --rebase &lt;remote&gt; &lt;branch&gt; 推送： # 将本地版本推送到远程端$ git push remote &lt;remote&gt; &lt;branch&gt;# 删除远程端分支$ git push &lt;remote&gt; :&lt;branch&gt; (since Git v1.5.0)$ git push &lt;remote&gt; --delete &lt;branch&gt; (since Git v1.7.0)# 发布标签$ git push --tags 查看信息 显示工作路径下已修改的文件： $ git status 显示与上次提交版本文件的不同： $ git diff 显示提交历史： # 从最新提交开始，显示所有的提交记录（显示hash， 作者信息，提交的标题和时间）$ git log# 显示某个用户的所有提交$ git log --author="username"# 显示某个文件的所有修改$ git log -p &lt;file&gt; 显示搜索内容： # 从当前目录的所有文件中查找文本内容$ git grep "Hello"# 在某一版本中搜索文本$ git grep "Hello" v2.5 分支 增删查分支： # 列出所有的分支$ git branch# 列出所有的远端分支$ git branch -r# 基于当前分支创建新分支$ git branch &lt;new-branch&gt;# 基于远程分支创建新的可追溯的分支$ git branch --track &lt;new-branch&gt; &lt;remote-branch&gt;# 删除本地分支$ git branch -d &lt;branch&gt;# 强制删除本地分支，将会丢失未合并的修改$ git branch -D &lt;branch&gt; 切换分支： # 切换分支$ git checkout &lt;branch&gt;# 创建并切换到新分支$ git checkout -b &lt;branch&gt; 标签 # 给当前版本打标签$ git tag &lt;tag-name&gt;# 给当前版本打标签并附加消息$ git tag -a &lt;tag-name&gt; 合并与重置 merge 与 rebase 虽然是 git 常用功能，但是强烈建议不要使用 git 命令来完成这项工作。 因为如果出现代码冲突，在没有代码比对工具的情况下，实在太艰难了。 你可以考虑使用各种 Git GUI 工具。 合并： # 将分支合并到当前HEAD中$ git merge &lt;branch&gt; 重置： # 将当前HEAD版本重置到分支中，请勿重置已发布的提交$ git rebase &lt;branch&gt; Github Github 作为最著名的代码开源协作社区，在程序员圈想必无人不知，无人不晓。 这里不赘述 Github 的用法，确实有不会用的新手同学，可以参考官方教程：https://guides.github.com/ clone 方式 Git 支持三种协议：HTTPS / SSH / GIT 而 Github 上支持 HTTPS 和 SSH。 HTTPS 这种方式要求你每次 push 时都要输入用户名、密码，有些繁琐。 而 SSH 要求你本地生成证书，然后在你的 Github 账户中注册。第一次配置麻烦是麻烦了点，但是以后就免去了每次 push 需要输入用户名、密码的繁琐。 以下介绍以下，如何生成证书，以及在 Github 中注册。 生成 SSH 公钥 如前所述，许多 Git 服务器都使用 SSH 公钥进行认证。 为了向 Git 服务器提供 SSH 公钥，如果某系统用户尚未拥有密钥，必须事先为其生成一份。 这个过程在所有操作系统上都是相似的。 首先，你需要确认自己是否已经拥有密钥。 默认情况下，用户的 SSH 密钥存储在其 \~/.ssh 目录下。 进入该目录并列出其中内容，你便可以快速确认自己是否已拥有密钥： $ cd ~/.ssh$ lsauthorized_keys2 id_dsa known_hostsconfig id_dsa.pub 我们需要寻找一对以 id_dsa 或 id_rsa 命名的文件，其中一个带有 .pub 扩展名。 .pub 文件是你的公钥，另一个则是私钥。 如果找不到这样的文件（或者根本没有 .ssh 目录），你可以通过运行 ssh-keygen 程序来创建它们。在 Linux/Mac 系统中，ssh-keygen 随 SSH 软件包提供；在 Windows 上，该程序包含于 MSysGit 软件包中。 $ ssh-keygenGenerating public/private rsa key pair.Enter file in which to save the key (/home/schacon/.ssh/id_rsa):Created directory '/home/schacon/.ssh'.Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /home/schacon/.ssh/id_rsa.Your public key has been saved in /home/schacon/.ssh/id_rsa.pub.The key fingerprint is:d0:82:24:8e:d7:f1:bb:9b:33:53:96:93:49:da:9b:e3 schacon@mylaptop.local 首先 ssh-keygen 会确认密钥的存储位置（默认是 .ssh/id_rsa），然后它会要求你输入两次密钥口令。如果你不想在使用密钥时输入口令，将其留空即可。 现在，进行了上述操作的用户需要将各自的公钥发送给任意一个 Git 服务器管理员（假设服务器正在使用基于公钥的 SSH 验证设置）。 他们所要做的就是复制各自的 .pub 文件内容，并将其通过邮件发送。 公钥看起来是这样的： $ cat ~/.ssh/id_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSUGPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XAt3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/EnmZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbxNrRFi9wrf+M7Q== schacon@mylaptop.local 在你的 Github 账户中，依次点击 Settings &gt; SSH and GPG keys &gt; New SSH key 然后，将上面生成的公钥内容粘贴到 Key 编辑框并保存。至此大功告成。 后面，你在克隆你的 Github 项目时使用 SSH 方式即可。 如果觉得我的讲解还不够细致，可以参考：https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/ 最佳实践 Git Flow 详细内容，可以参考这篇文章：Git 在团队中的最佳实践–如何正确使用 Git Flow Git 在实际开发中的最佳实践策略 Git Flow 可以归纳为以下： master 分支 - 也就是我们经常使用的主线分支，这个分支是最近发布到生产环境的代码，这个分支只能从其他分支合并，不能在这个分支直接修改。 develop 分支 - 这个分支是我们的主开发分支，包含所有要发布到下一个 release 的代码，这个分支主要是从其他分支合并代码过来，比如 feature 分支。 feature 分支 - 这个分支主要是用来开发一个新的功能，一旦开发完成，我们合并回 develop 分支进入下一个 release。 release 分支 - 当你需要一个发布一个新 release 的时候，我们基于 Develop 分支创建一个 release 分支，完成 release 后，我们合并到 master 和 develop 分支。 hotfix 分支 - 当我们在 master 发现新的 Bug 时候，我们需要创建一个 hotfix, 完成 hotfix 后，我们合并回 master 和 develop 分支，所以 hotfix 的改动会进入下一个 release。 常见问题 编辑提交(editting commits) 我刚才提交了什么 如果你用 git commit -a 提交了一次变化(changes)，而你又不确定到底这次提交了哪些内容。 你就可以用下面的命令显示当前HEAD上的最近一次的提交(commit): (master)$ git show 或者 $ git log -n1 -p 我的提交信息(commit message)写错了 如果你的提交信息(commit message)写错了且这次提交(commit)还没有推(push), 你可以通过下面的方法来修改提交信息(commit message): $ git commit --amend 这会打开你的默认编辑器, 在这里你可以编辑信息. 另一方面, 你也可以用一条命令一次完成: $ git commit --amend -m 'xxxxxxx' 如果你已经推(push)了这次提交(commit), 你可以修改这次提交(commit)然后强推(force push), 但是不推荐这么做。 我提交(commit)里的用户名和邮箱不对 如果这只是单个提交(commit)，修改它： $ git commit --amend --author "New Authorname &lt;authoremail@mydomain.com&gt;" 如果你需要修改所有历史, 参考 'git filter-branch’的指南页. 我想从一个提交(commit)里移除一个文件 通过下面的方法，从一个提交(commit)里移除一个文件: $ git checkout HEAD^ myfile$ git add -A$ git commit --amend 这将非常有用，当你有一个开放的补丁(open patch)，你往上面提交了一个不必要的文件，你需要强推(force push)去更新这个远程补丁。 我想删除我的的最后一次提交(commit) 如果你需要删除推了的提交(pushed commits)，你可以使用下面的方法。可是，这会不可逆的改变你的历史，也会搞乱那些已经从该仓库拉取(pulled)了的人的历史。简而言之，如果你不是很确定，千万不要这么做。 $ git reset HEAD^ --hard$ git push -f [remote] [branch] 如果你还没有推到远程, 把 Git 重置(reset)到你最后一次提交前的状态就可以了(同时保存暂存的变化): (my-branch*)$ git reset --soft HEAD@&#123;1&#125; 这只能在没有推送之前有用. 如果你已经推了, 唯一安全能做的是 git revert SHAofBadCommit， 那会创建一个新的提交(commit)用于撤消前一个提交的所有变化(changes)； 或者, 如果你推的这个分支是 rebase-safe 的 (例如： 其它开发者不会从这个分支拉), 只需要使用 git push -f； 更多, 请参考 the above section。 删除任意提交(commit) 同样的警告：不到万不得已的时候不要这么做. $ git rebase --onto SHA1_OF_BAD_COMMIT^ SHA1_OF_BAD_COMMIT$ git push -f [remote] [branch] 或者做一个 交互式 rebase 删除那些你想要删除的提交(commit)里所对应的行。 我尝试推一个修正后的提交(amended commit)到远程，但是报错： To https://github.com/yourusername/repo.git! [rejected] mybranch -&gt; mybranch (non-fast-forward)error: failed to push some refs to 'https://github.com/tanay1337/webmaker.org.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details. 注意, rebasing(见下面)和修正(amending)会用一个新的提交(commit)代替旧的, 所以如果之前你已经往远程仓库上推过一次修正前的提交(commit)，那你现在就必须强推(force push) (-f)。 注意 – 总是 确保你指明一个分支! (my-branch)$ git push origin mybranch -f 一般来说, 要避免强推. 最好是创建和推(push)一个新的提交(commit)，而不是强推一个修正后的提交。后者会使那些与该分支或该分支的子分支工作的开发者，在源历史中产生冲突。 我意外的做了一次硬重置(hard reset)，我想找回我的内容 如果你意外的做了 git reset --hard, 你通常能找回你的提交(commit), 因为 Git 对每件事都会有日志，且都会保存几天。 (master)$ git reflog 你将会看到一个你过去提交(commit)的列表, 和一个重置的提交。 选择你想要回到的提交(commit)的 SHA，再重置一次: (master)$ git reset --hard SHA1234 这样就完成了。 暂存(Staging) 我需要把暂存的内容添加到上一次的提交(commit) (my-branch*)$ git commit --amend 我想要暂存一个新文件的一部分，而不是这个文件的全部 一般来说, 如果你想暂存一个文件的一部分, 你可这样做: $ git add --patch filename.x -p 简写。这会打开交互模式， 你将能够用 s 选项来分隔提交(commit)； 然而, 如果这个文件是新的, 会没有这个选择， 添加一个新文件时, 这样做: $ git add -N filename.x 然后, 你需要用 e 选项来手动选择需要添加的行，执行 git diff --cached 将会显示哪些行暂存了哪些行只是保存在本地了。 我想把在一个文件里的变化(changes)加到两个提交(commit)里 git add 会把整个文件加入到一个提交. git add -p 允许交互式的选择你想要提交的部分. 我想把暂存的内容变成未暂存，把未暂存的内容暂存起来 这个有点困难， 我能想到的最好的方法是先 stash 未暂存的内容， 然后重置(reset)，再 pop 第一步 stashed 的内容, 最后再 add 它们。 $ git stash -k$ git reset --hard$ git stash pop$ git add -A 未暂存(Unstaged)的内容 我想把未暂存的内容移动到一个新分支 $ git checkout -b my-branch 我想把未暂存的内容移动到另一个已存在的分支 $ git stash$ git checkout my-branch$ git stash pop 我想丢弃本地未提交的变化(uncommitted changes) 如果你只是想重置源(origin)和你本地(local)之间的一些提交(commit)，你可以： ## one commit(my-branch)$ git reset --hard HEAD^## two commits(my-branch)$ git reset --hard HEAD^^## four commits(my-branch)$ git reset --hard HEAD~4## or(master)$ git checkout -f 重置某个特殊的文件, 你可以用文件名做为参数: $ git reset filename 我想丢弃某些未暂存的内容 如果你想丢弃工作拷贝中的一部分内容，而不是全部。 签出(checkout)不需要的内容，保留需要的。 $ git checkout -p## Answer y to all of the snippets you want to drop 另外一个方法是使用 stash， Stash 所有要保留下的内容, 重置工作拷贝, 重新应用保留的部分。 $ git stash -p## Select all of the snippets you want to save$ git reset --hard$ git stash pop 或者, stash 你不需要的部分, 然后 stash drop。 $ git stash -p## Select all of the snippets you don't want to save$ git stash drop 分支(Branches) 我从错误的分支拉取了内容，或把内容拉取到了错误的分支 这是另外一种使用 git reflog 情况，找到在这次错误拉(pull) 之前 HEAD 的指向。 (master)$ git reflogab7555f HEAD@&#123;0&#125;: pull origin wrong-branch: Fast-forwardc5bc55a HEAD@&#123;1&#125;: checkout: checkout message goes here 重置分支到你所需的提交(desired commit): $ git reset --hard c5bc55a 完成。 我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致 先确认你没有推(push)你的内容到远程。 git status 会显示你领先(ahead)源(origin)多少个提交: (my-branch)$ git status## On branch my-branch## Your branch is ahead of 'origin/my-branch' by 2 commits.## (use "git push" to publish your local commits)# 一种方法是: (master)$ git reset --hard origin/my-branch 我需要提交到一个新分支，但错误的提交到了 master 在 master 下创建一个新分支，不切换到新分支,仍在 master 下: (master)$ git branch my-branch 把 master 分支重置到前一个提交: (master)$ git reset --hard HEAD^ HEAD^ 是 HEAD^1 的简写，你可以通过指定要设置的HEAD来进一步重置。 或者, 如果你不想使用 HEAD^, 找到你想重置到的提交(commit)的 hash(git log 能够完成)， 然后重置到这个 hash。 使用git push 同步内容到远程。 例如, master 分支想重置到的提交的 hash 为a13b85e: (master)$ git reset --hard a13b85eHEAD is now at a13b85e 签出(checkout)刚才新建的分支继续工作: (master)$ git checkout my-branch 我想保留来自另外一个 ref-ish 的整个文件 假设你正在做一个原型方案(原文为 working spike (see note)), 有成百的内容，每个都工作得很好。现在, 你提交到了一个分支，保存工作内容: (solution)$ git add -A &amp;&amp; git commit -m "Adding all changes from this spike into one big commit." 当你想要把它放到一个分支里 (可能是feature, 或者 develop), 你关心是保持整个文件的完整，你想要一个大的提交分隔成比较小。 假设你有: 分支 solution, 拥有原型方案， 领先 develop 分支。 分支 develop, 在这里你应用原型方案的一些内容。 我去可以通过把内容拿到你的分支里，来解决这个问题: (develop)$ git checkout solution -- file1.txt 这会把这个文件内容从分支 solution 拿到分支 develop 里来: ## On branch develop## Your branch is up-to-date with 'origin/develop'.## Changes to be committed:## (use "git reset HEAD &lt;file&gt;..." to unstage)### modified: file1.txt 然后, 正常提交。 Note: Spike solutions are made to analyze or solve the problem. These solutions are used for estimation and discarded once everyone gets clear visualization of the problem. ~ Wikipedia. 我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里 假设你有一个master分支， 执行git log, 你看到你做过两次提交: (master)$ git logcommit e3851e817c451cc36f2e6f3049db528415e3c114Author: Alex Lee &lt;alexlee@example.com&gt;Date: Tue Jul 22 15:39:27 2014 -0400 Bug #21 - Added CSRF protectioncommit 5ea51731d150f7ddc4a365437931cd8be3bf3131Author: Alex Lee &lt;alexlee@example.com&gt;Date: Tue Jul 22 15:39:12 2014 -0400 Bug #14 - Fixed spacing on titlecommit a13b85e984171c6e2a1729bb061994525f626d14Author: Aki Rose &lt;akirose@example.com&gt;Date: Tue Jul 21 01:12:48 2014 -0400 First commit 让我们用提交 hash(commit hash)标记 bug (e3851e8 for #21, 5ea5173 for #14). 首先, 我们把master分支重置到正确的提交(a13b85e): (master)$ git reset --hard a13b85eHEAD is now at a13b85e 现在, 我们对 bug #21 创建一个新的分支: (master)$ git checkout -b 21(21)$ 接着, 我们用 cherry-pick 把对 bug #21 的提交放入当前分支。 这意味着我们将应用(apply)这个提交(commit)，仅仅这一个提交(commit)，直接在 HEAD 上面。 (21)$ git cherry-pick e3851e8 这时候, 这里可能会产生冲突， 参见交互式 rebasing 章 冲突节 解决冲突. 再者， 我们为 bug #14 创建一个新的分支, 也基于master分支 (21)$ git checkout master(master)$ git checkout -b 14(14)$ 最后, 为 bug #14 执行 cherry-pick: (14)$ git cherry-pick 5ea5173 我想删除上游(upstream)分支被删除了的本地分支 一旦你在 github 上面合并(merge)了一个 pull request, 你就可以删除你 fork 里被合并的分支。 如果你不准备继续在这个分支里工作, 删除这个分支的本地拷贝会更干净，使你不会陷入工作分支和一堆陈旧分支的混乱之中。 $ git fetch -p 我不小心删除了我的分支 如果你定期推送到远程, 多数情况下应该是安全的，但有些时候还是可能删除了还没有推到远程的分支。 让我们先创建一个分支和一个新的文件: (master)$ git checkout -b my-branch(my-branch)$ git branch(my-branch)$ touch foo.txt(my-branch)$ lsREADME.md foo.txt 添加文件并做一次提交 (my-branch)$ git add .(my-branch)$ git commit -m 'foo.txt added'(my-branch)$ foo.txt added 1 files changed, 1 insertions(+) create mode 100644 foo.txt(my-branch)$ git logcommit 4e3cd85a670ced7cc17a2b5d8d3d809ac88d5012Author: siemiatj &lt;siemiatj@example.com&gt;Date: Wed Jul 30 00:34:10 2014 +0200 foo.txt addedcommit 69204cdf0acbab201619d95ad8295928e7f411d5Author: Kate Hudson &lt;katehudson@example.com&gt;Date: Tue Jul 29 13:14:46 2014 -0400 Fixes #6: Force pushing after amending commits 现在我们切回到主(master)分支，‘不小心的’删除my-branch分支 (my-branch)$ git checkout masterSwitched to branch 'master'Your branch is up-to-date with 'origin/master'.(master)$ git branch -D my-branchDeleted branch my-branch (was 4e3cd85).(master)$ echo oh noes, deleted my branch!oh noes, deleted my branch! 在这时候你应该想起了reflog, 一个升级版的日志，它存储了仓库(repo)里面所有动作的历史。 (master)$ git reflog69204cd HEAD@&#123;0&#125;: checkout: moving from my-branch to master4e3cd85 HEAD@&#123;1&#125;: commit: foo.txt added69204cd HEAD@&#123;2&#125;: checkout: moving from master to my-branch 正如你所见，我们有一个来自删除分支的提交 hash(commit hash)，接下来看看是否能恢复删除了的分支。 (master)$ git checkout -b my-branch-helpSwitched to a new branch 'my-branch-help'(my-branch-help)$ git reset --hard 4e3cd85HEAD is now at 4e3cd85 foo.txt added(my-branch-help)$ lsREADME.md foo.txt 看! 我们把删除的文件找回来了。 Git 的 reflog 在 rebasing 出错的时候也是同样有用的。 我想删除一个分支 删除一个远程分支: (master)$ git push origin --delete my-branch 你也可以: (master)$ git push origin :my-branch 删除一个本地分支: (master)$ git branch -D my-branch 我想从别人正在工作的远程分支签出(checkout)一个分支 首先, 从远程拉取(fetch) 所有分支: (master)$ git fetch --all 假设你想要从远程的daves分支签出到本地的daves (master)$ git checkout --track origin/davesBranch daves set up to track remote branch daves from origin.Switched to a new branch 'daves' (--track 是 git checkout -b [branch] [remotename]/[branch] 的简写) 这样就得到了一个daves分支的本地拷贝, 任何推过(pushed)的更新，远程都能看到. Rebasing 和合并(Merging) 我想撤销 rebase/merge 你可以合并(merge)或 rebase 了一个错误的分支, 或者完成不了一个进行中的 rebase/merge。 Git 在进行危险操作的时候会把原始的 HEAD 保存在一个叫 ORIG_HEAD 的变量里, 所以要把分支恢复到 rebase/merge 前的状态是很容易的。 (my-branch)$ git reset --hard ORIG_HEAD 我已经 rebase 过, 但是我不想强推(force push) 不幸的是，如果你想把这些变化(changes)反应到远程分支上，你就必须得强推(force push)。 是因你快进(Fast forward)了提交，改变了 Git 历史, 远程分支不会接受变化(changes)，除非强推(force push)。这就是许多人使用 merge 工作流, 而不是 rebasing 工作流的主要原因之一， 开发者的强推(force push)会使大的团队陷入麻烦。使用时需要注意，一种安全使用 rebase 的方法是，不要把你的变化(changes)反映到远程分支上, 而是按下面的做: (master)$ git checkout my-branch(my-branch)$ git rebase -i master(my-branch)$ git checkout master(master)$ git merge --ff-only my-branch 更多, 参见 this SO thread. 我需要组合(combine)几个提交(commit) 假设你的工作分支将会做对于 master 的 pull-request。 一般情况下你不关心提交(commit)的时间戳，只想组合 所有 提交(commit) 到一个单独的里面, 然后重置(reset)重提交(recommit)。 确保主(master)分支是最新的和你的变化都已经提交了, 然后: (my-branch)$ git reset --soft master(my-branch)$ git commit -am "New awesome feature" 如果你想要更多的控制, 想要保留时间戳, 你需要做交互式 rebase (interactive rebase): (my-branch)$ git rebase -i master 如果没有相对的其它分支， 你将不得不相对自己的HEAD 进行 rebase。 例如：你想组合最近的两次提交(commit), 你将相对于HEAD\~2 进行 rebase， 组合最近 3 次提交(commit), 相对于HEAD\~3, 等等。 (master)$ git rebase -i HEAD~2 在你执行了交互式 rebase 的命令(interactive rebase command)后, 你将在你的编辑器里看到类似下面的内容: pick a9c8a1d Some refactoringpick 01b2fd8 New awesome featurepick b729ad5 fixuppick e3851e8 another fix## Rebase 8074d12..b729ad5 onto 8074d12### Commands:## p, pick = use commit## r, reword = use commit, but edit the commit message## e, edit = use commit, but stop for amending## s, squash = use commit, but meld into previous commit## f, fixup = like "squash", but discard this commit's log message## x, exec = run command (the rest of the line) using shell### These lines can be re-ordered; they are executed from top to bottom.### If you remove a line here THAT COMMIT WILL BE LOST.### However, if you remove everything, the rebase will be aborted.### Note that empty commits are commented out 所有以 # 开头的行都是注释, 不会影响 rebase. 然后，你可以用任何上面命令列表的命令替换 pick, 你也可以通过删除对应的行来删除一个提交(commit)。 例如, 如果你想 单独保留最旧(first)的提交(commit),组合所有剩下的到第二个里面, 你就应该编辑第二个提交(commit)后面的每个提交(commit) 前的单词为 f: pick a9c8a1d Some refactoringpick 01b2fd8 New awesome featuref b729ad5 fixupf e3851e8 another fix 如果你想组合这些提交(commit) 并重命名这个提交(commit), 你应该在第二个提交(commit)旁边添加一个r，或者更简单的用s 替代 f: pick a9c8a1d Some refactoringpick 01b2fd8 New awesome features b729ad5 fixups e3851e8 another fix 你可以在接下来弹出的文本提示框里重命名提交(commit)。 Newer, awesomer features## Please enter the commit message for your changes. Lines starting## with '#' will be ignored, and an empty message aborts the commit.## rebase in progress; onto 8074d12## You are currently editing a commit while rebasing branch 'master' on '8074d12'.### Changes to be committed:# modified: README.md# 如果成功了, 你应该看到类似下面的内容: (master)$ Successfully rebased and updated refs/heads/master. 安全合并(merging)策略 --no-commit 执行合并(merge)但不自动提交, 给用户在做提交前检查和修改的机会。 no-ff 会为特性分支(feature branch)的存在过留下证据, 保持项目历史一致。 (master)$ git merge --no-ff --no-commit my-branch 我需要将一个分支合并成一个提交(commit) (master)$ git merge --squash my-branch 我只想组合(combine)未推的提交(unpushed commit) 有时候，在将数据推向上游之前，你有几个正在进行的工作提交(commit)。这时候不希望把已经推(push)过的组合进来，因为其他人可能已经有提交(commit)引用它们了。 (master)$ git rebase -i @&#123;u&#125; 这会产生一次交互式的 rebase(interactive rebase), 只会列出没有推(push)的提交(commit)， 在这个列表时进行 reorder/fix/squash 都是安全的。 检查是否分支上的所有提交(commit)都合并(merge)过了 检查一个分支上的所有提交(commit)是否都已经合并(merge)到了其它分支, 你应该在这些分支的 head(或任何 commits)之间做一次 diff: (master)$ git log --graph --left-right --cherry-pick --oneline HEAD...feature/120-on-scroll 这会告诉你在一个分支里有而另一个分支没有的所有提交(commit), 和分支之间不共享的提交(commit)的列表。 另一个做法可以是: (master)$ git log master ^feature/120-on-scroll --no-merges 交互式 rebase(interactive rebase)可能出现的问题 这个 rebase 编辑屏幕出现’noop’ 如果你看到的是这样: noop 这意味着你 rebase 的分支和当前分支在同一个提交(commit)上, 或者 领先(ahead) 当前分支。 你可以尝试: 检查确保主(master)分支没有问题 rebase HEAD\~2 或者更早 有冲突的情况 如果你不能成功的完成 rebase, 你可能必须要解决冲突。 首先执行 git status 找出哪些文件有冲突: (my-branch)$ git statusOn branch my-branchChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: README.md 在这个例子里面, README.md 有冲突。 打开这个文件找到类似下面的内容: &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADsome code=========some code&gt;&gt;&gt;&gt;&gt;&gt;&gt; new-commit 你需要解决新提交的代码(示例里, 从中间==线到new-commit的地方)与HEAD 之间不一样的地方. 有时候这些合并非常复杂，你应该使用可视化的差异编辑器(visual diff editor): (master*)$ git mergetool -t opendiff 在你解决完所有冲突和测试过后, git add 变化了的(changed)文件, 然后用git rebase --continue 继续 rebase。 (my-branch)$ git add README.md(my-branch)$ git rebase --continue 如果在解决完所有的冲突过后，得到了与提交前一样的结果, 可以执行git rebase --skip。 任何时候你想结束整个 rebase 过程，回来 rebase 前的分支状态, 你可以做: (my-branch)$ git rebase --abort 杂项(Miscellaneous Objects) 克隆所有子模块 $ git clone --recursive git://github.com/foo/bar.git 如果已经克隆了: $ git submodule update --init --recursive 删除标签(tag) $ git tag -d &lt;tag_name&gt;$ git push &lt;remote&gt; :refs/tags/&lt;tag_name&gt; 恢复已删除标签(tag) 如果你想恢复一个已删除标签(tag), 可以按照下面的步骤: 首先, 需要找到无法访问的标签(unreachable tag): $ git fsck --unreachable | grep tag 记下这个标签(tag)的 hash，然后用 Git 的 update-ref: $ git update-ref refs/tags/&lt;tag_name&gt; &lt;hash&gt; 这时你的标签(tag)应该已经恢复了。 已删除补丁(patch) 如果某人在 GitHub 上给你发了一个 pull request, 但是然后他删除了他自己的原始 fork, 你将没法克隆他们的提交(commit)或使用 git am。在这种情况下, 最好手动的查看他们的提交(commit)，并把它们拷贝到一个本地新分支，然后做提交。 做完提交后, 再修改作者，参见变更作者。 然后, 应用变化, 再发起一个新的 pull request。 跟踪文件(Tracking Files) 我只想改变一个文件名字的大小写，而不修改内容 (master)$ git mv --force myfile MyFile 我想从 Git 删除一个文件，但保留该文件 (master)$ git rm --cached log.txt 配置(Configuration) 我想给一些 Git 命令添加别名(alias) 在 OS X 和 Linux 下, 你的 Git 的配置文件储存在 \~/.gitconfig。我在[alias] 部分添加了一些快捷别名(和一些我容易拼写错误的)，如下: [alias] a = add amend = commit --amend c = commit ca = commit --amend ci = commit -a co = checkout d = diff dc = diff --changed ds = diff --staged f = fetch loll = log --graph --decorate --pretty=oneline --abbrev-commit m = merge one = log --pretty=oneline outstanding = rebase -i @&#123;u&#125; s = status unpushed = log @&#123;u&#125; wc = whatchanged wip = rebase -i @&#123;u&#125; zap = fetch -p 我想缓存一个仓库(repository)的用户名和密码 你可能有一个仓库需要授权，这时你可以缓存用户名和密码，而不用每次推/拉(push/pull)的时候都输入，Credential helper 能帮你。 $ git config --global credential.helper cache## Set git to use the credential memory cache $ git config --global credential.helper 'cache --timeout=3600'## Set the cache to timeout after 1 hour (setting is in seconds) 我不知道我做错了些什么 你把事情搞砸了：你 重置(reset) 了一些东西, 或者你合并了错误的分支, 亦或你强推了后找不到你自己的提交(commit)了。有些时候, 你一直都做得很好, 但你想回到以前的某个状态。 这就是 git reflog 的目的， reflog 记录对分支顶端(the tip of a branch)的任何改变, 即使那个顶端没有被任何分支或标签引用。基本上, 每次 HEAD 的改变, 一条新的记录就会增加到reflog。遗憾的是，这只对本地分支起作用，且它只跟踪动作 (例如，不会跟踪一个没有被记录的文件的任何改变)。 (master)$ git reflog0a2e358 HEAD@&#123;0&#125;: reset: moving to HEAD\~20254ea7 HEAD@&#123;1&#125;: checkout: moving from 2.2 to masterc10f740 HEAD@&#123;2&#125;: checkout: moving from master to 2.2 上面的 reflog 展示了从 master 分支签出(checkout)到 2.2 分支，然后再签回。 那里，还有一个硬重置(hard reset)到一个较旧的提交。最新的动作出现在最上面以 HEAD@{0}标识. 如果事实证明你不小心回移(move back)了提交(commit), reflog 会包含你不小心回移前 master 上指向的提交(0254ea7)。 $ git reset --hard 0254ea7 然后使用 git reset 就可以把 master 改回到之前的 commit，这提供了一个在历史被意外更改情况下的安全网。 小结 最后，放一张我总结的脑图总结一下以上的知识点。 参考资料 官方资源 Git 官网 Git Github 模板 gitignore 模板 - .gitignore 文件模板 gitattributes 模板 - .gitattributes 文件模板 github-cheat-sheet - git 命令简略图表 Git 书 Git 官方推荐教程 - Scott Chacon 的 Git 书。 Git 教程 Git 中文教程 廖雪峰的 Git 教程 有关 git 的学习资源 文章 Git Cookbook Git 奇技淫巧 Git 风格指南 Git 在团队中的最佳实践–如何正确使用 Git Flow Git 工具 guis - Git 官网展示的客户端工具列表。 gogs - 极易搭建的自助 Git 服务。 gitflow - 应用 fit-flow 模型的工具。 firstaidgit.io 一个可搜索的最常被问到的 Git 的问题 git-extra-commands - 一堆有用的额外的 Git 脚本 git-extras - GIT 工具集 – repo summary, repl, changelog population, author commit percentages and more git-fire - git-fire 是一个 Git 插件，用于帮助在紧急情况下添加所有当前文件, 做提交(committing), 和推(push)到一个新分支(阻止合并冲突)。 git-tips - Git 小提示 git-town - 通用，高级 Git 工作流支持！ http://www.git-town.com GUI 客户端(GUI Clients) GitKraken - 豪华的 Git 客户端 Windows, Mac &amp; Linux git-cola - 另外一个 Git 客户端 Windows &amp; OS X GitUp - 一个新的 Git 客户端，在处理 Git 的复杂性上有自己的特点 gitx-dev - 图形化的 Git 客户端 OS X Source Tree - 免费的图形化 Git 客户端 Windows &amp; OS X Tower - 图形化 Git 客户端 OS X(付费) git cheat sheet github-git-cheat-sheet]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件工程与项目管理]]></title>
    <url>%2Fblog%2F2017%2F11%2F20%2Fmethod%2Fsoftware-engineering%2F</url>
    <content type="text"><![CDATA[软件工程与项目管理 📓 本文已归档到：「blog」 软件工程是一门研究用工程化方法构建和维护有效的、实用的和高质量的软件的学科。它涉及程序设计语言、数据库、软件开发工具、系统平台、标准、设计模式等方面。 软件工程的目标 软件工程的原理 软件工程的方法 软件需求 软件需求说明书（ SRS ） 软件生命周期 软件生命周期模型 瀑布模型 螺旋模型 软件工程术语 更多内容 书 文章 工具 文档模板 软件工程的目标 软件工程的目标是：在给定成本、进度的前提下，开发出具有适用性、有效性、可修改性、可靠性、可理解性、可维护性、可重用性、可移植性、可追踪性、可互操作性和满足用户需求的软件产品。 适用性 - 软件在不同的系统约束条件下，使用户需求得到满足的难易程度。 有效性 - 软件系统能最有效的利用计算机的时间和空间资源。各种软件无不把系统的时/空开销作为衡量软件质量的一项重要技术指标。很多场合，在追求时间有效性和空间有效性时会发生矛盾，这时不得不牺牲时间有效性换取空间有效性或牺牲空间有效性换取时间有效性。时/空折衷是经常采用的技巧。 可修改性 - 允许对系统进行修改而不增加原系统的复杂性。它支持软件的调试和维护，是一个难以达到的目标。 可靠性 - 能防止因概念、设计和结构等方面的不完善造成的软件系统失效，具有挽回因操作不当造成软件系统失效的能力。 可理解性 - 系统具有清晰的结构，能直接反映问题的需求。可理解性有助于控制系统软件复杂性，并支持软件的维护、移植或重用。 可维护性 - 软件交付使用后，能够对它进行修改，以改正潜伏的错误，改进性能和其它属性，使软件产品适应环境的变化等。软件维护费用在软件开发费用中占有很大的比重。可维护性是软件工程中一项十分重要的目标。 可重用性 - 把概念或功能相对独立的一个或一组相关模块定义为一个软部件。可组装在系统的任何位置，降低工作量。 可移植性 - 软件从一个计算机系统或环境搬到另一个计算机系统或环境的难易程度。 可追踪性 - 根据软件需求对软件设计、程序进行正向追踪，或根据软件设计、程序对软件需求的逆向追踪的能力。 可互操作性 - 多个软件元素相互通信并协同完成任务的能力。 软件工程的原理 软件工程的七条基本原理： 用分阶段的生存周期计划进行严格的管理。 坚持进行阶段评审。 实行严格的产品控制。 采用现代程序设计技术。 软件工程结果应能清楚地审查。 开发小组的人员应该少而精。 承认不断改进软件工程实践的必要性。 软件工程的方法 著名的重量级开发方法： ISO9000 - ISO 9000 系列标准是国际标准化组织设立的标准，与品质管理系统有关。 能力成熟度模型（CMM） - CMM 涵盖一个成熟的软件发展组织所应具备的重要功能与项目，它描述了软件发展的演进过程，从毫无章法、不成熟的软件开发阶段到成熟软件开发阶段的过程。 统一软件开发过程（RUP） - RUP 是一种软件工程方法，为迭代式软件开发流程。 著名的轻量级开发方法： 敏捷开发（Agile Development） - 是一种应对快速变化的需求的一种软件开发能力。它们的具体名称、理念、过程、术语都不尽相同，相对于“非敏捷”，更强调程序员团队与业务专家之间的紧密协作、面对面的沟通（认为比书面的文档更有效）、频繁交付新的软件版本、紧凑而自我组织型的团队、能够很好地适应需求变化的代码编写和团队组织方法，也更注重软件开发过程中人的作用。 极限编程（XP） - 极限编程是敏捷软件开发中最有成效的方法学之一。极限编程技术以沟通（Communication）、简单（Simplicity）、反馈（Feedback）、勇气（Courage）和尊重（Respect）为价值标准。 软件需求 软件需求包括三个不同的层次：业务需求、用户需求和功能需求。 **业务需求（Business requirement）**表示组织或客户高层次的目标。业务需求通常来自项目投资人、购买产品的客户、实际用户的管理者、市场营销部门或产品策划部门。业务需求描述了组织为什么要开发一个系统，即组织希望达到的目标。使用前景和范围（ vision and scope ）文档来记录业务需求，这份文档有时也被称作项目轮廓图或市场需求（ project charter 或 market requirement ）文档。 **用户需求（user requirement）**描述的是用户的目标，或用户要求系统必须能完成的任务。用例、场景描述和事件――响应表都是表达用户需求的有效途径。也就是说用户需求描述了用户能使用系统来做些什么。 **功能需求（functional requirement）**规定开发人员必须在产品中实现的软件功能，用户利用这些功能来完成任务，满足业务需求。功能需求有时也被称作行为需求（ behavioral requirement ），因为习惯上总是用“应该”对其进行描述：“系统应该发送电子邮件来通知用户已接受其预定”。功能需求描述是开发人员需要实现什么。 **系统需求（system requirement）**用于描述包含多个子系统的产品（即系统）的顶级需求。系统可以只包含软件系统，也可以既包含软件又包含硬件子系统。人也可以是系统的一部分，因此某些系统功能可能要由人来承担。 软件需求说明书（ SRS ） 软件需求说明书（ SRS ）完整地描述了软件系统的预期特性。开发、测试、质量保证、项目管理和其他相关的项目功能都要用到 SRS 。 除了功能需求外， SRS 中还包含非功能需求，包括性能指标和对质量属性的描述。 **质量属性（quality attribute）**对产品的功能描述作了补充，它从不同方面描述了产品的各种特性。这些特性包括可用性、可移植性、完整性、效率和健壮性，它们对用户或开发人员都很重要。其他的非功能需求包括系统与外部世界的外部界面，以及对设计与实现的约束。 **约束（constraint）**限制了开发人员设计和构建系统时的选择范围。 软件生命周期 软件生命周期（Software Life Cycle,SLC）是软件的产生直到报废或停止使用的生命周期。 问题定义 - 要求系统分析员与用户进行交流，弄清“用户需要计算机解决什么问题”然后提出关于“系统目标与范围的说明”，提交用户审查和确认。 可行性研究 - 一方面在于把待开发的系统的目标以明确的语言描述出来；另一方面从经济、技术、法律等多方面进行可行性分析。 需求分析 - 弄清用户对软件系统的全部需求，编写需求规格说明书和初步的用户手册，提交评审。 开发阶段 概要设计 详细设计 编码实现 软件测试 - 测试的过程分单元测试、组装测试以及系统测试三个阶段进行。测试的方法主要有白盒测试和黑盒测试两种。 维护 软件生命周期模型 瀑布模型 瀑布模型（Waterfall Model）强调系统开发应有完整的周期，且必须完整的经历周期的每一开发阶段，并系统化的考量分析与设计的技术、时间与资源之投入等。 核心思想 瀑布模型核心思想是按工序将问题拆分，将功能的实现与设计分开，便于分工协作，即采用结构化的分析与设计方法将逻辑实现与物理实现分开。将软件生命周期划分为制定计划、需求分析、软件设计、程序编写、软件测试和运行维护等六个基本活动，并且规定了它们自上而下、相互衔接的固定次序，如同瀑布流水，逐级下落。 优缺点 优点 为项目提供了按阶段划分的检查点。 当前一阶段完成后，您只需要去关注后续阶段。 可在迭代模型中应用瀑布模型。 它提供了一个模板，这个模板使得分析、设计、编码、测试和支持的方法可以在该模板下有一个共同的指导。 缺点 各个阶段的划分完全固定，阶段之间产生大量的文档，极大地增加了工作量。 由于开发模型是线性的，用户只有等到整个过程的末期才能见到开发成果，从而增加了开发风险。 通过过多的强制完成日期和里程碑来跟踪各个项目阶段。 瀑布模型的突出缺点是不适应用户需求的变化。 适用场景 是否使用这一模型主要取决于是否能理解客户的需求以及在项目的进程中这些需求的变化程度。对于需求经常变化的项目，不要适用瀑布模型。 螺旋模型 螺旋模型基本做法是在“瀑布模型”的每一个开发阶段前引入一个非常严格的风险识别、风险分析和风险控制，它把软件项目分解成一个个小项目。每个小项目都标识一个或多个主要风险，直到所有的主要风险因素都被确定。 核心思想 螺旋模型沿着螺线进行若干次迭代，图中的四个象限代表了以下活动： 制定计划 - 确定软件目标，选定实施方案，弄清项目开发的限制条件； 风险分析 - 分析评估所选方案，考虑如何识别和消除风险； 实施工程 - 实施软件开发和验证； 客户评估 - 评价开发工作，提出修正建议，制定下一步计划。 螺旋模型由风险驱动，强调可选方案和约束条件从而支持软件的重用，有助于将软件质量作为特殊目标融入产品开发之中。 优缺点 优点 设计上的灵活性,可以在项目的各个阶段进行变更。 以小的分段来构建大型系统,使成本计算变得简单容易。 客户始终参与每个阶段的开发,保证了项目不偏离正确方向以及项目的可控性。 随着项目推进,客户始终掌握项目的最新信息, 从而他或她能够和管理层有效地交互。 客户认可这种公司内部的开发方式带来的良好的沟通和高质量的产品。 缺点 很难让用户确信这种演化方法的结果是可以控制的。建设周期长，而软件技术发展比较快，所以经常出现软件开发完毕后，和当前的技术水平有了较大的差距，无法满足当前用户需求。 适用场景 对于新项目，需求不明确的情况下，适合用螺旋模型进行开发，便于风险控制和需求变更。 软件工程术语 里程碑（Milestone） - 在制定项目进度计划时，在进度时间表上设立一些重要的时间检查点，这样一来，就可以在项目执行过程中利用这些重要的时间检查点来对项目的进程进行检查和控制。这些重要的时间检查点被称作项目的里程碑。 人月 - 软件开发的工作量单位。如 200 人月，10 个人开发，那算来就是花 20 个月就可完工。 基线 - 基线是项目储存库中每个工件版本在特定时期的一个“快照”。它提供一个正式标准，随后的工作基于此标准，并且只有经过授权后才能变更这个标准。建立一个初始基线后，以后每次对其进行的变更都将记录为一个差值，直到建成下一个基线。 更多内容 书 人月神话 代码大全 文章 使用甘特图做项目管理 使用燃尽图监控项目整体进度 工具 10 大开源免费的项目管理软件推荐 http://www.ruanyifeng.com/blog/2017/08/issue.html 文档模板 软件工程文档标准模板百度网盘下载 - 下载密码：uu1f]]></content>
      <categories>
        <category>method</category>
        <category>软件工程</category>
      </categories>
      <tags>
        <tag>method</tag>
        <tag>软件工程</tag>
        <tag>项目管理</tag>
        <tag>方法论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Gitbook 打造你的电子书]]></title>
    <url>%2Fblog%2F2017%2F09%2F04%2Ftools%2Fgitbook%2F</url>
    <content type="text"><![CDATA[使用 Gitbook 打造你的电子书 本文详细讲解了 Gitbook 生成电子书的完整过程，内容包括：安装、命令、配置、文档结构、生成电子书、部署。 限于篇幅，本文不介绍任何 Gitbook 定制化页面的内容。 想看看 Gitbook 在线电子书效果，请猛戳这里：gitbook-notes 📓 本文已归档到：「blog」 概述 GitBook 安装 GitBook 命令 Gitbook 目录结构 Gitbook 配置 生成电子书 Gitbook 部署 参考资料 概述 GitBook 是使用 GitHub / Git 和 Markdown（或 AsciiDoc）构建漂亮书籍的命令行工具（和 Node.js 库）。 GitBook 可以将您的内容作为网站（可定制和可扩展）或电子书（PDF，ePub 或 Mobi）输出。 GitBook.com 是使用 GitBook 格式创建和托管图书的在线平台。它提供托管，协作功能和易于使用的编辑器。 GitBook 安装 本地安装 环境要求 安装 GitBook 是很简单的。您的系统只需要满足这两个要求： NodeJS（推荐使用 v4.0.0 及以上版本） Windows，Linux，Unix 或 Mac OS X 通过 NPM 安装 安装 GitBook 的最好办法是通过 NPM。在终端提示符下，只需运行以下命令即可安装 GitBook： $ npm install gitbook-cli -g gitbook-cli 是 GitBook 的一个命令行工具。它将自动安装所需版本的 GitBook 来构建一本书。 执行下面的命令，查看 GitBook 版本，以验证安装成功。 $ gitbook -V 安装历史版本 gitbook-cli 可以轻松下载并安装其他版本的 GitBook 来测试您的书籍： $ gitbook fetch beta 使用 gitbook ls-remote 会列举可以下载的版本。 创建一本书 初始化 GitBook 可以设置一个样板书： $ gitbook init 如果您希望将书籍创建到一个新目录中，可以通过运行 gitbook init ./directory 这样做。 构建 使用下面的命令，会在项目的目录下生成一个 _book 目录，里面的内容为静态站点的资源文件： $ gitbook build Debugging 您可以使用选项 --log=debug 和 --debug 来获取更好的错误消息（使用堆栈跟踪）。例如： $ gitbook build ./ --log=debug --debug 启动服务 使用下列命令会运行一个 web 服务, 通过 http://localhost:4000/ 可以预览书籍 $ gitbook serve GitBook 命令 这里主要介绍一下 GitBook 的命令行工具 gitbook-cli 的一些命令, 首先说明两点: gitbook-cli 和 gitbook 是两个软件 gitbook-cli 会将下载的 gitbook 的不同版本放到 \~/.gitbook中, 可以通过设置GITBOOK_DIR环境变量来指定另外的文件夹 列出 gitbook 所有的命令 gitbook help 输出 gitbook-cli 的帮助信息 gitbook --help 生成静态网页 gitbook build 生成静态网页并运行服务器 gitbook serve 生成时指定 gitbook 的版本, 本地没有会先下载 gitbook build --gitbook=2.0.1 列出本地所有的 gitbook 版本 gitbook ls 列出远程可用的 gitbook 版本 gitbook ls-remote 安装对应的 gitbook 版本 gitbook fetch 标签/版本号 更新到 gitbook 的最新版本 gitbook update 卸载对应的 gitbook 版本 gitbook uninstall 2.0.1 指定 log 的级别 gitbook build --log=debug 输出错误信息 gitbook builid --debug Gitbook 目录结构 GitBook 项目结构 GitBook 使用简单的目录结构。在 SUMMARY （即 SUMMARY.md 文件）中列出的所有 Markdown / Asciidoc 文件将被转换为 HTML。多语言书籍结构略有不同。 一个基本的 GitBook 电子书结构通常如下： .├── book.json├── README.md├── SUMMARY.md├── chapter-1/| ├── README.md| └── something.md└── chapter-2/ ├── README.md └── something.md GitBook 特殊文件的功能： 文件 描述 book.json 配置数据 (optional) README.md 电子书的前言或简介 (required) SUMMARY.md 电子书目录 (optional) GLOSSARY.md 词汇/注释术语列表 (optional) 静态文件和图片 静态文件是在 SUMMARY.md 中未列出的文件。除非被忽略，否则所有静态文件都将复制到输出路径。 忽略文件和文件夹 GitBook 将读取 .gitignore，.bookignore 和 .ignore 文件，以获取要过滤的文件和文件夹。这些文件中的格式遵循 .gitignore 的规则： # This is a comment# Ignore the file test.mdtest.md# Ignore everything in the directory "bin"bin/* 项目与子目录集成 对于软件项目，您可以使用子目录（如 docs/ ）来存储项目文档的图书。您可以配置根选项来指示 GitBook 可以找到该图书文件的文件夹： .├── book.json└── docs/ ├── README.md └── SUMMARY.md 在 book.json 中配置以下内容： &#123; "root": "./docs"&#125; Summary GitBook 使用 SUMMARY.md 文件来定义本书的章节和子章节的结构。 SUMMARY.md 文件用于生成本书的目录。 SUMMARY.md 的格式是一个链接列表。链接的标题将作为章节的标题，链接的目标是该章节文件的路径。 向父章节添加嵌套列表将创建子章节。 简单示例： # Summary* [Part I](part1/README.md) * [Writing is nice](part1/writing.md) * [GitBook is nice](part1/gitbook.md)* [Part II](part2/README.md) * [We love feedback](part2/feedback_please.md) * [Better tools for authors](part2/better_tools.md) 每章都有一个专用页面（part#/README.md），并分为子章节。 锚点 目录中的章节可以使用锚点指向文件的特定部分。 # Summary### Part I* [Part I](part1/README.md) * [Writing is nice](part1/README.md#writing) * [GitBook is nice](part1/README.md#gitbook)* [Part II](part2/README.md) * [We love feedback](part2/README.md#feedback) * [Better tools for authors](part2/README.md#tools) 部分 目录可以分为以标题或水平线 ---- 分隔的部分： # Summary### Part I* [Writing is nice](part1/writing.md)* [GitBook is nice](part1/gitbook.md)### Part II* [We love feedback](part2/feedback_please.md)* [Better tools for authors](part2/better_tools.md)----* [Last part without title](part3/title.md) Parts 只是章节组，没有专用页面，但根据主题，它将在导航中显示。 页面 Markdown 语法 默认情况下，GitBook 的大多数文件都使用 Markdown 语法。 GitBook 推荐使用这种语法。所使用的语法类似于 GitHub Flavored Markdown syntax 。 此外，你还可以选择 AsciiDoc 语法。 页面内容示例： # Title of the chapterThis is a great introduction.## Section 1Markdown will dictates _most_ of your **book's structure**## Section 2... 页面前言 页面可以包含一个可选的前言。它可以用于定义页面的描述。前面的事情必须是文件中的第一件事，必须采取在三虚线之间设置的有效 YAML 的形式。这是一个基本的例子： ---description: This is a short description of my page---# The content of my page... Glossary 允许您指定要显示为注释的术语及其各自的定义。根据这些术语，GitBook 将自动构建索引并突出显示这些术语。 GLOSSARY.md 的格式是 h2 标题的列表，以及描述段落： ## TermDefinition for this term## Another termWith it's definition, this can contain bold textand all other kinds of inline markup ... Gitbook 配置 GitBook 允许您使用灵活的配置自定义您的电子书。 这些选项在 book.json 文件中指定。对于不熟悉 JSON 语法的作者，您可以使用 JSONlint 等工具验证语法。 常规设置 变量 描述 root 包含所有图书文件的根文件夹的路径，除了 book.json structure 指定自述文件，摘要，词汇表等的路径，参考 Structure paragraph. title 您的书名，默认值是从 README 中提取出来的。在 GitBook.com 上，这个字段是预填的。 description 您的书籍的描述，默认值是从 README 中提取出来的。在 GitBook.com 上，这个字段是预填的。 author 作者名。在 GitBook.com 上，这个字段是预填的。 isbn 国际标准书号 ISBN language 本书的语言类型 —— ISO code 。默认值是 en direction 文本阅读顺序。可以是 rtl （从右向左）或 ltr （从左向右），默认值依赖于 language 的值。 gitbook 应该使用的 GitBook 版本。使用 SemVer 规范，并接受类似于 “&gt; = 3.0.0” 的条件。 author 作者姓名，在 GitBook.com 上，这个字段是预先填写的。 例： "author" : "victor zhang" description 电子书的描述，默认值是从 README 中提取出来的。在 GitBook.com 上，这个字段是预先填写的。 例： "description" : "Gitbook 教程" direction 文本的方向。可以是 rtl 或 ltr，默认值取决于语言的值。 例： "direction" : "ltr" gitbook 应该使用的 GitBook 版本。使用 SemVer 规范，接受类似于 &gt;=3.0.0 的条件。 例： "gitbook" : "3.0.0","gitbook" : "&gt;=3.0.0" language Gitbook 使用的语言, 版本 2.6.4 中可选的语言如下： en, ar, bn, cs, de, en, es, fa, fi, fr, he, it, ja, ko, no, pl, pt, ro, ru, sv, uk, vi, zh-hans, zh-tw 例： "language" : "zh-hans", links 在左侧导航栏添加链接信息 例： "links" : &#123; "sidebar" : &#123; "Home" : "https://github.com/dunwu/gitbook-notes" &#125;&#125; root 包含所有图书文件的根文件夹的路径， book.json 文件除外。 例： "root" : "./docs", structure 指定 Readme、Summary、Glossary 和 Languages 对应的文件名。 styles 自定义页面样式， 默认情况下各 generator 对应的 css 文件 例： "styles": &#123; "website": "styles/website.css", "ebook": "styles/ebook.css", "pdf": "styles/pdf.css", "mobi": "styles/mobi.css", "epub": "styles/epub.css"&#125; 例如要使 h1、h2 标签有下边框， 可以在 website.css 中设置 h1,h2 &#123; border-bottom: 1px solid #efeaea;&#125; title 电子书的书名，默认值是从 README 中提取出来的。在 GitBook.com 上，这个字段是预先填写的。 例： "title" : "gitbook-notes", plugins 插件及其配置在 book.json 中指定。有关详细信息。 自 3.0.0 版本开始，GitBook 可以使用主题。有关详细信息，请参阅 the theming section 。 变量 描述 plugins 要加载的插件列表 pluginsConfig 插件的配置 添加插件 "plugins": [ "splitter"] 添加新插件之后需要运行 gitbook install 来安装新的插件 去除自带插件 Gitbook 默认带有 5 个插件： highlight search sharing font-settings livereload "plugins": [ "-search"] structure 除了 root 属性之外，您可以指定 Readme，Summary，Glossary 和 Languages 的名称（而不是使用默认名称，如 README.md）。这些文件必须在项目的根目录下（或 root 的根目录，如果你在 book.json 中配置了 root 属性）。不接受的路径，如：dir / MY_README.md。 变量 描述 structure.readme Readme 文件名（默认值是 README.md ） structure.summary Summary 文件名（默认值是 SUMMARY.md ） structure.glossary Glossary 文件名（默认值是 GLOSSARY.md ） structure.languages Languages 文件名（默认值是 LANGS.md ） pdf 可以使用 book.json 中的一组选项来定制 PDF 输出： Variable Description pdf.pageNumbers 将页码添加到每个页面的底部（默认为 true） pdf.fontSize 基本字体大小（默认是 12） pdf.fontFamily 基本字体样式（默认是 Arial） pdf.paperSize 页面尺寸，选项有： 'a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'legal', 'letter' （默认值是 a4） pdf.margin.top 上边界（默认值是 56） pdf.margin.bottom 下边界（默认值是 56） pdf.margin.right 右边界（默认值是 62） pdf.margin.left 左边界（默认值是 62） 生成电子书 GitBook 可以生成一个网站，但也可以输出内容作为电子书（ePub，Mobi，PDF）。 # Generate a PDF file$ gitbook pdf ./ ./mybook.pdf# Generate an ePub file$ gitbook epub ./ ./mybook.epub# Generate a Mobi file$ gitbook mobi ./ ./mybook.mobi 安装 ebook-convert ebook-convert 可以用来生成电子书（epub，mobi，pdf）。 GNU/Linux 安装 Calibre application. $ sudo aptitude install calibre 在一些 GNU / Linux 发行版中，节点被安装为 nodejs，您需要手动创建一个符号链接： $sudo ln -s /usr/bin/nodejs /usr/bin/node OS X 下载 Calibre application。将 calibre.app 移动到应用程序文件夹后，创建一个符号链接到 ebook-convert 工具： $ sudo ln -s ~/Applications/calibre.app/Contents/MacOS/ebook-convert /usr/bin 您可以使用 $PATH 中的任何目录替换 /usr/bin 。 封面 封面用于所有电子书格式。您可以自己提供一个，也可以使用 autocover plugin 生成一个。 要提供封面，请将 cover.jpg 文件放在书本的根目录下。添加一个 cover_small.jpg 将指定一个较小版本的封面。封面应为 JPEG 文件。 好的封面应该遵守以下准则： cover.jpg 的尺寸为 1800x2360 像素，cover_small.jpg 为 200x262 没有边界 清晰可见的书名 任何重要的文字应该在小版本中可见 Gitbook 部署 托管到 gitbook.com GitBook.com 是使用 GitBook 格式创建和托管图书的在线平台。它提供托管，协作功能和易于使用的编辑器。 创建新书 如下图所示，根据个人需求，选择一个模板创建你的电子书。 设置书的基本信息 clone 到本地 Gitbook.com 会为每本书创建一个 git 仓库。 如下图所示，拷贝 git 地址，然后 git clone 到本地。 发布 在本地按照 Gitbook 规范编辑电子书，然后 git push 到 Gitbook 的远程仓库。 默认访问地址是：https://用户名.gitbooks.io/项目名/content/ 例如：我的用户名为 dunwu，一个电子书项目名为 test，则访问路径是： https://dunwu.gitbooks.io/test/content/ 当然，如果你有自己的域名，也可以设置 Domains 选项，来指定访问路径为你的域。 托管到 Github 如果你不希望使用 Gitbook 的仓库，而是想直接使用 Github 的仓库，也是可以的。 首先，你需要绑定你的 Github 账号。最简单的方式当然就是登录 Gitbook.com 时使用 Github 账号登录方式了。否则，你也可以在 Account Settings 中的 Github 设置选项中去进行绑定。 绑定了 Github 账号后，你可以在新建电子书时，选择从一个指定的 Github 仓库导入电子书项目。参考下图： 只要你指定的 Github 仓库中的文档内容符合 Gitbook 规范，Gitbook 就会自动根据你的每次更新去构建生成电子书网站。 默认访问地址是： https://Github用户名.gitbooks.io/Github 仓库/content/ 例如：我的用户名为 dunwu，Github 仓库名为 gitbook-notes，则访问路径是： https://dunwu.gitbooks.io/gitbook-notes/content/ 托管到 Github Pages 也许你以前也了解 Github 的一个功能： GitHub Pages 。它允许用户在 GitHub 仓库托管你的个人、组织或项目的静态页面（自动识别 html、css、javascript）。 建立 xxx.github.io 仓库 要使用这个特性，首先，你必须建立一个严格遵循以下命名要求的仓库：Github账号名.github.io举例，我的 Github 账号为 dunwu，则这个仓库应该叫 dunwu.github.io。通常，这个仓库被用来作为个人或组织的博客。 建立 gh-pages 分支 完成第 1 步后，在任意一个 Github 仓库中建立一个名为 gh-pages 的分支。只要 gh-pages 中的内容符合一个静态站点要求，就可以在如下地址中进行访问：https://Github用户名.gitbooks.io/Github 仓库 。例如：我的一个 Github 仓库名为 react-notes，则访问路径是：https://dunwu.github.io/react-notes 自动化发布到 gh-pages 如果每次都手动 git push 到远程 gh-pages 分支，略有点麻烦。 怎么实现自动化发布呢？ 有两种方法： 使用 gh-pages 插件 如果你了解 Nodejs，那么最简单的发布方式就是使用 gh-pages 插件。 先在本地安装插件 $ npm i -D gh-pages 然后，在 package.json 文件中添加脚本命令： 如下：-d 命令参数后面是要发布的静态站点内容的目录 "scripts": &#123; "deploy": "gh-pages -d build"&#125;, 脚本 写一个执行 git 命令的脚本就搞定了。 下面的脚本无论是在 bat 或 sh 脚本中都可以执行。 cd buildgit initgit checkout -b gh-pagesgit add .git commit -am "Update"git push git@github.com:dunwu/gitbook-notes gh-pages --force" 参考资料 官方资源 Gitbook Github Gitbook 官网 Gitbook Toolchain 文档 Gitbook 帮助中心 教程资源 gitbook-use by zhangjikai 工具 Gitbook 编辑器]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>gitbook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2Fblog%2F2016%2F10%2F10%2Ftools%2Fregex%2F</url>
    <content type="text"><![CDATA[正则表达式 📓 本文已归档到：「blog」 简介 基本元字符 等价字符 元字符优先级顺序 捕获与非捕获 反向引用 非捕获组 零宽断言 贪婪与懒惰 最实用的正则 速查元字符字典 参考资料 简介 为了理解下面章节的内容，你需要先了解一些基本概念。 正则表达式 - 正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。 元字符 - 元字符(metacharacters)就是正则表达式中具有特殊意义的专用字符。 普通字符 - 普通字符包括没有显式指定为元字符的所有可打印和不可打印字符。这包括所有大写和小写字母、所有数字、所有标点符号和一些其他符号。 基本元字符 正则表达式的元字符难以记忆，很大程度上是因为有很多为了简化表达而出现的等价字符。 而实际上最基本的元字符，并没有那么多。对于大部分的场景，基本元字符都可以搞定。 让我们从一个个实例出发，由浅入深的去体会正则的奥妙。 多选 - | 例 匹配一个确定的字符串 checkMatches("abc", "abc"); 如果要匹配一个确定的字符串，非常简单，如例 1 所示。 如果你不确定要匹配的字符串，希望有多个选择，怎么办？ 答案是：使用元字符| ，它的含义是或。 例 匹配多个可选的字符串 // 测试正则表达式字符：|Assert.assertTrue(checkMatches("yes|no", "yes"));Assert.assertTrue(checkMatches("yes|no", "no"));Assert.assertFalse(checkMatches("yes|no", "right")); 输出 yes matches： yes|nono matches： yes|noright not matches： yes|no 分组 - () 如果你希望表达式由多个子表达式组成，你可以使用 ()。 例 匹配组合字符串 Assert.assertTrue(checkMatches("(play|end)(ing|ed)", "ended"));Assert.assertTrue(checkMatches("(play|end)(ing|ed)", "ending"));Assert.assertTrue(checkMatches("(play|end)(ing|ed)", "playing"));Assert.assertTrue(checkMatches("(play|end)(ing|ed)", "played")); 输出 ended matches： (play|end)(ing|ed)ending matches： (play|end)(ing|ed)playing matches： (play|end)(ing|ed)played matches： (play|end)(ing|ed) 指定单字符有效范围 - [] 前面展示了如何匹配字符串，但是很多时候你需要精确的匹配一个字符，这时可以使用[] 。 例 字符在指定范围 // 测试正则表达式字符：[]Assert.assertTrue(checkMatches("[abc]", "b")); // 字符只能是a、b、cAssert.assertTrue(checkMatches("[a-z]", "m")); // 字符只能是a - zAssert.assertTrue(checkMatches("[A-Z]", "O")); // 字符只能是A - ZAssert.assertTrue(checkMatches("[a-zA-Z]", "K")); // 字符只能是a - z和A - ZAssert.assertTrue(checkMatches("[a-zA-Z]", "k"));Assert.assertTrue(checkMatches("[0-9]", "5")); // 字符只能是0 - 9 输出 b matches： [abc]m matches： [a-z]O matches： [A-Z]K matches： [a-zA-Z]k matches： [a-zA-Z]5 matches： [0-9] 指定单字符无效范围 - [^] 例 字符不能在指定范围 如果需要匹配一个字符的逆操作，即字符不能在指定范围，可以使用[^]。 // 测试正则表达式字符：[^]Assert.assertFalse(checkMatches("[^abc]", "b")); // 字符不能是a、b、cAssert.assertFalse(checkMatches("[^a-z]", "m")); // 字符不能是a - zAssert.assertFalse(checkMatches("[^A-Z]", "O")); // 字符不能是A - ZAssert.assertFalse(checkMatches("[^a-zA-Z]", "K")); // 字符不能是a - z和A - ZAssert.assertFalse(checkMatches("[^a-zA-Z]", "k"));Assert.assertFalse(checkMatches("[^0-9]", "5")); // 字符不能是0 - 9 输出 b not matches： [^abc]m not matches： [^a-z]O not matches： [^A-Z]K not matches： [^a-zA-Z]k not matches： [^a-zA-Z]5 not matches： [^0-9] 限制字符数量 - {} 如果想要控制字符出现的次数，可以使用{}。 字符 描述 {n} n 是一个非负整数。匹配确定的 n 次。 {n,} n 是一个非负整数。至少匹配 n 次。 {n,m} m 和 n 均为非负整数，其中 n &lt;= m。最少匹配 n 次且最多匹配 m 次。 例 限制字符出现次数 // &#123;n&#125;: n 是一个非负整数。匹配确定的 n 次。checkMatches("ap&#123;1&#125;", "a");checkMatches("ap&#123;1&#125;", "ap");checkMatches("ap&#123;1&#125;", "app");checkMatches("ap&#123;1&#125;", "apppppppppp");// &#123;n,&#125;: n 是一个非负整数。至少匹配 n 次。checkMatches("ap&#123;1,&#125;", "a");checkMatches("ap&#123;1,&#125;", "ap");checkMatches("ap&#123;1,&#125;", "app");checkMatches("ap&#123;1,&#125;", "apppppppppp");// &#123;n,m&#125;: m 和 n 均为非负整数，其中 n &lt;= m。最少匹配 n 次且最多匹配 m 次。checkMatches("ap&#123;2,5&#125;", "a");checkMatches("ap&#123;2,5&#125;", "ap");checkMatches("ap&#123;2,5&#125;", "app");checkMatches("ap&#123;2,5&#125;", "apppppppppp"); 输出 a not matches： ap&#123;1&#125;ap matches： ap&#123;1&#125;app not matches： ap&#123;1&#125;apppppppppp not matches： ap&#123;1&#125;a not matches： ap&#123;1,&#125;ap matches： ap&#123;1,&#125;app matches： ap&#123;1,&#125;apppppppppp matches： ap&#123;1,&#125;a not matches： ap&#123;2,5&#125;ap not matches： ap&#123;2,5&#125;app matches： ap&#123;2,5&#125;apppppppppp not matches： ap&#123;2,5&#125; 转义字符 - / 如果想要查找元字符本身，你需要使用转义符，使得正则引擎将其视作一个普通字符，而不是一个元字符去处理。 * 的转义字符：\*+ 的转义字符：\+? 的转义字符：\?^ 的转义字符：\^$ 的转义字符：\$. 的转义字符：\. 如果是转义符\本身，你也需要使用\\ 。 指定表达式字符串的开始和结尾 - ^、$ 如果希望匹配的字符串必须以特定字符串开头，可以使用^ 。 注：请特别留意，这里的^ 一定要和 [^] 中的 “^” 区分。 例 限制字符串头部 Assert.assertTrue(checkMatches("^app[a-z]&#123;0,&#125;", "apple")); // 字符串必须以app开头Assert.assertFalse(checkMatches("^app[a-z]&#123;0,&#125;", "aplause")); 输出 apple matches： ^app[a-z]&#123;0,&#125;aplause not matches： ^app[a-z]&#123;0,&#125; 如果希望匹配的字符串必须以特定字符串开头，可以使用$ 。 例 限制字符串尾部 Assert.assertTrue(checkMatches("[a-z]&#123;0,&#125;ing$", "playing")); // 字符串必须以ing结尾Assert.assertFalse(checkMatches("[a-z]&#123;0,&#125;ing$", "long")); 输出 playing matches： [a-z]&#123;0,&#125;ing$long not matches： [a-z]&#123;0,&#125;ing$ 等价字符 等价字符，顾名思义，就是对于基本元字符表达的一种简化（等价字符的功能都可以通过基本元字符来实现）。 在没有掌握基本元字符之前，可以先不用理会，因为很容易把人绕晕。 等价字符的好处在于简化了基本元字符的写法。 表示某一类型字符的等价字符 下表中的等价字符都表示某一类型的字符。 字符 描述 . 匹配除“\n”之外的任何单个字符。 \d 匹配一个数字字符。等价于[0-9]。 \D 匹配一个非数字字符。等价于[^0-9]。 \w 匹配包括下划线的任何单词字符。类似但不等价于“[A-Za-z0-9_]”，这里的单词字符指的是 Unicode 字符集。 \W 匹配任何非单词字符。 \s 匹配任何不可见字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]。 \S 匹配任何可见字符。等价于[ \f\n\r\t\v]。 案例 基本等价字符的用法 // 匹配除“\n”之外的任何单个字符Assert.assertTrue(checkMatches(".&#123;1,&#125;", "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_"));Assert.assertTrue(checkMatches(".&#123;1,&#125;", "~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\"));Assert.assertFalse(checkMatches(".", "\n"));Assert.assertFalse(checkMatches("[^\n]", "\n"));// 匹配一个数字字符。等价于[0-9]Assert.assertTrue(checkMatches("\\d&#123;1,&#125;", "0123456789"));// 匹配一个非数字字符。等价于[^0-9]Assert.assertFalse(checkMatches("\\D&#123;1,&#125;", "0123456789"));// 匹配包括下划线的任何单词字符。类似但不等价于“[A-Za-z0-9_]”，这里的单词字符指的是Unicode字符集Assert.assertTrue(checkMatches("\\w&#123;1,&#125;", "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_"));Assert.assertFalse(checkMatches("\\w&#123;1,&#125;", "~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\"));// 匹配任何非单词字符Assert.assertFalse(checkMatches("\\W&#123;1,&#125;", "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_"));Assert.assertTrue(checkMatches("\\W&#123;1,&#125;", "~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\"));// 匹配任何不可见字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]Assert.assertTrue(checkMatches("\\s&#123;1,&#125;", " \f\r\n\t"));// 匹配任何可见字符。等价于[^ \f\n\r\t\v]Assert.assertFalse(checkMatches("\\S&#123;1,&#125;", " \f\r\n\t")); 输出 ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_ matches： .&#123;1,&#125;~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\ matches： .&#123;1,&#125;\n not matches： .\n not matches： [^\n]0123456789 matches： \\d&#123;1,&#125;0123456789 not matches： \\D&#123;1,&#125;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_ matches： \\w&#123;1,&#125;~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\ not matches： \\w&#123;1,&#125;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_ not matches： \\W&#123;1,&#125;~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\ matches： \\W&#123;1,&#125; \f\r\n\t matches： \\s&#123;1,&#125; \f\r\n\t not matches： \\S&#123;1,&#125; 限制字符数量的等价字符 在基本元字符章节中，已经介绍了限制字符数量的基本元字符 - {} 。 此外，还有 *、+、? 这个三个为了简化写法而出现的等价字符，我们来认识一下。 字符 描述 * 匹配前面的子表达式零次或多次。等价于{0,}。 + 匹配前面的子表达式一次或多次。等价于{1,}。 ? 匹配前面的子表达式零次或一次。等价于 {0,1}。 案例 限制字符数量的等价字符 // *: 匹配前面的子表达式零次或多次。* 等价于&#123;0,&#125;。checkMatches("ap*", "a");checkMatches("ap*", "ap");checkMatches("ap*", "app");checkMatches("ap*", "apppppppppp");// +: 匹配前面的子表达式一次或多次。+ 等价于 &#123;1,&#125;。checkMatches("ap+", "a");checkMatches("ap+", "ap");checkMatches("ap+", "app");checkMatches("ap+", "apppppppppp");// ?: 匹配前面的子表达式零次或一次。? 等价于 &#123;0,1&#125;。checkMatches("ap?", "a");checkMatches("ap?", "ap");checkMatches("ap?", "app");checkMatches("ap?", "apppppppppp"); 输出 a matches： ap*ap matches： ap*app matches： ap*apppppppppp matches： ap*a not matches： ap+ap matches： ap+app matches： ap+apppppppppp matches： ap+a matches： ap?ap matches： ap?app not matches： ap?apppppppppp not matches： ap? 元字符优先级顺序 正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。 下表从最高到最低说明了各种正则表达式运算符的优先级顺序： 运算符 说明 \ 转义符 (), (?😃, (?=), [] 括号和中括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, *任何元字符、任何字符* 定位点和序列 | 替换 字符具有高于替换运算符的优先级，使得“m|food”匹配“m”或“food”。若要匹配“mood”或“food”，请使用括号创建子表达式，从而产生“(m|f)ood”。 分组构造 在基本元字符章节，提到了 () 字符可以用来对表达式分组。实际上分组还有更多复杂的用法。 所谓分组构造，是用来描述正则表达式的子表达式，用于捕获字符串中的子字符串。 捕获与非捕获 下表为分组构造中的捕获和非捕获分类。 表达式 描述 捕获或非捕获 (exp) 匹配的子表达式 捕获 (?&lt;name&gt;exp) 命名的反向引用 捕获 (?:exp) 非捕获组 非捕获 (?=exp) 零宽度正预测先行断言 非捕获 (?!exp) 零宽度负预测先行断言 非捕获 (?&lt;=exp) 零宽度正回顾后发断言 非捕获 (?&lt;!exp) 零宽度负回顾后发断言 非捕获 注：Java 正则引擎不支持平衡组。 反向引用 带编号的反向引用 带编号的反向引用使用以下语法：\number 其中number 是正则表达式中捕获组的序号位置。 例如，\4 匹配第四个捕获组的内容。 如果正则表达式模式中未定义number，则将发生分析错误 例 匹配重复的单词和紧随每个重复的单词的单词(不命名子表达式) // (\w+)\s\1\W(\w+) 匹配重复的单词和紧随每个重复的单词的单词Assert.assertTrue(findAll("(\\w+)\\s\\1\\W(\\w+)", "He said that that was the the correct answer.") &gt; 0); 输出 regex = (\w+)\s\1\W(\w+), content: He said that that was the the correct answer.[1th] start: 8, end: 21, group: that that was[2th] start: 22, end: 37, group: the the correct 说明 (\w+): 匹配一个或多个单词字符。 \s: 与空白字符匹配。 \1: 匹配第一个组，即(\w+)。 \W: 匹配包括空格和标点符号的一个非单词字符。 这样可以防止正则表达式模式匹配从第一个捕获组的单词开头的单词。 命名的反向引用 命名后向引用通过使用下面的语法进行定义：\k&lt;name &gt; 例 匹配重复的单词和紧随每个重复的单词的单词(命名子表达式) // (?&lt;duplicateWord&gt;\w+)\s\k&lt;duplicateWord&gt;\W(?&lt;nextWord&gt;\w+) 匹配重复的单词和紧随每个重复的单词的单词Assert.assertTrue(findAll("(?&lt;duplicateWord&gt;\\w+)\\s\\k&lt;duplicateWord&gt;\\W(?&lt;nextWord&gt;\\w+)", "He said that that was the the correct answer.") &gt; 0); 输出 regex = (?&lt;duplicateWord&gt;\w+)\s\k&lt;duplicateWord&gt;\W(?&lt;nextWord&gt;\w+), content: He said that that was the the correct answer.[1th] start: 8, end: 21, group: that that was[2th] start: 22, end: 37, group: the the correct 说明 (?\w+): 匹配一个或多个单词字符。 命名此捕获组 duplicateWord。 \s: 与空白字符匹配。 \k: 匹配名为 duplicateWord 的捕获的组。 \W: 匹配包括空格和标点符号的一个非单词字符。 这样可以防止正则表达式模式匹配从第一个捕获组的单词开头的单词。 (?\w+): 匹配一个或多个单词字符。 命名此捕获组 nextWord。 非捕获组 (?:exp) 表示当一个限定符应用到一个组，但组捕获的子字符串并非所需时，通常会使用非捕获组构造。 例 匹配以.结束的语句。 // 匹配由句号终止的语句。Assert.assertTrue(findAll("(?:\\b(?:\\w+)\\W*)+\\.", "This is a short sentence. Never end") &gt; 0); 输出 regex = (?:\b(?:\w+)\W*)+\., content: This is a short sentence. Never end[1th] start: 0, end: 25, group: This is a short sentence. 零宽断言 用于查找在某些内容(但并不包括这些内容)之前或之后的东西，也就是说它们像\b,^,$那样用于指定一个位置，这个位置应该满足一定的条件(即断言)，因此它们也被称为零宽断言。 表达式 描述 (?=exp) 匹配 exp 前面的位置 (?&lt;=exp) 匹配 exp 后面的位置 (?!exp) 匹配后面跟的不是 exp 的位置 (?&lt;!exp) 匹配前面不是 exp 的位置 匹配 exp 前面的位置 (?=exp) 表示输入字符串必须匹配子表达式中的正则表达式模式，尽管匹配的子字符串未包含在匹配结果中。 // \b\w+(?=\sis\b) 表示要捕获is之前的单词Assert.assertTrue(findAll("\\b\\w+(?=\\sis\\b)", "The dog is a Malamute.") &gt; 0);Assert.assertFalse(findAll("\\b\\w+(?=\\sis\\b)", "The island has beautiful birds.") &gt; 0);Assert.assertFalse(findAll("\\b\\w+(?=\\sis\\b)", "The pitch missed home plate.") &gt; 0);Assert.assertTrue(findAll("\\b\\w+(?=\\sis\\b)", "Sunday is a weekend day.") &gt; 0); 输出 regex = \b\w+(?=\sis\b), content: The dog is a Malamute.[1th] start: 4, end: 7, group: dogregex = \b\w+(?=\sis\b), content: The island has beautiful birds.not foundregex = \b\w+(?=\sis\b), content: The pitch missed home plate.not foundregex = \b\w+(?=\sis\b), content: Sunday is a weekend day.[1th] start: 0, end: 6, group: Sunday 说明 \b: 在单词边界处开始匹配。 \w+: 匹配一个或多个单词字符。 (?=\sis\b): 确定单词字符是否后接空白字符和字符串“is”，其在单词边界处结束。 如果如此，则匹配成功。 匹配 exp 后面的位置 (?&lt;=exp) 表示子表达式不得在输入字符串当前位置左侧出现，尽管子表达式未包含在匹配结果中。零宽度正回顾后发断言不会回溯。 // (?&lt;=\b20)\d&#123;2&#125;\b 表示要捕获以20开头的数字的后面部分Assert.assertTrue(findAll("(?&lt;=\\b20)\\d&#123;2&#125;\\b", "2010 1999 1861 2140 2009") &gt; 0); 输出 regex = (?&lt;=\b20)\d&#123;2&#125;\b, content: 2010 1999 1861 2140 2009[1th] start: 2, end: 4, group: 10[2th] start: 22, end: 24, group: 09 说明 \d{2}: 匹配两个十进制数字。 {?&lt;=\b20): 如果两个十进制数字的字边界以小数位数“20”开头，则继续匹配。 \b: 在单词边界处结束匹配。 匹配后面跟的不是 exp 的位置 (?!exp) 表示输入字符串不得匹配子表达式中的正则表达式模式，尽管匹配的子字符串未包含在匹配结果中。 例 捕获未以“un”开头的单词 // \b(?!un)\w+\b 表示要捕获未以“un”开头的单词Assert.assertTrue(findAll("\\b(?!un)\\w+\\b", "unite one unethical ethics use untie ultimate") &gt; 0); 输出 regex = \b(?!un)\w+\b, content: unite one unethical ethics use untie ultimate[1th] start: 6, end: 9, group: one[2th] start: 20, end: 26, group: ethics[3th] start: 27, end: 30, group: use[4th] start: 37, end: 45, group: ultimate 说明 \b: 在单词边界处开始匹配。 (?!un): 确定接下来的两个的字符是否为“un”。 如果没有，则可能匹配。 \w+: 匹配一个或多个单词字符。 \b: 在单词边界处结束匹配。 匹配前面不是 exp 的位置 (?&lt;!exp) 表示子表达式不得在输入字符串当前位置的左侧出现。 但是，任何不匹配子表达式 的子字符串不包含在匹配结果中。 例 捕获任意工作日 // (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b 表示要捕获任意工作日（即周一到周五）Assert.assertTrue(findAll("(?&lt;!(Saturday|Sunday) )\\b\\w+ \\d&#123;1,2&#125;, \\d&#123;4&#125;\\b", "Monday February 1, 2010") &gt; 0);Assert.assertTrue(findAll("(?&lt;!(Saturday|Sunday) )\\b\\w+ \\d&#123;1,2&#125;, \\d&#123;4&#125;\\b", "Wednesday February 3, 2010") &gt; 0);Assert.assertFalse(findAll("(?&lt;!(Saturday|Sunday) )\\b\\w+ \\d&#123;1,2&#125;, \\d&#123;4&#125;\\b", "Saturday February 6, 2010") &gt; 0);Assert.assertFalse(findAll("(?&lt;!(Saturday|Sunday) )\\b\\w+ \\d&#123;1,2&#125;, \\d&#123;4&#125;\\b", "Sunday February 7, 2010") &gt; 0);Assert.assertTrue(findAll("(?&lt;!(Saturday|Sunday) )\\b\\w+ \\d&#123;1,2&#125;, \\d&#123;4&#125;\\b", "Monday, February 8, 2010") &gt; 0); 输出 regex = (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b, content: Monday February 1, 2010[1th] start: 7, end: 23, group: February 1, 2010regex = (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b, content: Wednesday February 3, 2010[1th] start: 10, end: 26, group: February 3, 2010regex = (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b, content: Saturday February 6, 2010not foundregex = (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b, content: Sunday February 7, 2010not foundregex = (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b, content: Monday, February 8, 2010[1th] start: 8, end: 24, group: February 8, 2010 贪婪与懒惰 当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符。以这个表达式为例：a.*b，它将会匹配最长的以 a 开始，以 b 结束的字符串。如果用它来搜索 aabab 的话，它会匹配整个字符串 aabab。这被称为贪婪匹配。 有时，我们更需要懒惰匹配，也就是匹配尽可能少的字符。前面给出的限定符都可以被转化为懒惰匹配模式，只要在它后面加上一个问号?。这样.*?就意味着匹配任意数量的重复，但是在能使整个匹配成功的前提下使用最少的重复。 表达式 描述 *? 重复任意次，但尽可能少重复 +? 重复 1 次或更多次，但尽可能少重复 ?? 重复 0 次或 1 次，但尽可能少重复 {n,m}? 重复 n 到 m 次，但尽可能少重复 {n,}? 重复 n 次以上，但尽可能少重复 例 Java 正则中贪婪与懒惰的示例 // 贪婪匹配Assert.assertTrue(findAll("a\\w*b", "abaabaaabaaaab") &gt; 0);// 懒惰匹配Assert.assertTrue(findAll("a\\w*?b", "abaabaaabaaaab") &gt; 0);Assert.assertTrue(findAll("a\\w+?b", "abaabaaabaaaab") &gt; 0);Assert.assertTrue(findAll("a\\w??b", "abaabaaabaaaab") &gt; 0);Assert.assertTrue(findAll("a\\w&#123;0,4&#125;?b", "abaabaaabaaaab") &gt; 0);Assert.assertTrue(findAll("a\\w&#123;3,&#125;?b", "abaabaaabaaaab") &gt; 0); 输出 regex = a\w*b, content: abaabaaabaaaab[1th] start: 0, end: 14, group: abaabaaabaaaabregex = a\w*?b, content: abaabaaabaaaab[1th] start: 0, end: 2, group: ab[2th] start: 2, end: 5, group: aab[3th] start: 5, end: 9, group: aaab[4th] start: 9, end: 14, group: aaaabregex = a\w+?b, content: abaabaaabaaaab[1th] start: 0, end: 5, group: abaab[2th] start: 5, end: 9, group: aaab[3th] start: 9, end: 14, group: aaaabregex = a\w??b, content: abaabaaabaaaab[1th] start: 0, end: 2, group: ab[2th] start: 2, end: 5, group: aab[3th] start: 6, end: 9, group: aab[4th] start: 11, end: 14, group: aabregex = a\w&#123;0,4&#125;?b, content: abaabaaabaaaab[1th] start: 0, end: 2, group: ab[2th] start: 2, end: 5, group: aab[3th] start: 5, end: 9, group: aaab[4th] start: 9, end: 14, group: aaaabregex = a\w&#123;3,&#125;?b, content: abaabaaabaaaab[1th] start: 0, end: 5, group: abaab[2th] start: 5, end: 14, group: aaabaaaab 说明 本例中代码展示的是使用不同贪婪或懒惰策略去查找字符串&quot;abaabaaabaaaab&quot; 中匹配以&quot;a&quot;开头，以&quot;b&quot;结尾的所有子字符串。 请从输出结果中，细细体味使用不同的贪婪或懒惰策略，对于匹配子字符串有什么影响。 最实用的正则 校验中文 **描述：**校验字符串中只能有中文字符（不包括中文标点符号）。中文字符的 Unicode 编码范围是\u4e00 到 \u9fa5。 如有兴趣，可以参考百度百科-Unicode 。 ^[\u4e00-\u9fa5]+$ 匹配： 春眠不觉晓 **不匹配：**春眠不觉晓， 校验身份证号码 **描述：**身份证为 15 位或 18 位。15 位是第一代身份证。从 1999 年 10 月 1 日起，全国实行公民身份证号码制度，居民身份证编号由原 15 位升至 18 位。 15 位身份证 **描述：**由 15 位数字组成。排列顺序从左至右依次为：六位数字地区码；六位数字出生日期；三位顺序号，其中 15 位男为单数，女为双数。 18 位身份证 **描述：**由十七位数字本体码和一位数字校验码组成。排列顺序从左至右依次为：六位数字地区码；八位数字出生日期；三位数字顺序码和一位数字校验码（也可能是 X）。 身份证号含义详情请见：百度百科-居民身份证号码 地区码（6 位） (1[1-5]|2[1-3]|3[1-7]|4[1-3]|5[0-4]|6[1-5])\d&#123;4&#125; 出生日期（8 位） 注：下面的是 18 位身份证的有效出生日期，如果是 15 位身份证，只要将第一个\d{4}改为\d{2}即可。 ((\d&#123;4&#125;((0[13578]|1[02])(0[1-9]|[12]\d|3[01])|(0[13456789]|1[012])(0[1-9]|[12]\d|30)|02(0[1-9]|1\d|2[0-8])))|([02468][048]|[13579][26])0229) 15 位有效身份证 ^((1[1-5]|2[1-3]|3[1-7]|4[1-3]|5[0-4]|6[1-5])\d&#123;4&#125;)((\d&#123;2&#125;((0[13578]|1[02])(0[1-9]|[12]\d|3[01])|(0[13456789]|1[012])(0[1-9]|[12]\d|30)|02(0[1-9]|1\d|2[0-8])))|([02468][048]|[13579][26])0229)(\d&#123;3&#125;)$ **匹配：**110001700101031 **不匹配：**110001701501031 18 位有效身份证 ^((1[1-5]|2[1-3]|3[1-7]|4[1-3]|5[0-4]|6[1-5])\d&#123;4&#125;)((\d&#123;4&#125;((0[13578]|1[02])(0[1-9]|[12]\d|3[01])|(0[13456789]|1[012])(0[1-9]|[12]\d|30)|02(0[1-9]|1\d|2[0-8])))|([02468][048]|[13579][26])0229)(\d&#123;3&#125;(\d|X))$ **匹配：**110001199001010310 | 11000019900101015X **不匹配：**990000199001010310 | 110001199013010310 校验有效用户名、密码 **描述：**长度为 6-18 个字符，允许输入字母、数字、下划线，首字符必须为字母。 ^[a-zA-Z]\w&#123;5,17&#125;$ **匹配：**he_llo@worl.d.com | hel.l-o@wor-ld.museum | h1ello@123.com **不匹配：**hello@worl_d.com | he&amp;llo@world.co1 | .hello@wor#.co.uk 校验邮箱 **描述：**不允许使用 IP 作为域名，如 : hello@154.145.68.12 @符号前的邮箱用户和.符号前的域名(domain)必须满足以下条件： 字符只能是英文字母、数字、下划线_、.、- ； 首字符必须为字母或数字； _、.、- 不能连续出现。 域名的根域只能为字母，且至少为两个字符。 ^[A-Za-z0-9](([_\.\-]?[a-zA-Z0-9]+)*)@([A-Za-z0-9]+)(([\.\-]?[a-zA-Z0-9]+)*)\.([A-Za-z]&#123;2,&#125;)$ **匹配：**he_llo@worl.d.com | hel.l-o@wor-ld.museum | h1ello@123.com **不匹配：**hello@worl_d.com | he&amp;llo@world.co1 | .hello@wor#.co.uk 校验 URL **描述：**校验 URL。支持 http、https、ftp、ftps。 ^(ht|f)(tp|tps)\://[a-zA-Z0-9\-\.]+\.([a-zA-Z]&#123;2,3&#125;)?(/\S*)?$ **匹配：**http://google.com/help/me | http://www.google.com/help/me/ | https://www.google.com/help.asp | ftp://www.google.com | ftps://google.org **不匹配：**http://un/www.google.com/index.asp 校验时间 **描述：**校验时间。时、分、秒必须是有效数字，如果数值不是两位数，十位需要补零。 ^([0-1][0-9]|[2][0-3]):([0-5][0-9])$ **匹配：**00:00:00 | 23:59:59 | 17:06:30 **不匹配：**17:6:30 | 24:16:30 校验日期 **描述：**校验日期。日期满足以下条件： 格式 yyyy-MM-dd 或 yyyy-M-d 连字符可以没有或是“-”、“/”、“.”之一 闰年的二月可以有 29 日；而平年不可以。 一、三、五、七、八、十、十二月为 31 日。四、六、九、十一月为 30 日。 ^(?:(?!0000)[0-9]&#123;4&#125;([-/.]?)(?:(?:0?[1-9]|1[0-2])\1(?:0?[1-9]|1[0-9]|2[0-8])|(?:0?[13-9]|1[0-2])\1(?:29|30)|(?:0?[13578]|1[02])\1(?:31))|(?:[0-9]&#123;2&#125;(?:0[48]|[2468][048]|[13579][26])|(?:0[48]|[2468][048]|[13579][26])00)([-/.]?)0?2\2(?:29))$ **匹配：**2016/1/1 | 2016/01/01 | 20160101 | 2016-01-01 | 2016.01.01 | 2000-02-29 **不匹配：**2001-02-29 | 2016/12/32 | 2016/6/31 | 2016/13/1 | 2016/0/1 校验中国手机号码 **描述：**中国手机号码正确格式：11 位数字。 移动有 16 个号段：134、135、136、137、138、139、147、150、151、152、157、158、159、182、187、188。其中 147、157、188 是 3G 号段，其他都是 2G 号段。联通有 7 种号段：130、131、132、155、156、185、186。其中 186 是 3G（WCDMA）号段，其余为 2G 号段。电信有 4 个号段：133、153、180、189。其中 189 是 3G 号段（CDMA2000），133 号段主要用作无线网卡号。总结：13 开头手机号 0-9；15 开头手机号 0-3、5-9；18 开头手机号 0、2、5-9。 此外，中国在国际上的区号为 86，所以手机号开头有+86、86 也是合法的。 以上信息来源于 百度百科-手机号 ^((\+)?86\s*)?((13[0-9])|(15([0-3]|[5-9]))|(18[0,2,5-9]))\d&#123;8&#125;$ 匹配：+86 18012345678 | 86 18012345678 | 15812345678 **不匹配：**15412345678 | 12912345678 | 180123456789 校验中国固话号码 **描述：**固话号码，必须加区号（以 0 开头）。 3 位有效区号：010、020~029，固话位数为 8 位。 4 位有效区号：03xx 开头到 09xx，固话位数为 7。 如果想了解更详细的信息，请参考 百度百科-电话区号 。 ^(010|02[0-9])(\s|-)\d&#123;8&#125;|(0[3-9]\d&#123;2&#125;)(\s|-)\d&#123;7&#125;$ **匹配：**010-12345678 | 010 12345678 | 0512-1234567 | 0512 1234567 **不匹配：**1234567 | 12345678 校验 IPv4 地址 **描述：**IP 地址是一个 32 位的二进制数，通常被分割为 4 个“8 位二进制数”（也就是 4 个字节）。IP 地址通常用“点分十进制”表示成（a.b.c.d）的形式，其中，a,b,c,d 都是 0~255 之间的十进制整数。 ^([01]?\d\d?|2[0-4]\d|25[0-5])\.([01]?\d\d?|2[0-4]\d|25[0-5])\.([01]?\d\d?|2[0-4]\d|25[0-5])\.([01]?\d\d?|2[0-4]\d|25[0-5])$ **匹配：**0.0.0.0 | 255.255.255.255 | 127.0.0.1 **不匹配：**10.10.10 | 10.10.10.256 校验 IPv6 地址 **描述：**IPv6 的 128 位地址通常写成 8 组，每组为四个十六进制数的形式。 IPv6 地址可以表示为以下形式： IPv6 地址 零压缩 IPv6 地址(section 2.2 of rfc5952) 带有本地链接区域索引的 IPv6 地址 (section 11 of rfc4007) 嵌入 IPv4 的 IPv6 地址(section 2 of rfc6052 映射 IPv4 的 IPv6 地址 (section 2.1 of rfc2765) 翻译 IPv4 的 IPv6 地址 (section 2.1 of rfc2765) 显然，IPv6 地址的表示方式很复杂。你也可以参考 百度百科-IPv6 Stack overflow 上的 IPv6 正则表达高票答案 (([0-9a-fA-F]&#123;1,4&#125;:)&#123;7,7&#125;[0-9a-fA-F]&#123;1,4&#125;|([0-9a-fA-F]&#123;1,4&#125;:)&#123;1,7&#125;:|([0-9a-fA-F]&#123;1,4&#125;:)&#123;1,6&#125;:[0-9a-fA-F]&#123;1,4&#125;|([0-9a-fA-F]&#123;1,4&#125;:)&#123;1,5&#125;(:[0-9a-fA-F]&#123;1,4&#125;)&#123;1,2&#125;|([0-9a-fA-F]&#123;1,4&#125;:)&#123;1,4&#125;(:[0-9a-fA-F]&#123;1,4&#125;)&#123;1,3&#125;|([0-9a-fA-F]&#123;1,4&#125;:)&#123;1,3&#125;(:[0-9a-fA-F]&#123;1,4&#125;)&#123;1,4&#125;|([0-9a-fA-F]&#123;1,4&#125;:)&#123;1,2&#125;(:[0-9a-fA-F]&#123;1,4&#125;)&#123;1,5&#125;|[0-9a-fA-F]&#123;1,4&#125;:((:[0-9a-fA-F]&#123;1,4&#125;)&#123;1,6&#125;)|:((:[0-9a-fA-F]&#123;1,4&#125;)&#123;1,7&#125;|:)|fe80:(:[0-9a-fA-F]&#123;0,4&#125;)&#123;0,4&#125;%[0-9a-zA-Z]&#123;1,&#125;|::(ffff(:0&#123;1,4&#125;)&#123;0,1&#125;:)&#123;0,1&#125;((25[0-5]|(2[0-4]|1&#123;0,1&#125;[0-9])&#123;0,1&#125;[0-9])\.)&#123;3,3&#125;(25[0-5]|(2[0-4]|1&#123;0,1&#125;[0-9])&#123;0,1&#125;[0-9])|([0-9a-fA-F]&#123;1,4&#125;:)&#123;1,4&#125;:((25[0-5]|(2[0-4]|1&#123;0,1&#125;[0-9])&#123;0,1&#125;[0-9])\.)&#123;3,3&#125;(25[0-5]|(2[0-4]|1&#123;0,1&#125;[0-9])&#123;0,1&#125;[0-9])) **匹配：**1:2:3:4:5:6:7:8 | 1:: | 1::8 | 1::6:7:8 | 1::5:6:7:8 | 1::4:5:6:7:8 | 1::3:4:5:6:7:8 | ::2:3:4:5:6:7:8 | 1:2:3:4:5:6:7:: | 1:2:3:4:5:6::8 | 1:2:3:4:5::8 | 1:2:3:4::8 | 1:2:3::8 | 1:2::8 | 1::8 | ::8 | fe80::7:8%1 | ::255.255.255.255 | 2001:db8:3:4::192.0.2.33 | 64:ff9b::192.0.2.33 **不匹配：**1.2.3.4.5.6.7.8 | 1::2::3 特定字符 匹配长度为 3 的字符串：^.{3}$。 匹配由 26 个英文字母组成的字符串：^[A-Za-z]+$。 匹配由 26 个大写英文字母组成的字符串：^[A-Z]+$。 匹配由 26 个小写英文字母组成的字符串：^[a-z]+$。 匹配由数字和 26 个英文字母组成的字符串：^[A-Za-z0-9]+$。 匹配由数字、26 个英文字母或者下划线组成的字符串：^\w+$。 特定数字 匹配正整数：^[1-9]\d*$ 匹配负整数：^-[1-9]\d*$ 匹配整数：^(-?[1-9]\d*)|0$ 匹配正浮点数：^[1-9]\d*\.\d+|0\.\d+$ 匹配负浮点数：^-([1-9]\d*\.\d*|0\.\d*[1-9]\d*)$ 匹配浮点数：^-?([1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0)$ 速查元字符字典 为了方便快查正则的元字符含义，在本节根据元字符的功能集中罗列正则的各种元字符。 限定符 字符 描述 * 匹配前面的子表达式零次或多次。例如，zo* 能匹配 “z” 以及 “zoo”。* 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，‘zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，“do(es)?” 可以匹配 “do” 或 “does” 中的&quot;do&quot; 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，‘o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配 n 次。例如，‘o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。‘o{1,}’ 等价于 ‘o+’。‘o{0,}’ 则等价于 ‘o*’。 {n,m} m 和 n 均为非负整数，其中 n &lt;= m。最少匹配 n 次且最多匹配 m 次。例如，“o{1,3}” 将匹配 “fooooood” 中的前三个 o。‘o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。 定位符 字符 描述 ^ 匹配输入字符串开始的位置。如果设置了 RegExp 对象的 Multiline 属性，^ 还会与 \n 或 \r 之后的位置匹配。 $ 匹配输入字符串结尾的位置。如果设置了 RegExp 对象的 Multiline 属性，$ 还会与 \n 或 \r 之前的位置匹配。 \b 匹配一个字边界，即字与空格间的位置。 \B 非字边界匹配。 非打印字符 字符 描述 \cx 匹配由 x 指明的控制字符。例如， \cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \f 匹配一个换页符。等价于 \x0c 和 \cL。 \n 匹配一个换行符。等价于 \x0a 和 \cJ。 \r 匹配一个回车符。等价于 \x0d 和 \cM。 \s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。 \S 匹配任何非空白字符。等价于 [ \f\n\r\t\v]。 \t 匹配一个制表符。等价于 \x09 和 \cI。 \v 匹配一个垂直制表符。等价于 \x0b 和 \cK。 分组 表达式 描述 (exp) 匹配的子表达式。()中的内容就是子表达式。 (?&lt;name&gt;exp) 命名的子表达式（反向引用）。 (?:exp) 非捕获组，表示当一个限定符应用到一个组，但组捕获的子字符串并非所需时，通常会使用非捕获组构造。 (?=exp) 匹配 exp 前面的位置。 (?&lt;=exp) 匹配 exp 后面的位置。 (?!exp) 匹配后面跟的不是 exp 的位置。 (?&lt;!exp) 匹配前面不是 exp 的位置。 特殊符号 字符 描述 \ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， ‘n’ 匹配字符 ‘n’。’\n’ 匹配换行符。序列 ‘\’ 匹配 “”，而 ‘(’ 则匹配 “(”。 \| 指明两项之间的一个选择。 [] 匹配方括号范围内的任意一个字符。形式如：[xyz]、[xyz]、[a-z]、[a-z]、[x,y,z] 参考资料 正则表达式 30 分钟入门教程 msdn 正则表达式教程 正则应用之——日期正则表达式 http://www.regexlib.com/]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>regex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 极简教程]]></title>
    <url>%2Fblog%2F2016%2F10%2F10%2Ftools%2Fnginx%2F</url>
    <content type="text"><![CDATA[Nginx 极简教程 本文是一个 Nginx 极简教程，目的在于帮助新手快速入门 Nginx。 我在 Github 上创建了一个 Nginx 教程项目： nginx-tutorial。教程中提供了一些常用场景的 Nginx 示例，示例可以通过脚本一键式启动，方便新手学习。 📓 本文已归档到：「blog」 概述 安装 Windows 安装 Linux 安装 Linux 开机自启动 使用 nginx 配置实战 http 反向代理配置 负载均衡配置 网站有多个 webapp 的配置 https 反向代理配置 静态站点配置 搭建文件服务器 跨域解决方案 参考资料 概述 什么是 Nginx? Nginx (engine x) 是一款轻量级的 Web 服务器 、反向代理服务器及电子邮件（IMAP/POP3）代理服务器。 什么是反向代理？ 反向代理（Reverse Proxy）方式是指以代理服务器来接受 internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 安装 Windows 安装 （1）进入官方下载地址，选择合适版本（nginx/Windows-xxx）。 （2）解压到本地 （3）启动 下面以 C 盘根目录为例说明下： cd C:cd C:\nginx-0.8.54 start nginx 注：Nginx / Win32 是运行在一个控制台程序，而非 windows 服务方式的。服务器方式目前还是开发尝试中。 Linux 安装 rpm 包方式（推荐） （1）进入下载页面，选择合适版本下载。 $ wget http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm （2）安装 nginx rpm 包 nginx rpm 包实际上安装的是 nginx 的 yum 源。 $ rpm -ivh nginx-*.rpm （3）正式安装 rpm 包 $ yum install nginx （4）关闭防火墙 $ firewall-cmd --zone=public --add-port=80/tcp --permanent$ firewall-cmd --reload 源码编译方式 安装编译工具及库文件 Nginx 源码的编译依赖于 gcc 以及一些库文件，所以必须提前安装。 $ yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel Nginx 依赖 pcre 库，安装步骤如下： （1）下载解压到本地 进入pcre 官网下载页面，选择合适的版本下载。 我选择的是 8.35 版本： wget -O /opt/pcre/pcre-8.35.tar.gz http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gzcd /opt/pcretar zxvf pcre-8.35.tar.gz （2）编译安装 执行以下命令： cd /opt/pcre/pcre-8.35./configuremake &amp;&amp; make install （3）检验是否安装成功 执行 pcre-config --version 命令。 安装 Nginx 安装步骤如下： （1）下载解压到本地 进入官网下载地址：http://nginx.org/en/download.html ，选择合适的版本下载。 我选择的是 1.12.2 版本：http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz wget -O /opt/nginx/nginx-1.12.2.tar.gz http://nginx.org/download/nginx-1.12.2.tar.gzcd /opt/nginxtar zxvf nginx-1.12.2.tar.gz （2）编译安装 执行以下命令： cd /opt/nginx/nginx-1.12.2./configure --with-http_stub_status_module --with-http_ssl_module --with-pcre=/opt/pcre/pcre-8.35 （3）关闭防火墙 $ firewall-cmd --zone=public --add-port=80/tcp --permanent$ firewall-cmd --reload （4） 启动 Nginx 安装成功后，直接执行 nginx 命令即可启动 nginx。 Linux 开机自启动 Centos7 以上是用 Systemd 进行系统初始化的，Systemd 是 Linux 系统中最新的初始化系统（init），它主要的设计目标是克服 sysvinit 固有的缺点，提高系统的启动速度。Systemd 服务文件以 .service 结尾。 rpm 包方式 如果是通过 rpm 包安装的，会自动创建 nginx.service 文件。 直接用命令： $ systemctl enable nginx.service 设置开机启动即可。 源码编译方式 如果采用源码编译方式，需要手动创建 nginx.service 文件。 使用 nginx 的使用比较简单，就是几条命令。 常用到的命令如下： nginx -s stop 快速关闭Nginx，可能不保存相关信息，并迅速终止web服务。nginx -s quit 平稳关闭Nginx，保存相关信息，有安排的结束web服务。nginx -s reload 因改变了Nginx相关配置，需要重新加载配置而重载。nginx -s reopen 重新打开日志文件。nginx -c filename 为 Nginx 指定一个配置文件，来代替缺省的。nginx -t 不运行，而仅仅测试配置文件。nginx 将检查配置文件的语法的正确性，并尝试打开配置文件中所引用到的文件。nginx -v 显示 nginx 的版本。nginx -V 显示 nginx 的版本，编译器版本和配置参数。 如果不想每次都敲命令，可以在 nginx 安装目录下新添一个启动批处理文件startup.bat，双击即可运行。内容如下： @echo offrem 如果启动前已经启动nginx并记录下pid文件，会kill指定进程nginx.exe -s stoprem 测试配置文件语法正确性nginx.exe -t -c conf/nginx.confrem 显示版本信息nginx.exe -vrem 按照指定配置去启动nginxnginx.exe -c conf/nginx.conf 如果是运行在 Linux 下，写一个 shell 脚本，大同小异。 nginx 配置实战 我始终认为，各种开发工具的配置还是结合实战来讲述，会让人更易理解。 http 反向代理配置 我们先实现一个小目标：不考虑复杂的配置，仅仅是完成一个 http 反向代理。 nginx.conf 配置文件如下： 注：conf / nginx.conf 是 nginx 的默认配置文件。你也可以使用 nginx -c 指定你的配置文件 #运行用户#user somebody;#启动进程,通常设置成和cpu的数量相等worker_processes 1;#全局错误日志error_log D:/Tools/nginx-1.10.1/logs/error.log;error_log D:/Tools/nginx-1.10.1/logs/notice.log notice;error_log D:/Tools/nginx-1.10.1/logs/info.log info;#PID文件，记录当前启动的nginx的进程IDpid D:/Tools/nginx-1.10.1/logs/nginx.pid;#工作模式及连接数上限events &#123; worker_connections 1024; #单个后台worker process进程的最大并发链接数&#125;#设定http服务器，利用它的反向代理功能提供负载均衡支持http &#123; #设定mime类型(邮件支持类型),类型由mime.types文件定义 include D:/Tools/nginx-1.10.1/conf/mime.types; default_type application/octet-stream; #设定日志 log_format main '[$remote_addr] - [$remote_user] [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log D:/Tools/nginx-1.10.1/logs/access.log main; rewrite_log on; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用， #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 keepalive_timeout 120; tcp_nodelay on; #gzip压缩开关 #gzip on; #设定实际的服务器列表 upstream zp_server1&#123; server 127.0.0.1:8089; &#125; #HTTP服务器 server &#123; #监听80端口，80端口是知名端口号，用于HTTP协议 listen 80; #定义使用www.xx.com访问 server_name www.helloworld.com; #首页 index index.html #指向webapp的目录 root D:\01_Workspace\Project\github\zp\SpringNotes\spring-security\spring-shiro\src\main\webapp; #编码格式 charset utf-8; #代理配置参数 proxy_connect_timeout 180; proxy_send_timeout 180; proxy_read_timeout 180; proxy_set_header Host $host; proxy_set_header X-Forwarder-For $remote_addr; #反向代理的路径（和upstream绑定），location 后面设置映射的路径 location / &#123; proxy_pass http://zp_server1; &#125; #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; root D:\01_Workspace\Project\github\zp\SpringNotes\spring-security\spring-shiro\src\main\webapp\views; #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。 expires 30d; &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; stub_status on; access_log on; auth_basic "NginxStatus"; auth_basic_user_file conf/htpasswd; &#125; #禁止访问 .htxxx 文件 location ~ /\.ht &#123; deny all; &#125; #错误处理页面（可选择性配置） #error_page 404 /404.html; #error_page 500 502 503 504 /50x.html; #location = /50x.html &#123; # root html; #&#125; &#125;&#125; 好了，让我们来试试吧： 启动 webapp，注意启动绑定的端口要和 nginx 中的 upstream 设置的端口保持一致。 更改 host：在 C:\Windows\System32\drivers\etc 目录下的 host 文件中添加一条 DNS 记录 127.0.0.1 www.helloworld.com 启动前文中 startup.bat 的命令 在浏览器中访问 www.helloworld.com，不出意外，已经可以访问了。 负载均衡配置 上一个例子中，代理仅仅指向一个服务器。 但是，网站在实际运营过程中，多半都是有多台服务器运行着同样的 app，这时需要使用负载均衡来分流。 nginx 也可以实现简单的负载均衡功能。 假设这样一个应用场景：将应用部署在 192.168.1.11:80、192.168.1.12:80、192.168.1.13:80 三台 linux 环境的服务器上。网站域名叫 www.helloworld.com，公网 IP 为 192.168.1.11。在公网 IP 所在的服务器上部署 nginx，对所有请求做负载均衡处理。 nginx.conf 配置如下： http &#123; #设定mime类型,类型由mime.type文件定义 include /etc/nginx/mime.types; default_type application/octet-stream; #设定日志格式 access_log /var/log/nginx/access.log; #设定负载均衡的服务器列表 upstream load_balance_server &#123; #weigth参数表示权值，权值越高被分配到的几率越大 server 192.168.1.11:80 weight=5; server 192.168.1.12:80 weight=1; server 192.168.1.13:80 weight=6; &#125; #HTTP服务器 server &#123; #侦听80端口 listen 80; #定义使用www.xx.com访问 server_name www.helloworld.com; #对所有请求进行负载均衡请求 location / &#123; root /root; #定义服务器的默认网站根目录位置 index index.html index.htm; #定义首页索引文件的名称 proxy_pass http://load_balance_server ;#请求转向load_balance_server 定义的服务器列表 #以下是一些反向代理的配置(可选择性配置) #proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $remote_addr; proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数 &#125; &#125;&#125; 网站有多个 webapp 的配置 当一个网站功能越来越丰富时，往往需要将一些功能相对独立的模块剥离出来，独立维护。这样的话，通常，会有多个 webapp。 举个例子：假如 www.helloworld.com 站点有好几个 webapp，finance（金融）、product（产品）、admin（用户中心）。访问这些应用的方式通过上下文(context)来进行区分: www.helloworld.com/finance/ www.helloworld.com/product/ www.helloworld.com/admin/ 我们知道，http 的默认端口号是 80，如果在一台服务器上同时启动这 3 个 webapp 应用，都用 80 端口，肯定是不成的。所以，这三个应用需要分别绑定不同的端口号。 那么，问题来了，用户在实际访问 www.helloworld.com 站点时，访问不同 webapp，总不会还带着对应的端口号去访问吧。所以，你再次需要用到反向代理来做处理。 配置也不难，来看看怎么做吧： http &#123; #此处省略一些基本配置 upstream product_server&#123; server www.helloworld.com:8081; &#125; upstream admin_server&#123; server www.helloworld.com:8082; &#125; upstream finance_server&#123; server www.helloworld.com:8083; &#125; server &#123; #此处省略一些基本配置 #默认指向product的server location / &#123; proxy_pass http://product_server; &#125; location /product/&#123; proxy_pass http://product_server; &#125; location /admin/ &#123; proxy_pass http://admin_server; &#125; location /finance/ &#123; proxy_pass http://finance_server; &#125; &#125;&#125; https 反向代理配置 一些对安全性要求比较高的站点，可能会使用 HTTPS（一种使用 ssl 通信标准的安全 HTTP 协议）。 这里不科普 HTTP 协议和 SSL 标准。但是，使用 nginx 配置 https 需要知道几点： HTTPS 的固定端口号是 443，不同于 HTTP 的 80 端口 SSL 标准需要引入安全证书，所以在 nginx.conf 中你需要指定证书和它对应的 key 其他和 http 反向代理基本一样，只是在 Server 部分配置有些不同。 #HTTP服务器server &#123; #监听443端口。443为知名端口号，主要用于HTTPS协议 listen 443 ssl; #定义使用www.xx.com访问 server_name www.helloworld.com; #ssl证书文件位置(常见证书文件格式为：crt/pem) ssl_certificate cert.pem; #ssl证书key位置 ssl_certificate_key cert.key; #ssl配置参数（选择性配置） ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; #数字签名，此处使用MD5 ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / &#123; root /root; index index.html index.htm; &#125;&#125; 静态站点配置 有时候，我们需要配置静态站点(即 html 文件和一堆静态资源)。 举例来说：如果所有的静态资源都放在了 /app/dist 目录下，我们只需要在 nginx.conf 中指定首页以及这个站点的 host 即可。 配置如下： worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; gzip on; gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/javascript image/jpeg image/gif image/png; gzip_vary on; server &#123; listen 80; server_name static.zp.cn; location / &#123; root /app/dist; index index.html; #转发任何请求到 index.html &#125; &#125;&#125; 然后，添加 HOST： 127.0.0.1 static.zp.cn 此时，在本地浏览器访问 static.zp.cn ，就可以访问静态站点了。 搭建文件服务器 有时候，团队需要归档一些数据或资料，那么文件服务器必不可少。使用 Nginx 可以非常快速便捷的搭建一个简易的文件服务。 Nginx 中的配置要点： 将 autoindex 开启可以显示目录，默认不开启。 将 autoindex_exact_size 开启可以显示文件的大小。 将 autoindex_localtime 开启可以显示文件的修改时间。 root 用来设置开放为文件服务的根路径。 charset 设置为 charset utf-8,gbk;，可以避免中文乱码问题（windows 服务器下设置后，依然乱码，本人暂时没有找到解决方法）。 一个最简化的配置如下： autoindex on;# 显示目录autoindex_exact_size on;# 显示文件大小autoindex_localtime on;# 显示文件时间server &#123; charset utf-8,gbk; # windows 服务器下设置后，依然乱码，暂时无解 listen 9050 default_server; listen [::]:9050 default_server; server_name _; root /share/fs;&#125; 跨域解决方案 web 领域开发中，经常采用前后端分离模式。这种模式下，前端和后端分别是独立的 web 应用程序，例如：后端是 Java 程序，前端是 React 或 Vue 应用。 各自独立的 web app 在互相访问时，势必存在跨域问题。解决跨域问题一般有两种思路： CORS 在后端服务器设置 HTTP 响应头，把你需要运行访问的域名加入加入 Access-Control-Allow-Origin 中。 jsonp 把后端根据请求，构造 json 数据，并返回，前端用 jsonp 跨域。 这两种思路，本文不展开讨论。 需要说明的是，nginx 根据第一种思路，也提供了一种解决跨域的解决方案。 举例：www.helloworld.com 网站是由一个前端 app ，一个后端 app 组成的。前端端口号为 9000， 后端端口号为 8080。 前端和后端如果使用 http 进行交互时，请求会被拒绝，因为存在跨域问题。来看看，nginx 是怎么解决的吧： 首先，在 enable-cors.conf 文件中设置 cors ： # allow origin listset $ACAO '*';# set single originif ($http_origin ~* (www.helloworld.com)$) &#123; set $ACAO $http_origin;&#125;if ($cors = "trueget") &#123; add_header 'Access-Control-Allow-Origin' "$http_origin"; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type';&#125;if ($request_method = 'OPTIONS') &#123; set $cors "$&#123;cors&#125;options";&#125;if ($request_method = 'GET') &#123; set $cors "$&#123;cors&#125;get";&#125;if ($request_method = 'POST') &#123; set $cors "$&#123;cors&#125;post";&#125; 接下来，在你的服务器中 include enable-cors.conf 来引入跨域配置： # ----------------------------------------------------# 此文件为项目 nginx 配置片段# 可以直接在 nginx config 中 include（推荐）# 或者 copy 到现有 nginx 中，自行配置# www.helloworld.com 域名需配合 dns hosts 进行配置# 其中，api 开启了 cors，需配合本目录下另一份配置文件# ----------------------------------------------------upstream front_server&#123; server www.helloworld.com:9000;&#125;upstream api_server&#123; server www.helloworld.com:8080;&#125;server &#123; listen 80; server_name www.helloworld.com; location ~ ^/api/ &#123; include enable-cors.conf; proxy_pass http://api_server; rewrite "^/api/(.*)$" /$1 break; &#125; location ~ ^/ &#123; proxy_pass http://front_server; &#125;&#125; 到此，就完成了。 参考资料 Nginx 的中文维基]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>load balance</tag>
        <tag>proxy</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络协议之 HTTP]]></title>
    <url>%2Fblog%2F2016%2F01%2F08%2Fcommunication%2Fhttp%2F</url>
    <content type="text"><![CDATA[网络协议之 HTTP 📓 本文已归档到：「blog」 HTTP 是什么？ 实例 工作原理 特点 客户端请求消息 服务器响应消息 HTTP 状态码 更多内容 HTTP 是什么？ HTTP（HyperText Transfer Protocol，超文本传输协议）是 WWW (World Wide Web)实现数据通信的基石。 HTTP 是由 IETF(Internet Engineering Task Force，互联网工程工作小组) 和 W3C(World Wide Web Consortium，万维网协会) 共同合作制订的，它们发布了一系列的RFC(Request For Comments)，其中最著名的是 RFC 2616，它定义了HTTP /1.1。 它是一种应用层协议（OSI 七层模型的最顶层），它基于 TCP/IP 通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。 实例 如果你学习过计算机网络，熟悉 OSI 模型，那么你可以跳过这个实例了。 而不了解 OSI 模型的朋友，不妨通过一个实例来对 HTTP 报文有一个感性的认识。 以下是使用 wireshark 抓取的一个实际访问百度首页的 HTTP GET 报文： 可以清楚的看到它的层级结构如下图，经过了层层的包装。 工作原理 HTTP 工作于 Client/Server 模型上。 客户端和服务器之间的通信采用 request/response 机制。 客户端是终端（可以是浏览器、爬虫程序等），服务器是网站的 Web 服务器。 一次 HTTP 操作称为一个事务，其工作过程大致可分为四步： 建立连接 - 首先，客户端和服务器需要建立一个到服务器指定端口（默认端口号为 80）的 TCP 连接（注：虽然 HTTP 采用 TCP 连接是最流行的方式，但是 RFC 并没有指定一定要采用这种网络传输方式。）。 发送请求信息 - 客户端向服务器发送请求。请求方式的格式为，统一资源标识符、协议版本号，后边是 MIME 信息包括请求修饰符 发送响应信息 - 服务器监听指定接口是否收到请求，一旦发现请求，处理后，返回响应结果给客户端。其格式为一个状态行包括信息的协议版本号、一个成功或错误的代码，后边是 MIME 信息包括服务器信息、实体信息和可能的内容。 关闭连接 - 客户端根据响应，显示结果给用户，最后关闭连接。 特点 无连接的 - 无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 无状态的 - HTTP 协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 媒体独立的 - 这意味着，只要客户端和服务器知道如何处理的数据内容，任何类型的数据都可以通过 HTTP 发送。客户端以及服务器指定使用适合的 MIME-type 内容类型。 C/S 模型的 - 基于 Client/Server 模型工作。 HTTP 消息结构 HTTP 是基于客户端/服务端（C/S）的架构模型，通过一个可靠的链接来交换信息，是一个无状态的请求/响应协议。 一个 HTTP&quot;客户端&quot;是一个应用程序（Web 浏览器或其他任何客户端），通过连接到服务器达到向服务器发送一个或多个 HTTP 的请求的目的。 一个 HTTP&quot;服务器&quot;同样也是一个应用程序（通常是一个 Web 服务，如 Apache Web 服务器或 IIS 服务器等），通过接收客户端的请求并向客户端发送 HTTP 响应数据。 HTTP 使用统一资源标识符（Uniform Resource Identifiers, URI）来传输数据和建立连接。 一旦建立连接后，数据消息就通过类似 Internet 邮件所使用的格式[RFC5322]和多用途 Internet 邮件扩展（MIME）[RFC2045]来传送。 客户端请求消息 客户端发送一个 HTTP 请求到服务器的请求消息包括以下格式：请求行（request line）、请求头部（header）、空行和请求数据四个部分组成，下图给出了请求报文的一般格式。 服务器响应消息 HTTP 响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。 HTTP 请求 根据 HTTP 标准，HTTP 请求可以使用多种请求方法。 HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。 HTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT方法。 方法 描述 GET 请求指定的页面信息，并返回实体主体。 HEAD 类似于 get 请求，只不过返回的响应中没有具体的内容，用于获取报头 POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。 PUT 从客户端向服务器传送的数据取代指定的文档的内容。 DELETE 请求服务器删除指定的页面。 CONNECT HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。 OPTIONS 允许客户端查看服务器的性能。 TRACE 回显服务器收到的请求，主要用于测试或诊断。 HTTP 请求消息头 请求消息头 说明 Accept 浏览器支持的格式 Accept-Encoding 支持的编码格式，如（UTF-8，GBK） Accept-Language 支持的语言类型 User-Agent 浏览器信息 Cookie 记录的是用户当前的状态 Referer 指从哪个页面单击链接进入的页面 HOST 目的地址对应的主机名 Connection 连接类型。如 Keep-Alive 表示长连接，不会断开 Content-Length 内容长度 Content-Type 内容类型 HTTP 响应 响应消息头 说明 Allow 服务器支持哪些请求方法（如 GET、POST 等）。 Content-Encoding 文档的编码（Encode）方法。只有在解码之后才可以得到 Content-Type 头指定的内容类型。利用 gzip 压缩文档能够显著地减少 HTML 文档的下载时间。Java 的 GZIPOutputStream 可以很方便地进行 gzip 压缩，但只有 Unix 上的 Netscape 和 Windows 上的 IE 4、IE 5 才支持它。因此，Servlet 应该通过查看 Accept-Encoding 头（即 request.getHeader(“Accept-Encoding”)）检查浏览器是否支持 gzip，为支持 gzip 的浏览器返回经 gzip 压缩的 HTML 页面，为其他浏览器返回普通页面。 Content-Length 表示内容长度。只有当浏览器使用持久 HTTP 连接时才需要这个数据。如果你想要利用持久连接的优势，可以把输出文档写入 ByteArrayOutputStram，完成后查看其大小，然后把该值放入 Content-Length 头，最后通过byteArrayStream.writeTo(response.getOutputStream() 发送内容。 Content-Type 表示后面的文档属于什么 MIME 类型。Servlet 默认为 text/plain，但通常需要显式地指定为 text/html。由于经常要设置 Content-Type，因此 HttpServletResponse 提供了一个专用的方法 setContentType。 Date 当前的 GMT 时间。你可以用 setDateHeader 来设置这个头以避免转换时间格式的麻烦。 Expires 应该在什么时候认为文档已经过期，从而不再缓存它？ Last-Modified 文档的最后改动时间。客户可以通过 If-Modified-Since 请求头提供一个日期，该请求将被视为一个条件 GET，只有改动时间迟于指定时间的文档才会返回，否则返回一个 304（Not Modified）状态。Last-Modified 也可用 setDateHeader 方法来设置。 Location 表示客户应当到哪里去提取文档。Location 通常不是直接设置的，而是通过 HttpServletResponse 的 sendRedirect 方法，该方法同时设置状态代码为 302。 Refresh 表示浏览器应该在多少时间之后刷新文档，以秒计。除了刷新当前文档之外，你还可以通过 response.setHeader(&quot;Refresh&quot;, &quot;5;URL=http://host/path&quot;)让浏览器读取指定的页面。 注意这种功能通常是通过设置 HTML 页面 HEAD 区的 &lt;META HTTP-EQUIV=&quot;Refresh&quot; CONTENT=&quot;5;URL=http://host/path&quot;&gt;实现，这是因为，自动刷新或重定向对于那些不能使用 CGI 或 Servlet 的 HTML 编写者十分重要。但是，对于 Servlet 来说，直接设置 Refresh 头更加方便。 注意 Refresh 的意义是&quot;N 秒之后刷新本页面或访问指定页面&quot;，而不是&quot;每隔 N 秒刷新本页面或访问指定页面&quot;。因此，连续刷新要求每次都发送一个 Refresh 头，而发送 204 状态代码则可以阻止浏览器继续刷新，不管是使用 Refresh 头还是 &lt;META HTTP-EQUIV=&quot;Refresh&quot; ...&gt;。 注意 Refresh 头不属于 HTTP 1.1 正式规范的一部分，而是一个扩展，但 Netscape 和 IE 都支持它。 Server 服务器名字。Servlet 一般不设置这个值，而是由 Web 服务器自己设置。 Set-Cookie 设置和页面关联的 Cookie。Servlet 不应使用response.setHeader(&quot;Set-Cookie&quot;, ...)，而是应使用 HttpServletResponse 提供的专用方法 addCookie。参见下文有关 Cookie 设置的讨论。 WWW-Authenticate 客户应该在 Authorization 头中提供什么类型的授权信息？在包含 401（Unauthorized）状态行的应答中这个头是必需的。例如，response.setHeader(&quot;WWW-Authenticate&quot;, &quot;BASIC realm=＼&quot;executives＼&quot;&quot;)。 注意 Servlet 一般不进行这方面的处理，而是让 Web 服务器的专门机制来控制受密码保护页面的访问（例如.htaccess）。 HTTP 状态码 当浏览者访问一个网页时，浏览者的浏览器会向网页所在服务器发出请求。当浏览器接收并显示网页前，此网页所在的服务器会返回一个包含 HTTP 状态码的信息头（server header）用以响应浏览器的请求。 HTTP 状态码的英文为 HTTP Status Code。 下面是常见的 HTTP 状态码： 200 - 请求成功 301 - 资源（网页等）被永久转移到其它 URL 404 - 请求的资源（网页等）不存在 500 - 内部服务器错误 HTTP 状态码分类 HTTP 状态码由三个十进制数字组成，第一个十进制数字定义了状态码的类型，后两个数字没有分类的作用。HTTP 状态码共分为 5 种类型： 分类 分类描述 1 信息，服务器收到请求，需要请求者继续执行操作 2 成功，操作被成功接收并处理 3 重定向，需要进一步的操作以完成请求 4 客户端错误，请求包含语法错误或无法完成请求 5 服务器错误，服务器在处理请求的过程中发生了错误 HTTP 状态列表： 状态码 状态码英文名称 100 Continue 101 Switching Protocols 200 OK 201 Created 202 Accepted 203 Non-Authoritative Information 204 No Content 205 Reset Content 206 Partial Content 300 Multiple Choices 301 Moved Permanently 302 Found 303 See Other 304 Not Modified 305 Use Proxy 306 Unused 307 Temporary Redirect 400 Bad Request 401 Unauthorized 402 Payment Required 403 Forbidden 404 Not Found 405 Method Not Allowed 406 Not Acceptable 407 Proxy Authentication Required 408 Request Time-out 409 Conflict 410 Gone 411 Length Required 412 Precondition Failed 413 Request Entity Too Large 414 Request-URI Too Large 415 Unsupported Media Type 416 Requested range not satisfiable 417 Expectation Failed 500 Internal Server Error 501 Not Implemented 502 Bad Gateway 503 Service Unavailable 504 Gateway Time-out 505 HTTP Version not supported 更多内容 http://blog.csdn.net/gueter/article/details/1524447 http://www.runoob.com/http/http-intro.html https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol]]></content>
      <categories>
        <category>communication</category>
      </categories>
      <tags>
        <tag>communication</tag>
        <tag>network</tag>
        <tag>protocol</tag>
        <tag>application</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ICMP]]></title>
    <url>%2Fblog%2F2014%2F07%2F02%2Fcommunication%2Ficmp%2F</url>
    <content type="text"><![CDATA[ICMP 📓 本文已归档到：「blog」 ICMP 简介 ICMP 类型 目的不可达(Destination Unreachable Message) 超时(Time Exceeded Message) 参数错误报文(Parameter Problem Message) 源冷却(Source Quench Message) 重定向(Redirect Message) 请求回显或回显应答(Echo or Echo Reply Message) 时间戳或时间戳请求(Timestamp or Timestamp Reply Message) 信息请求或信息响应 总结 参考 ICMP 简介 ICMP 全名为(INTERNET CONTROL MESSAGE PROTOCOL)网络控制消息协议。 ICMP 的协议号为1。 ICMP 报文就像是 IP 报文的小弟，总顶着 IP 报文的名头出来混。因为 ICMP 报文是在 IP 报文内部的，如图： 图：IP 数据报 ICMP 类型 ICMP 报文主要有两大功能：查询报文和差错报文。 目的不可达(Destination Unreachable Message) 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Type | Code | Checksum | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | unused | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Internet Header + 64 bits of Original Data Datagram | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ 日常生活中，邮寄包裹会经过多个传递环节，任意一环如果无法传下去，都会返回寄件人，并附上无法邮寄的原因。同理，当路由器收到一个无法传递下去的 IP 报文时，会发送 ICMP目的不可达报文（Type 为 3）给 IP 报文的源发送方。报文中的 Code 就表示发送失败的原因。 Code 0 = net unreachable; 1 = host unreachable; 2 = protocol unreachable; 3 = port unreachable; 4 = fragmentation needed and DF set; 5 = source route failed. 超时(Time Exceeded Message) 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Type | Code | Checksum | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | unused | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Internet Header + 64 bits of Original Data Datagram | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ 网络传输 IP 数据报的过程中，如果 IP 数据包的 TTL 值逐渐递减为 0 时，需要丢弃数据报。这时，路由器需要向源发送方发送 ICMP 超时报文(Type 为 11)，Code 为 0，表示传输过程中超时了。 一个 IP 数据报可能会因为过大而被分片，然后在目的主机侧把所有的分片重组。如果主机迟迟没有等到所有的分片报文，就会向源发送方发送一个 ICMP 超时报文，Code 为 1，表示分片重组超时了。 参数错误报文(Parameter Problem Message) 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Type | Code | Checksum | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Pointer | unused | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Internet Header + 64 bits of Original Data Datagram | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ 当路由器或主机处理数据报时，发现因为报文头的参数错误而不得不丢弃报文时，需要向源发送方发送参数错误报文(Type 为 12)。当 Code 为 0 时，报文中的 Pointer 表示错误的字节位置。 源冷却(Source Quench Message) 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Type | Code | Checksum | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | unused | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Internet Header + 64 bits of Original Data Datagram | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ 路由器在处理报文时会有一个缓存队列。如果超过最大缓存队列，将无法处理，从而丢弃报文。并向源发送方发一个 ICMP 源冷却报文(Type 为 4)，告诉对方：“嘿，我这里客满了，你迟点再来。” 重定向(Redirect Message) 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Type | Code | Checksum | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Gateway Internet Address | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Internet Header + 64 bits of Original Data Datagram | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ 想像一下，在公司中，有人来你的项目组问你某某某在哪儿。你一想，我们组没有这人啊。你肯定就会说，我们组没有这号人，你去其他组看看。当路由收到 IP 数据报，发现数据报的目的地址在路由表上没有，它就会发 ICMP 重定向报文(Type 为 5)给源发送方，提醒它想要发送的地址不在，去其他地方找找吧。 请求回显或回显应答(Echo or Echo Reply Message) 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Type | Code | Checksum | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Identifier | Sequence Number | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Data … ±±±±± Type(8)是请求回显报文(Echo)；Type(0)是回显应答报文(Echo Reply)。 请求回显或回显应答报文属于查询报文。Ping 就是用这种报文进行查询和回应。 时间戳或时间戳请求(Timestamp or Timestamp Reply Message) 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Type | Code | Checksum | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Identifier | Sequence Number | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Originate Timestamp | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Receive Timestamp | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Transmit Timestamp | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ 时间戳报文是用来记录收发以及传输时间的报文。Originate Timestamp 记录的是发送方发送报文的时刻；Receive Timestamp记录的是接收方收到报文的时刻；Transmit Timestamp表示回显这最后发送报文的时刻。 信息请求或信息响应 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Type | Code | Checksum | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ | Identifier | Sequence Number | ±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±+ 这种报文是用来找出一个主机所在的网络个数（一个主机可能会在多个网络中）。报文的 IP 消息头的目的地址会填为全 0，表示 this，源地址会填为源 IP 所在的网络 IP。 总结 图：ICMP 知识点思维导图 参考 RFC792]]></content>
      <categories>
        <category>communication</category>
      </categories>
      <tags>
        <tag>communication</tag>
        <tag>network</tag>
        <tag>protocol</tag>
      </tags>
  </entry>
</search>
